<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>努力，奋斗</title>
  
  <subtitle>记录学习</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://shang.at/"/>
  <updated>2020-06-28T23:23:44.036Z</updated>
  <id>https://shang.at/</id>
  
  <author>
    <name>王尚</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Python学习-python3.6-dict有序且效率更高</title>
    <link href="https://shang.at/post/Python%E5%AD%A6%E4%B9%A0-python3-6-dict%E6%9C%89%E5%BA%8F%E4%B8%94%E6%95%88%E7%8E%87%E6%9B%B4%E9%AB%98/"/>
    <id>https://shang.at/post/Python学习-python3-6-dict有序且效率更高/</id>
    <published>2020-06-28T23:22:42.000Z</published>
    <updated>2020-06-28T23:23:44.036Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.cnblogs.com/xieqiankun/p/python_dict.html" target="_blank" rel="noopener">https://www.cnblogs.com/xieqiankun/p/python_dict.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/xieqiankun/p/python_dict.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnblogs.com/xieqiankun/p/pytho
      
    
    </summary>
    
      <category term="Python学习" scheme="https://shang.at/categories/Python%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="python的dict" scheme="https://shang.at/tags/python%E7%9A%84dict/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop学习</title>
    <link href="https://shang.at/post/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    <id>https://shang.at/post/Hadoop学习/</id>
    <published>2020-06-26T16:34:48.000Z</published>
    <updated>2020-06-26T17:03:15.779Z</updated>
    
    <content type="html"><![CDATA[<p>大数据</p><p>分布式数据存储</p><p>​    数据一致性 - CAP - poxes</p><p>主从</p><p>​    单点故障 - HA</p><p>​    内存压力 - 分片管理</p><p>分布式计算 - 计算向数据移动</p><p>​    </p><p>mapreduce</p><p>数据以一条记录为单位及经过map方法映射成KV，相同的K为一组，这一组数据条用一次reduce方法，在方法内迭代计算一组数据。</p><p>迭代器模式，数据集一般是用迭代计算的方式</p><p>​    </p><p>为什么要有split？split只是一个逻辑上的概念。</p><p>​    与数据物理存储上的block解耦(软件工程上：加一层解耦)，默认情况下，split等于block，但是也可以小于block，也可能大于block</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;大数据&lt;/p&gt;
&lt;p&gt;分布式数据存储&lt;/p&gt;
&lt;p&gt;​    数据一致性 - CAP - poxes&lt;/p&gt;
&lt;p&gt;主从&lt;/p&gt;
&lt;p&gt;​    单点故障 - HA&lt;/p&gt;
&lt;p&gt;​    内存压力 - 分片管理&lt;/p&gt;
&lt;p&gt;分布式计算 - 计算向数据移动&lt;/p&gt;
&lt;p&gt;
      
    
    </summary>
    
      <category term="Hadoop学习" scheme="https://shang.at/categories/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Hadoop" scheme="https://shang.at/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop学习-Yarn-Scheduler</title>
    <link href="https://shang.at/post/Hadoop%E5%AD%A6%E4%B9%A0-Yarn-Scheduler/"/>
    <id>https://shang.at/post/Hadoop学习-Yarn-Scheduler/</id>
    <published>2020-06-25T06:24:45.000Z</published>
    <updated>2020-06-25T06:25:31.320Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="Hadoop学习" scheme="https://shang.at/categories/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Yarn-Scheduler" scheme="https://shang.at/tags/Yarn-Scheduler/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop学习-Yarn-Container</title>
    <link href="https://shang.at/post/Hadoop%E5%AD%A6%E4%B9%A0-Yarn-Container/"/>
    <id>https://shang.at/post/Hadoop学习-Yarn-Container/</id>
    <published>2020-06-25T06:24:29.000Z</published>
    <updated>2020-06-25T06:25:23.223Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="Hadoop学习" scheme="https://shang.at/categories/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Yarn-Container" scheme="https://shang.at/tags/Yarn-Container/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop学习-如何实现一个在Yarn上的Application</title>
    <link href="https://shang.at/post/Hadoop%E5%AD%A6%E4%B9%A0-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E5%9C%A8Yarn%E4%B8%8A%E7%9A%84Application/"/>
    <id>https://shang.at/post/Hadoop学习-如何实现一个在Yarn上的Application/</id>
    <published>2020-06-25T01:27:51.000Z</published>
    <updated>2020-06-25T01:28:09.068Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="Hadoop学习" scheme="https://shang.at/categories/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="实现一个在Yarn上的Application" scheme="https://shang.at/tags/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E5%9C%A8Yarn%E4%B8%8A%E7%9A%84Application/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop学习-Mapreduce编程模式</title>
    <link href="https://shang.at/post/Hadoop%E5%AD%A6%E4%B9%A0-Mapreduce%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%BC%8F/"/>
    <id>https://shang.at/post/Hadoop学习-Mapreduce编程模式/</id>
    <published>2020-06-25T01:26:50.000Z</published>
    <updated>2020-06-25T01:27:19.885Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="Hadoop学习" scheme="https://shang.at/categories/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Mapreduce编程模式" scheme="https://shang.at/tags/Mapreduce%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Hive学习-安装</title>
    <link href="https://shang.at/post/Hive%E5%AD%A6%E4%B9%A0-%E5%AE%89%E8%A3%85/"/>
    <id>https://shang.at/post/Hive学习-安装/</id>
    <published>2020-06-24T07:41:54.000Z</published>
    <updated>2020-06-24T07:56:08.447Z</updated>
    
    <content type="html"><![CDATA[<h4 id="配置过程"><a href="#配置过程" class="headerlink" title="配置过程"></a>配置过程</h4><ol><li><p>mysql</p><p>安装</p><p>配置可以远程连接</p></li><li><p>jdbc driver</p><p>hive使用的jdbc drive要与mysql的版本匹配</p></li><li><p>hive配置</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- hive-site.xml --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://hostmachine:3306/metastore?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>the URL of the MySQL database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive1234<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>datanucleus.autoCreateSchema<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>datanucleus.fixedDatastore<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>datanucleus.autoStartMechanism<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>SchemaTable<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 配置数据存放在hdfs上的路径 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 配置metastore service 的节点 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://node2:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>IP address (or fully-qualified domain name) and port of the metastore host<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.schema.verification<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li></li></ol><h4 id="启动过程"><a href="#启动过程" class="headerlink" title="启动过程"></a>启动过程</h4><ol><li>首先启动hdfs：<code>start-dfs.sh</code></li><li>初始化metestore：<code>schematool --dbType mysql --initSchema</code></li><li>启动metastore service：<code>hive --service metastore</code></li><li>启动hive：<code>hive</code></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;配置过程&quot;&gt;&lt;a href=&quot;#配置过程&quot; class=&quot;headerlink&quot; title=&quot;配置过程&quot;&gt;&lt;/a&gt;配置过程&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;mysql&lt;/p&gt;
&lt;p&gt;安装&lt;/p&gt;
&lt;p&gt;配置可以远程连接&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;jdbc
      
    
    </summary>
    
      <category term="Hive学习" scheme="https://shang.at/categories/Hive%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Hive安装" scheme="https://shang.at/tags/Hive%E5%AE%89%E8%A3%85/"/>
    
  </entry>
  
  <entry>
    <title>数据库-mysql-环境配置</title>
    <link href="https://shang.at/post/%E6%95%B0%E6%8D%AE%E5%BA%93-mysql-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <id>https://shang.at/post/数据库-mysql-环境配置/</id>
    <published>2020-06-24T06:16:33.000Z</published>
    <updated>2020-06-24T07:15:44.507Z</updated>
    
    <content type="html"><![CDATA[<p>platform：MAC</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">brew istall mysql</span><br><span class="line"></span><br><span class="line">We've installed your MySQL database without a root password. To secure it run:</span><br><span class="line">    mysql_secure_installation</span><br><span class="line"></span><br><span class="line">MySQL is configured to only allow connections from localhost by default</span><br><span class="line"></span><br><span class="line">To connect run:</span><br><span class="line">    mysql -uroot</span><br><span class="line"></span><br><span class="line">To have launchd start mysql now and restart at login:</span><br><span class="line">  brew services start mysql</span><br><span class="line">Or, if you don't want/need a background service you can just run:</span><br><span class="line">  mysql.server start</span><br></pre></td></tr></table></figure><p>新安装的mysql，需要重置密码：</p><p>The initial root account may or may not have a password. Choose whichever of the following procedures applies:</p><ul><li><p>If the root account exists with an initial random password that has been expired, connect to the server as root using that password, then choose a new password. This is the case if the data directory was initialized using <a href="https://dev.mysql.com/doc/refman/8.0/en/mysqld.html" target="_blank" rel="noopener">mysqld –initialize</a>, either manually or using an installer that does not give you the option of specifying a password during the install operation. Because the password exists, you must use it to connect to the server. But because the password is expired, you cannot use the account for any purpose other than to choose a new password, until you do choose one.</p></li><li><ol><li>If you do not know the initial random password, look in the server error log.</li><li>Connect to the server as root using the password:</li></ol></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">shell&gt;</span> mysql -u root -p </span><br><span class="line">Enter password: (enter the random root password here)</span><br></pre></td></tr></table></figure><ul><li><ol><li>Choose a new password to replace the random password:</li></ol></li></ul><p>mysql&gt; ALTER USER ‘root‘@’localhost’ IDENTIFIED BY ‘root-password’;</p><ul><li><p>If the root account exists but has no password, connect to the server as root using no password, then assign a password. This is the case if you initialized the data directory using <a href="https://dev.mysql.com/doc/refman/8.0/en/mysqld.html" target="_blank" rel="noopener">mysqld –initialize-insecure</a>.</p></li><li><ol><li>Connect to the server as root using no password:</li></ol></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">shell&gt;</span> mysql -u root --skip-password</span><br></pre></td></tr></table></figure><ul><li><ol><li>Assign a password:</li></ol></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span> ALTER USER 'root'@'localhost' IDENTIFIED BY 'root-password';</span><br></pre></td></tr></table></figure><p>After assigning the root account a password, you must supply that password whenever you connect to the server using the account. For example, to connect to the server using the <a href="https://dev.mysql.com/doc/refman/8.0/en/mysql.html" target="_blank" rel="noopener">mysql</a> client, use this command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">shell&gt;</span> mysql -u root -p </span><br><span class="line">Enter password: (enter root password here)</span><br></pre></td></tr></table></figure><p>To shut down the server with <a href="https://dev.mysql.com/doc/refman/8.0/en/mysqladmin.html" target="_blank" rel="noopener">mysqladmin</a>, use this command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">shell&gt;</span> mysqladmin -u root -p shutdown </span><br><span class="line">Enter password: (enter root password here)</span><br></pre></td></tr></table></figure><h3 id="设置远程访问"><a href="#设置远程访问" class="headerlink" title="设置远程访问"></a>设置远程访问</h3><h5 id="设置my-cnf"><a href="#设置my-cnf" class="headerlink" title="设置my.cnf"></a>设置my.cnf</h5><p>使用brew 安装的mysql，my.cnf文件在<code>/usr/local/etc/my.cnf</code>，修改<code>bind-address为0.0.0.0</code>，然后重启<code>brew services restart mysql</code></p><h5 id="创建用户，赋予权限"><a href="#创建用户，赋予权限" class="headerlink" title="创建用户，赋予权限"></a>创建用户，赋予权限</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 登录mysql</span><br><span class="line">mysql -u root -p 123456</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 创建新用户</span><br><span class="line">create user 'hive' identified by 'hive1234';</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 授权</span><br><span class="line">grant all privileges on *.* to 'hive'@'%' with grant option;</span><br><span class="line"><span class="meta">#</span> *.* 前边的*号指的是数据库，后面的*号指的是表，*.*的意思就是任意数据库下的任意表</span><br><span class="line"><span class="meta">#</span> 'root'@'%'，'root'用户名，'%'任意的主机名。</span><br><span class="line"><span class="meta">#</span> 这条配置信息就是说，允许任意节点以root身份登录，并且可以访问mysql里的任意库下的任意表</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 刷新</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure><p>至此，便可以在其他host上访问mysql服务了。</p><h4 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a>其他问题</h4><ol><li>jar记得更新</li><li>server 时区</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;platform：MAC&lt;/p&gt;
&lt;h3 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h3&gt;&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=
      
    
    </summary>
    
      <category term="数据库" scheme="https://shang.at/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="mysql环境配置" scheme="https://shang.at/tags/mysql%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop学习-Shell脚本学习</title>
    <link href="https://shang.at/post/Hadoop%E5%AD%A6%E4%B9%A0-Shell%E8%84%9A%E6%9C%AC%E5%AD%A6%E4%B9%A0/"/>
    <id>https://shang.at/post/Hadoop学习-Shell脚本学习/</id>
    <published>2020-06-24T05:28:09.000Z</published>
    <updated>2020-06-24T05:28:38.353Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="Hadoop学习" scheme="https://shang.at/categories/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Hadoop-Shell" scheme="https://shang.at/tags/Hadoop-Shell/"/>
    
  </entry>
  
  <entry>
    <title>工具使用-iterm2</title>
    <link href="https://shang.at/post/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8-iterm2/"/>
    <id>https://shang.at/post/工具使用-iterm2/</id>
    <published>2020-06-23T10:30:55.000Z</published>
    <updated>2020-06-23T10:32:31.790Z</updated>
    
    <content type="html"><![CDATA[<h3 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">新建标签：command + t</span><br><span class="line">关闭标签：command + w</span><br><span class="line">切换标签：command + 数字 command + 左右方向键</span><br><span class="line">切换全屏：command + enter</span><br><span class="line">查找：command + f</span><br></pre></td></tr></table></figure><h3 id="分屏"><a href="#分屏" class="headerlink" title="分屏"></a>分屏</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">垂直分屏：command + d</span><br><span class="line">水平分屏：command + shift + d</span><br><span class="line">切换屏幕：command + option + 方向键 command + [ 或 command + ]</span><br><span class="line">查看历史命令：command + ;</span><br><span class="line">查看剪贴板历史：command + shift + h</span><br></pre></td></tr></table></figure><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">清除当前行：ctrl + u</span><br><span class="line">到行首：ctrl + a</span><br><span class="line">到行尾：ctrl + e</span><br><span class="line">前进后退：ctrl + f/b (相当于左右方向键)</span><br><span class="line">上一条命令：ctrl + p</span><br><span class="line">搜索命令历史：ctrl + r</span><br><span class="line">删除当前光标的字符：ctrl + d</span><br><span class="line">删除光标之前的字符：ctrl + h</span><br><span class="line">删除光标之前的单词：ctrl + w</span><br><span class="line">删除到文本末尾：ctrl + k</span><br><span class="line">交换光标处文本：ctrl + t</span><br><span class="line">清屏1：command + r</span><br><span class="line">清屏2：ctrl + l</span><br><span class="line">自带有哪些很实用的功能/快捷键</span><br><span class="line">⌘ + 数字在各 tab 标签直接来回切换</span><br><span class="line">选择即复制 + 鼠标中键粘贴，这个很实用</span><br><span class="line">⌘ + f 所查找的内容会被自动复制</span><br><span class="line">⌘ + d 横着分屏 / ⌘ + shift + d 竖着分屏</span><br><span class="line">⌘ + r = clear，而且只是换到新一屏，不会想 clear 一样创建一个空屏</span><br><span class="line">ctrl + u 清空当前行，无论光标在什么位置</span><br><span class="line">输入开头命令后 按 ⌘ + ; 会自动列出输入过的命令</span><br><span class="line">⌘ + shift + h 会列出剪切板历史</span><br><span class="line">可以在 Preferences &gt; keys 设置全局快捷键调出 iterm，这个也可以用过 Alfred 实现</span><br></pre></td></tr></table></figure><h3 id="常用的一些快捷键"><a href="#常用的一些快捷键" class="headerlink" title="常用的一些快捷键"></a>常用的一些快捷键</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">⌘ + 1 / 2 左右 tab 之间来回切换，这个在 前面 已经介绍过了</span><br><span class="line">⌘← / ⌘→ 到一行命令最左边/最右边 ，这个功能同 C+a / C+e</span><br><span class="line">⌥← / ⌥→ 按单词前移/后移，相当与 C+f / C+b，其实这个功能在Iterm中已经预定义好了，⌥f / ⌥b，看个人习惯了</span><br><span class="line">好像就这几个</span><br><span class="line"></span><br><span class="line">设置方法如下</span><br><span class="line">当然除了这些可以自定义的也不能忘了 linux 下那些好用的组合</span><br><span class="line">C+a / C+e 这个几乎在哪都可以使用</span><br><span class="line">C+p / !! 上一条命令</span><br><span class="line">C+k 从光标处删至命令行尾 (本来 C+u 是删至命令行首，但iterm中是删掉整行)</span><br><span class="line">C+w A+d 从光标处删至字首/尾</span><br><span class="line">C+h C+d 删掉光标前后的自负</span><br><span class="line">C+y 粘贴至光标后</span><br><span class="line">C+r 搜索命令历史，这个较常用</span><br></pre></td></tr></table></figure><h3 id="选中即复制"><a href="#选中即复制" class="headerlink" title="选中即复制"></a>选中即复制</h3><h4 id="iterm2-有-2-种好用的选中即复制模式。"><a href="#iterm2-有-2-种好用的选中即复制模式。" class="headerlink" title="iterm2 有 2 种好用的选中即复制模式。"></a>iterm2 有 2 种好用的选中即复制模式。</h4><ul><li>一种是用鼠标，在 iterm2 中，选中某个路径或者某个词汇，那么，iterm2 就自动复制了。 　　</li><li>另一种是无鼠标模式，<code>command+f</code>,弹出 iterm2 的查找模式，输入要查找并复制的内容的前几个字母，确认找到的是自己的内容之后，输入 <code>tab</code>，查找窗口将自动变化内容，并将其复制。如果输入的是 <code>shift+tab</code>，则自动将查找内容的左边选中并复制。</li></ul><h3 id="自动完成"><a href="#自动完成" class="headerlink" title="自动完成"></a>自动完成</h3><p>输入打头几个字母，然后输入 <code>command+</code>; iterm2 将自动列出之前输入过的类似命令。 　　</p><h3 id="剪切历史"><a href="#剪切历史" class="headerlink" title="剪切历史"></a>剪切历史</h3><p>输入 <code>command+shift+h</code>，iterm2 将自动列出剪切板的历史记录。如果需要将剪切板的历史记录保存到磁盘，在 <code>Preferences &gt; General &gt; Save copy/paste history to disk</code> 中设置。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;标签&quot;&gt;&lt;a href=&quot;#标签&quot; class=&quot;headerlink&quot; title=&quot;标签&quot;&gt;&lt;/a&gt;标签&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span 
      
    
    </summary>
    
      <category term="工具使用" scheme="https://shang.at/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"/>
    
    
      <category term="iterm2" scheme="https://shang.at/tags/iterm2/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop学习-源码编译</title>
    <link href="https://shang.at/post/Hadoop%E5%AD%A6%E4%B9%A0-%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/"/>
    <id>https://shang.at/post/Hadoop学习-源码编译/</id>
    <published>2020-06-23T10:18:16.000Z</published>
    <updated>2020-06-23T10:19:33.849Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="Hadoop学习" scheme="https://shang.at/categories/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Hadoop源码编译" scheme="https://shang.at/tags/Hadoop%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop学习-集群搭建</title>
    <link href="https://shang.at/post/Hadoop%E5%AD%A6%E4%B9%A0-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>https://shang.at/post/Hadoop学习-集群搭建/</id>
    <published>2020-06-23T10:17:38.000Z</published>
    <updated>2020-06-26T03:45:57.288Z</updated>
    
    <content type="html"><![CDATA[<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> hadoop.sh -&gt; /etc/profile.d/</span><br><span class="line">export HADOOP_PREFIX=/root/hadoop</span><br><span class="line">export HADOOP_YARN_HOME=$&#123;HADOOP_PREFIX&#125;</span><br><span class="line">export HADOOP_CONF_DIR=$&#123;HADOOP_PREFIX&#125;/etc/hadoop</span><br><span class="line">export YARN_LOG_DIR=$&#123;HADOOP_YARN_HOME&#125;/logs</span><br><span class="line">export YARN_IDENT_STRING=root</span><br><span class="line">export HADOOP_MAPRED_IDENT_STRING=root</span><br><span class="line">export PATH=$&#123;HADOOP_PREFIX&#125;/bin:$&#123;HADOOP_PREFIX&#125;/sbin:$&#123;PATH&#125;</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- core-site.xml -&gt; path_to_hadoop/etc/hadoop/ --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-common/core-default.xml --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node4:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///root/data/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">description</span>&gt;</span>A base for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- hdfs-site.xml -&gt; path_to_hadoop/etc/hadoop/ --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///root/data/hadoop/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///root/data/hadoop/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- config secondary namenode --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node3:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- enable webhdfs --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- disable permissions; only for development, of course --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.handler.count<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>5<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.handler.count<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>5<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- yarn-site.xml -&gt; path_to_hadoop/etc/hadoop/ --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- https://hadoop.apache.org/docs/r2.7.3/hadoop-yarn/hadoop-yarn-common/yarn-default.xml --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- enable log aggregation, this is false by default --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.timeline-service.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- mapred-site.xml -&gt; path_to_hadoop/etc/hadoop/ --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- https://hadoop.apache.org/docs/r2.7.3/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node3:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="启动流程"><a href="#启动流程" class="headerlink" title="启动流程"></a>启动流程</h2><p>Step1. 第一次启动HDFS，需要格式化一下hdfs</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span>HADOOP_PREFIX/bin/hdfs namenode -format &lt;cluster-name&gt;</span><br></pre></td></tr></table></figure><p>Step2. 启动</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">start-dfs</span>.sh</span><br><span class="line"><span class="built_in">start-yarn</span>.sh</span><br><span class="line">yarn<span class="literal">-daemon</span>.sh start proxyserver</span><br><span class="line">mr<span class="literal">-jobhistory</span><span class="literal">-daemon</span>.sh start historyserver</span><br></pre></td></tr></table></figure><h2 id="停止流程"><a href="#停止流程" class="headerlink" title="停止流程"></a>停止流程</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">stop-dfs.sh</span><br><span class="line">stop-yarn.sh</span><br><span class="line">yarn-daemon.sh stop proxyserver</span><br><span class="line">mr-jobhistory-daemon.sh stop historyserver</span><br></pre></td></tr></table></figure><h2 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h2><p>Once the Hadoop cluster is up and running check the web-ui of the components as described below:</p><table><thead><tr><th style="text-align:left">Daemon</th><th style="text-align:left">Web Interface</th><th style="text-align:left">Notes</th></tr></thead><tbody><tr><td style="text-align:left">NameNode</td><td style="text-align:left"><a href="http://nn_host:port/" target="_blank" rel="noopener">http://nn_host:port/</a></td><td style="text-align:left">Default HTTP port is 50070.</td></tr><tr><td style="text-align:left">SecondaryNameNode</td><td style="text-align:left"><a href="http://nn_host:port/" target="_blank" rel="noopener">http://nn_host:port/</a></td><td style="text-align:left">Default HTTP port is 50090.</td></tr><tr><td style="text-align:left">ResourceManager</td><td style="text-align:left"><a href="http://rm_host:port/" target="_blank" rel="noopener">http://rm_host:port/</a></td><td style="text-align:left">Default HTTP port is 8088.</td></tr><tr><td style="text-align:left">YarnWebProxy</td><td style="text-align:left"><a href="http://proxy_host:port/" target="_blank" rel="noopener">http://proxy_host:port/</a></td><td style="text-align:left">no Default HTTP port. 需要自定义</td></tr><tr><td style="text-align:left">MapReduce JobHistory Server</td><td style="text-align:left"><a href="http://jhs_host:port/" target="_blank" rel="noopener">http://jhs_host:port/</a></td><td style="text-align:left">Default HTTP port is 19888.</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;配置&quot;&gt;&lt;a href=&quot;#配置&quot; class=&quot;headerlink&quot; title=&quot;配置&quot;&gt;&lt;/a&gt;配置&lt;/h2&gt;&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span 
      
    
    </summary>
    
      <category term="Hadoop学习" scheme="https://shang.at/categories/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Hadoop集群搭建" scheme="https://shang.at/tags/Hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop学习-配置详解</title>
    <link href="https://shang.at/post/Hadoop%E5%AD%A6%E4%B9%A0-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/"/>
    <id>https://shang.at/post/Hadoop学习-配置详解/</id>
    <published>2020-06-23T09:12:52.000Z</published>
    <updated>2020-06-26T02:48:44.351Z</updated>
    
    <content type="html"><![CDATA[<p>版本：<a href="https://hadoop.apache.org/docs/r2.7.3/" target="_blank" rel="noopener">2.7.3</a></p><h3 id="core-default-xml"><a href="#core-default-xml" class="headerlink" title="core-default.xml"></a>core-default.xml</h3><table><thead><tr><th>parameter</th><th>default value</th><th>notes</th></tr></thead><tbody><tr><td><code>fs.defaultFS</code></td><td><code>file:///</code></td><td>定义<code>namenode</code>的URI，改成<code>hdfs://host:port/</code></td></tr><tr><td><code>hadoop.tmp.dir</code></td><td><code>/tmp/hadoop-${user.name}</code></td><td>定义其他临时目录的根目录</td></tr><tr><td><code>io.file.buffer.size</code></td><td><code>4096</code></td><td>读写文件操作时的缓存字节数，必须是硬件上的内存页大小的整数倍</td></tr></tbody></table><h3 id="hdfs-default-xml"><a href="#hdfs-default-xml" class="headerlink" title="hdfs-default.xml"></a>hdfs-default.xml</h3><h4 id="namenode"><a href="#namenode" class="headerlink" title="namenode"></a>namenode</h4><table><thead><tr><th>parameter</th><th>default value</th><th>note</th></tr></thead><tbody><tr><td><code>dfs.namenode.http(s)-address</code></td><td><code>0.0.0.0:50070(50470)</code></td><td>配置<code>dfs</code>的<code>web ui</code>界面，不建议修改。可以通过<code>http://namenode_hostname:50070</code>访问</td></tr><tr><td><code>dfs.namenode.name.dir</code></td><td><code>file://${hadoop.tmp.dir}/dfs/name</code></td><td>配置<code>DFS namenode</code>的<code>fsimage</code>文件存放在本次文件系统的路径。如果配置了使用逗号分隔的多个路径，那么namemode会在每个目录下面都冗余的存放一份。</td></tr><tr><td><code>dfs.namenode.edits.dir</code></td><td><code>dfs.namenode.name.dir</code></td><td>配置<code>DFS namenode</code>的<code>edits</code>文件存放在本次文件系统的路径。如果配置了使用逗号分隔的多个路径，那么namemode会在每个目录下面都冗余的存放一份。</td></tr><tr><td><code>dfs.namenode.fs-limits.min-block-size</code></td><td><code>1048576</code>  <code>1m</code></td><td>最小块大小（以字节为单位），由Namenode在创建时强制执行。这样可以防止意外创建具有很小块大小（因此有很多块）的文件，这会降低性能。减少数据块的数量，</td></tr><tr><td><code>dfs.namenode.handler.count</code></td><td><code>10</code></td><td>namenode端服务的线程数，测试时可以配置的小一些，减少内存占用</td></tr></tbody></table><h4 id="datanode"><a href="#datanode" class="headerlink" title="datanode"></a>datanode</h4><table><thead><tr><th>parameter</th><th>default value</th><th>notes</th></tr></thead><tbody><tr><td><code>dfs.datanode.data.dir</code></td><td><code>file://${hadoop.tmp.dir}/dfs/data</code></td><td>文件块的在<code>local filesystem</code>中的存放路径。如果提供的是逗号分隔的目录列表，那么数据将会存储在所有的目录中，(通常目录列表是在不同的设备上)。目录应该被相应的存储类型所标记(HDFS上有四种存储设备：SSD、DISK、ARCHIVE、RAM_DISK)，如果没有指定，默认是DISK。如果目录不存在，那么会自动创建(需要获取目录权限)</td></tr><tr><td><code>dfs.datanode.handler.count</code></td><td><code>10</code></td><td>namenode端服务的线程数，测试时可以配置的小一些，减少内存占用</td></tr></tbody></table><h4 id="secondary-namenode"><a href="#secondary-namenode" class="headerlink" title="secondary namenode"></a>secondary namenode</h4><table><thead><tr><th>parameter</th><th>default value</th><th>notes</th></tr></thead><tbody><tr><td><code>dfs.namenode.secondary.http(s)-address</code></td><td><code>0.0.0.0:50090(50091)</code></td><td>配置<code>secondary namenode</code>的http server和端口</td></tr><tr><td><code>dfs.namenode.checkpoint.dir</code></td><td><code>file://${hadoop.tmp.dir}/dfs/namesecondary</code></td><td></td></tr><tr><td><code>dfs.namenode.checkpoint.edits.dir</code></td><td><code>${dfs.namenode.checkpoint.dir}</code></td><td></td></tr><tr><td><code>dfs.namenode.checkpoint.period</code></td><td><code>3600</code></td><td></td></tr><tr><td><code>dfs.namenode.checkpoint.txns</code></td><td><code>1000000</code></td><td></td></tr><tr><td><code>dfs.namenode.checkpoint.check.period</code></td><td><code>60</code></td><td></td></tr><tr><td><code>dfs.namenode.checkpoint.max-retries</code></td><td><code>3</code></td><td></td></tr><tr><td><code>dfs.namenode.num.checkpoints.retained</code></td><td><code>2</code></td></tr></tbody></table><h4 id="dfs"><a href="#dfs" class="headerlink" title="dfs"></a>dfs</h4><table><thead><tr><th>parameter</th><th>default value</th><th>notes</th></tr></thead><tbody><tr><td><code>dfs.permissions.enabled</code></td><td><code>true</code></td><td>配置是否启用权限检查，默认是启用的。测试时可以设置为false。当开启状态时，dfs不会检测文件的权限检测。<a href="https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/HdfsPermissionsGuide.html" target="_blank" rel="noopener">HDFS Permission</a>HDFS默认启动namenode的user为superuser，这个</td></tr><tr><td><code>dfs.blocksize</code></td><td><code>134217728</code>  <code>128m</code></td><td>单位字节，新文件的block 大小</td></tr><tr><td><code>dfs.hosts</code> / <code>dfs.hosts.exclude</code></td><td></td><td>List of permitted/excluded DataNodes.If necessary, use these files to control the list of allowable datanodes.</td></tr><tr><td><code>dfs.replication</code></td><td><code>3</code></td><td>块副本数</td></tr><tr><td><code>dfs.webhdfs.enabled</code></td><td><code>true</code></td><td>启动namenode和datanode上的WebHHDFS(REST API)</td></tr></tbody></table><h3 id="mapred-default-xml"><a href="#mapred-default-xml" class="headerlink" title="mapred-default.xml"></a>mapred-default.xml</h3><h4 id="MapReduce-Applications"><a href="#MapReduce-Applications" class="headerlink" title="MapReduce Applications"></a>MapReduce Applications</h4><table><thead><tr><th style="text-align:left">Parameter</th><th style="text-align:left">Value</th><th style="text-align:left">Notes</th></tr></thead><tbody><tr><td style="text-align:left"><code>mapreduce.framework.name</code></td><td style="text-align:left"><code>yarn</code></td><td style="text-align:left">Execution framework set to Hadoop YARN.</td></tr><tr><td style="text-align:left"><code>mapreduce.map.memory.mb</code></td><td style="text-align:left"><code>1536</code></td><td style="text-align:left">Larger resource limit for maps.</td></tr><tr><td style="text-align:left"><code>mapreduce.map.java.opts</code></td><td style="text-align:left"><code>-Xmx1024M</code></td><td style="text-align:left">Larger heap-size for child jvms of maps.</td></tr><tr><td style="text-align:left"><code>mapreduce.reduce.memory.mb</code></td><td style="text-align:left"><code>3072</code></td><td style="text-align:left">Larger resource limit for reduces.</td></tr><tr><td style="text-align:left"><code>mapreduce.reduce.java.opts</code></td><td style="text-align:left"><code>-Xmx2560M</code></td><td style="text-align:left">Larger heap-size for child jvms of reduces.</td></tr><tr><td style="text-align:left"><code>mapreduce.task.io.sort.mb</code></td><td style="text-align:left"><code>100</code></td><td style="text-align:left">Higher memory-limit while sorting data for efficiency.</td></tr><tr><td style="text-align:left"><code>mapreduce.task.io.sort.factor</code></td><td style="text-align:left"><code>10</code></td><td style="text-align:left">More streams merged at once while sorting files.</td></tr><tr><td style="text-align:left"><code>mapreduce.reduce.shuffle.parallelcopies</code></td><td style="text-align:left"><code>5</code></td><td style="text-align:left">Higher number of parallel copies run by reduces to fetch outputs from very large number of maps.</td></tr></tbody></table><h4 id="MapReduce-JobHistory-Server"><a href="#MapReduce-JobHistory-Server" class="headerlink" title="MapReduce JobHistory Server"></a>MapReduce JobHistory Server</h4><table><thead><tr><th style="text-align:left">Parameter</th><th style="text-align:left">Value</th><th style="text-align:left">Notes</th></tr></thead><tbody><tr><td style="text-align:left"><code>mapreduce.jobhistory.address</code></td><td style="text-align:left"><code>0.0.0.0:10020</code></td><td style="text-align:left">MapReduce JobHistory Server IPC host:port</td></tr><tr><td style="text-align:left"><code>mapreduce.jobhistory.webapp.address</code></td><td style="text-align:left"><code>0.0.0.0:19888</code></td><td style="text-align:left">MapReduce JobHistory Server Web UI host:port</td></tr><tr><td style="text-align:left"><code>yarn.app.mapreduce.am.staging-dir</code></td><td style="text-align:left"><code>/tmp/hadoop-yarn/staging</code></td><td style="text-align:left">The staging dir used while submitting jobs.</td></tr><tr><td style="text-align:left"><code>mapreduce.jobhistory.intermediate-done-dir</code></td><td style="text-align:left"><code>${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate</code></td><td style="text-align:left">Directory where history files are written by MapReduce jobs.</td></tr><tr><td style="text-align:left"><code>mapreduce.jobhistory.done-dir</code></td><td style="text-align:left"><code>${yarn.app.mapreduce.am.staging-dir}/history/done</code></td><td style="text-align:left">Directory where history files are managed by the MR JobHistory Server.</td></tr></tbody></table><h3 id="yarn-default-xml"><a href="#yarn-default-xml" class="headerlink" title="yarn-default.xml"></a>yarn-default.xml</h3><h4 id="ResourceManager-and-NodeManager"><a href="#ResourceManager-and-NodeManager" class="headerlink" title="ResourceManager and NodeManager"></a>ResourceManager and NodeManager</h4><table><thead><tr><th style="text-align:left">Parameter</th><th style="text-align:left">default Value</th><th style="text-align:left">Notes</th></tr></thead><tbody><tr><td style="text-align:left"><code>yarn.acl.enable</code></td><td style="text-align:left"><code>false</code></td><td style="text-align:left">是否开启ACLs</td></tr><tr><td style="text-align:left"><code>yarn.admin.acl</code></td><td style="text-align:left"><code>*</code></td><td style="text-align:left">ACL to set admins on the cluster. ACLs are of for <em>comma-separated-usersspacecomma-separated-groups</em>. Defaults to special value of <strong>*</strong> which means <em>anyone</em>. Special value of just <em>space</em> means no one has access.</td></tr><tr><td style="text-align:left"><code>yarn.log-aggregation-enable</code></td><td style="text-align:left"><code>false</code></td><td style="text-align:left">是否启动日志聚合。日志聚合会收集每个container的日志并且在应用完成后将他们移动到HDFS中。具体目录由下面两个选项配置<code>yarn.nodemanager.remote-app-log-dir</code>和<code>yarn.nodemanager.remote-app-log-dir-suffix</code>。用户可以通过<code>Application Timeline Server</code>访问这些日志文件</td></tr></tbody></table><h4 id="ResourceManager"><a href="#ResourceManager" class="headerlink" title="ResourceManager"></a>ResourceManager</h4><table><thead><tr><th style="text-align:left">Parameter</th><th style="text-align:left">default Value</th><th style="text-align:left">Notes</th></tr></thead><tbody><tr><td style="text-align:left"><code>yarn.resourcemanager.address</code></td><td style="text-align:left"><code>${yarn.resourcemanager.hostname}:8032</code></td><td style="text-align:left">配置RM的URI<br>for clients to submit jobs.</td></tr><tr><td style="text-align:left"><code>yarn.resourcemanager.scheduler.address</code></td><td style="text-align:left"><code>${yarn.resourcemanager.hostname}:8030</code></td><td style="text-align:left">资源调度器URI<br>for ApplicationMasters to talk to Scheduler to obtain resources.</td></tr><tr><td style="text-align:left"><code>yarn.resourcemanager.resource-tracker.address</code></td><td style="text-align:left"><code>${yarn.resourcemanager.hostname}:8031</code></td><td style="text-align:left">for NodeManagers.</td></tr><tr><td style="text-align:left"><code>yarn.resourcemanager.admin.address</code></td><td style="text-align:left"><code>${yarn.resourcemanager.hostname}:8033</code></td><td style="text-align:left">for administrative commands.</td></tr><tr><td style="text-align:left"><code>yarn.resourcemanager.webapp.address</code></td><td style="text-align:left"><code>${yarn.resourcemanager.hostname}:8088</code></td><td style="text-align:left">RM web application</td></tr><tr><td style="text-align:left"><code>yarn.resourcemanager.hostname</code></td><td style="text-align:left"><code>0.0.0.0</code></td><td style="text-align:left"><code>ResourceManager</code> host.应该改成特定的hostname</td></tr><tr><td style="text-align:left"><code>yarn.web-proxy.address</code></td><td style="text-align:left">默认没有配置，会作为RM的一部分运行</td><td style="text-align:left">The address for the web proxy as HOST:PORT, if this is not given then the proxy will run as part of the RM</td></tr><tr><td style="text-align:left"><code>yarn.resourcemanager.scheduler.class</code></td><td style="text-align:left"><code>org.apache.hadoop.yarn.server.resourcemanager.&lt;br /&gt;scheduler.capacity.CapacityScheduler</code></td><td style="text-align:left">指定RM使用的调度器：<code>CapacityScheduler</code> (recommended), <code>FairScheduler</code> (also recommended), or <code>FifoScheduler</code></td></tr><tr><td style="text-align:left"><code>yarn.scheduler.minimum-allocation-mb</code></td><td style="text-align:left"><code>1024</code></td><td style="text-align:left">In MBs，Minimum limit of memory to allocate to each container request at the <code>ResourceManager</code>.</td></tr><tr><td style="text-align:left"><code>yarn.scheduler.maximum-allocation-mb</code></td><td style="text-align:left"><code>8192</code></td><td style="text-align:left">In MBs，Maximum limit of memory to allocate to each container request at the <code>Resource Manager</code>.</td></tr><tr><td style="text-align:left"><code>yarn.resourcemanager.nodes.include-path</code> / <code>yarn.resourcemanager.nodes.exclude-path</code></td><td style="text-align:left"></td><td style="text-align:left">List of permitted/excluded NodeManagers.If necessary, use these files to control the list of allowable NodeManagers.</td></tr></tbody></table><h4 id="NodeManager"><a href="#NodeManager" class="headerlink" title="NodeManager"></a>NodeManager</h4><table><thead><tr><th style="text-align:left">Parameter</th><th style="text-align:left">default Value</th><th style="text-align:left">Notes</th></tr></thead><tbody><tr><td style="text-align:left"><code>yarn.nodemanager.resource.memory-mb</code></td><td style="text-align:left"><code>8192</code></td><td style="text-align:left">Resource i.e. available physical memory, in MB, for given <code>NodeManager</code>.Defines total available resources on the <code>NodeManager</code> to be made available to running containers</td></tr><tr><td style="text-align:left"><code>yarn.nodemanager.vmem-pmem-ratio</code></td><td style="text-align:left"><code>2.1</code><br>Maximum ratio by which virtual memory usage of tasks may exceed physical memory</td><td style="text-align:left">The virtual memory usage of each task may exceed its physical memory limit by this ratio. The total amount of virtual memory used by tasks on the NodeManager may exceed its physical memory usage by this ratio.</td></tr><tr><td style="text-align:left"><code>yarn.nodemanager.local-dirs</code></td><td style="text-align:left"><code>${hadoop.tmp.dir}/nm-local-dir</code><br>Comma-separated list of paths on the local filesystem where intermediate data is written.</td><td style="text-align:left">Multiple paths help spread disk i/o.</td></tr><tr><td style="text-align:left"><code>yarn.nodemanager.log-dirs</code></td><td style="text-align:left"><code>${yarn.log.dir}/userlogs</code><br>Comma-separated list of paths on the local filesystem where logs are written.</td><td style="text-align:left">Multiple paths help spread disk i/o.</td></tr><tr><td style="text-align:left"><code>yarn.nodemanager.log.retain-seconds</code></td><td style="text-align:left"><em>10800</em></td><td style="text-align:left">Default time (in seconds) to retain log files on the NodeManager. Only applicable if log-aggregation is disabled.</td></tr><tr><td style="text-align:left"><code>yarn.nodemanager.remote-app-log-dir</code></td><td style="text-align:left"><code>/tmp/logs</code></td><td style="text-align:left">HDFS directory where the application logs are moved on application completion. Need to set appropriate permissions. Only applicable if log-aggregation is enabled.</td></tr><tr><td style="text-align:left"><code>yarn.nodemanager.remote-app-log-dir-suffix</code></td><td style="text-align:left"><code>logs</code></td><td style="text-align:left">Suffix appended to the remote log dir. Logs will be aggregated to <code>${yarn.nodemanager.remote-app-log-dir}/${user}/${thisParam}</code> Only applicable if log-aggregation is enabled.</td></tr><tr><td style="text-align:left"><code>yarn.nodemanager.aux-services</code></td><td style="text-align:left"><code>mapreduce_shuffle</code></td><td style="text-align:left">Shuffle service that needs to be set for Map Reduce applications.</td></tr></tbody></table><h4 id="History-Server-Needs-to-be-moved-elsewhere"><a href="#History-Server-Needs-to-be-moved-elsewhere" class="headerlink" title="History Server (Needs to be moved elsewhere)"></a>History Server (Needs to be moved elsewhere)</h4><table><thead><tr><th style="text-align:left">Parameter</th><th style="text-align:left">default Value</th><th style="text-align:left">Notes</th></tr></thead><tbody><tr><td style="text-align:left"><code>yarn.log-aggregation.retain-seconds</code></td><td style="text-align:left"><code>-1</code></td><td style="text-align:left">How long to keep aggregation logs before deleting them. -1 disables. Be careful, set this too small and you will spam the name node.</td></tr><tr><td style="text-align:left"><code>yarn.log-aggregation.retain-check-interval-seconds</code></td><td style="text-align:left"><code>-1</code></td><td style="text-align:left">Time between checks for aggregated log retention. If set to 0 or a negative value then the value is computed as one-tenth of the aggregated log retention time. Be careful, set this too small and you will spam the name node.</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;版本：&lt;a href=&quot;https://hadoop.apache.org/docs/r2.7.3/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;2.7.3&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;core-default-xml&quot;&gt;&lt;a href=&quot;#core
      
    
    </summary>
    
      <category term="Hadoop学习" scheme="https://shang.at/categories/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Hadoop配置详解" scheme="https://shang.at/tags/Hadoop%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/"/>
    
  </entry>
  
  <entry>
    <title>Shell编程-常用命令</title>
    <link href="https://shang.at/post/Shell%E7%BC%96%E7%A8%8B-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>https://shang.at/post/Shell编程-常用命令/</id>
    <published>2020-06-23T08:53:17.000Z</published>
    <updated>2020-06-24T05:12:06.667Z</updated>
    
    <content type="html"><![CDATA[<h4 id="文本编辑"><a href="#文本编辑" class="headerlink" title="文本编辑"></a>文本编辑</h4><h5 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h5><h5 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h5><h4 id="Linux上的定时器"><a href="#Linux上的定时器" class="headerlink" title="Linux上的定时器"></a>Linux上的定时器</h4><h5 id="cron"><a href="#cron" class="headerlink" title="cron"></a>cron</h5><h4 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h4><h5 id="xargs"><a href="#xargs" class="headerlink" title="xargs"></a>xargs</h5><h5 id="exec"><a href="#exec" class="headerlink" title="exec"></a>exec</h5><h4 id="远程控制"><a href="#远程控制" class="headerlink" title="远程控制"></a>远程控制</h4><h5 id="ssh"><a href="#ssh" class="headerlink" title="ssh"></a>ssh</h5><h5 id="scp"><a href="#scp" class="headerlink" title="scp"></a>scp</h5><h5 id="rsync"><a href="#rsync" class="headerlink" title="rsync"></a>rsync</h5><h4 id="软件管理"><a href="#软件管理" class="headerlink" title="软件管理"></a>软件管理</h4><h5 id="rpm"><a href="#rpm" class="headerlink" title="rpm"></a>rpm</h5>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;文本编辑&quot;&gt;&lt;a href=&quot;#文本编辑&quot; class=&quot;headerlink&quot; title=&quot;文本编辑&quot;&gt;&lt;/a&gt;文本编辑&lt;/h4&gt;&lt;h5 id=&quot;sed&quot;&gt;&lt;a href=&quot;#sed&quot; class=&quot;headerlink&quot; title=&quot;sed&quot;&gt;&lt;/a&gt;se
      
    
    </summary>
    
      <category term="Shell编程" scheme="https://shang.at/categories/Shell%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="常见命令" scheme="https://shang.at/tags/%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>操作系统-centos7修改hostname</title>
    <link href="https://shang.at/post/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-centos7%E4%BF%AE%E6%94%B9hostname/"/>
    <id>https://shang.at/post/操作系统-centos7修改hostname/</id>
    <published>2020-06-23T04:31:11.000Z</published>
    <updated>2020-06-23T04:36:45.901Z</updated>
    
    <content type="html"><![CDATA[<p>在CentOS7中，有三种定义的主机名:静态的（static）、瞬态的（transient）、灵活的（pretty）。“静态”主机名也称为内核主机名，是系统在启动时从/etc/hostname自动初始化的主机名。“瞬态”主机名是在系统运行时临时分配的主机名，例如，通过DHCP或mDNS服务器分配。静态主机名和瞬态主机名都遵从作为互联网域名同样的字符限制规则。而另一方面，“灵活”主机名则允许使用自由形式（包括特殊/空白字符）的主机名，以展示给终端用户。</p><h4 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@Geeklp201 ~]# hostnamectl   #查看一下当前主机名的情况</span><br><span class="line">   Static hostname: Geeklp201</span><br><span class="line">         Icon name: computer-vm</span><br><span class="line">           Chassis: vm</span><br><span class="line">        Machine ID: 77efa27de81d470883b5bb0ed04f468c</span><br><span class="line">           Boot ID: fa62bd1c0f5e4e53a0691fb97971594f</span><br><span class="line">    Virtualization: vmware</span><br><span class="line">  Operating System: CentOS Linux 7 (Core)</span><br><span class="line">       CPE OS Name: cpe:/o:centos:centos:7</span><br><span class="line">            Kernel: Linux 3.10.0-693.el7.x86_64</span><br><span class="line">      Architecture: x86-64</span><br><span class="line">[root@Geeklp201 ~]# hostnamectl set-hostname geeklp --static</span><br><span class="line">[root@Geeklp201 ~]# hostnamectl status</span><br><span class="line">   Static hostname: geeklp</span><br><span class="line">   Pretty hostname: Geeklp201</span><br><span class="line">         Icon name: computer-vm</span><br><span class="line">           Chassis: vm</span><br><span class="line">        Machine ID: 77efa27de81d470883b5bb0ed04f468c</span><br><span class="line">           Boot ID: fa62bd1c0f5e4e53a0691fb97971594f</span><br><span class="line">    Virtualization: vmware</span><br><span class="line">  Operating System: CentOS Linux 7 (Core)</span><br><span class="line">       CPE OS Name: cpe:/o:centos:centos:7</span><br><span class="line">            Kernel: Linux 3.10.0-693.el7.x86_64</span><br><span class="line">      Architecture: x86-64</span><br><span class="line"></span><br><span class="line">重启VM</span><br></pre></td></tr></table></figure><h4 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h4><p>通过修改文件/etc/hostname来实现主机名的修改。把该文件内容替换成自己想要的主机名重启即可。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在CentOS7中，有三种定义的主机名:静态的（static）、瞬态的（transient）、灵活的（pretty）。“静态”主机名也称为内核主机名，是系统在启动时从/etc/hostname自动初始化的主机名。“瞬态”主机名是在系统运行时临时分配的主机名，例如，通过DHC
      
    
    </summary>
    
    
      <category term="centos7修改hostname" scheme="https://shang.at/tags/centos7%E4%BF%AE%E6%94%B9hostname/"/>
    
  </entry>
  
  <entry>
    <title>工具使用-vim</title>
    <link href="https://shang.at/post/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8-vim/"/>
    <id>https://shang.at/post/工具使用-vim/</id>
    <published>2020-06-23T04:22:22.000Z</published>
    <updated>2020-06-23T04:29:27.472Z</updated>
    
    <content type="html"><![CDATA[<h4 id="vim快捷键"><a href="#vim快捷键" class="headerlink" title="vim快捷键"></a>vim快捷键</h4><ul><li><p>命令模式：<code>esc</code></p></li><li><p>编辑模式：</p><ul><li>在当前字符前开始编辑：命令模式下按<code>i</code></li><li>在当前字符后开始编辑：命令模式下按<code>a</code></li><li>另起一行：命令模式下按<code>o</code></li></ul></li><li><p>复制</p><ul><li>单行复制 在命令模式下，将光标移动到将要复制的行处，按“yy”进行复制，将光标移动到将要粘贴的行处，按“p”进行粘贴； </li><li>多行复制 在命令模式下，将光标移动到将要复制的首行处，按“nyy”复制n行；其中n为1、2、3…… 2、粘贴 在命令模式下，将光标移动到将要粘贴的行处，按“p”进行粘贴</li></ul></li></ul><h4 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h4><ul><li><p>输入： <code>/abc</code>     查询 abc 开头的单词</p><p>之后，所以以abc开头的单词都会标记高亮，输入 <code>n</code>  会查找下一个结果</p></li><li><p><code>?pattern</code> 向上搜索<code>#</code>继续搜索上一个</p></li></ul><h4 id="查看"><a href="#查看" class="headerlink" title="查看"></a>查看</h4><ul><li><p>暂时显示/取消行号：</p><p>使用Vim打开文件后，在Normal模式下输入</p><p><code>:set number</code>（或 <code>:set nu</code>）显示行号</p><p><code>:set nonumber</code> （或 <code>:set nonu</code>）取消行号</p></li><li><p>永久显示行号</p><p>查找Vim设定文件 </p><p><code>sudo find / -name vimrc</code></p><p>修改Vim设定文件 <code>/etc/vimrc</code> ,末尾添加</p><p><code>set number （或 set nu）</code></p><p>保存即可。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;vim快捷键&quot;&gt;&lt;a href=&quot;#vim快捷键&quot; class=&quot;headerlink&quot; title=&quot;vim快捷键&quot;&gt;&lt;/a&gt;vim快捷键&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;命令模式：&lt;code&gt;esc&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;编辑模式：&lt;
      
    
    </summary>
    
      <category term="工具使用" scheme="https://shang.at/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"/>
    
    
      <category term="vim" scheme="https://shang.at/tags/vim/"/>
    
  </entry>
  
  <entry>
    <title>大数据-常见端口</title>
    <link href="https://shang.at/post/%E5%A4%A7%E6%95%B0%E6%8D%AE-%E5%B8%B8%E8%A7%81%E7%AB%AF%E5%8F%A3/"/>
    <id>https://shang.at/post/大数据-常见端口/</id>
    <published>2020-06-21T01:17:50.000Z</published>
    <updated>2020-06-23T07:50:07.013Z</updated>
    
    <content type="html"><![CDATA[<ul><li>mysql：3306</li><li>redis：</li><li>zookeeper：2181</li><li>kafka：9092<ul><li>eagle：8048</li></ul></li><li>hdfs：50070</li><li>yarn：8088</li><li>spark：4041</li><li>flink：8081</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;mysql：3306&lt;/li&gt;
&lt;li&gt;redis：&lt;/li&gt;
&lt;li&gt;zookeeper：2181&lt;/li&gt;
&lt;li&gt;kafka：9092&lt;ul&gt;
&lt;li&gt;eagle：8048&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;hdfs：50070&lt;/li&gt;
&lt;li&gt;
      
    
    </summary>
    
      <category term="大数据生态" scheme="https://shang.at/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/"/>
    
    
      <category term="大数据端口" scheme="https://shang.at/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AB%AF%E5%8F%A3/"/>
    
  </entry>
  
  <entry>
    <title>大数据-环境配置</title>
    <link href="https://shang.at/post/%E5%A4%A7%E6%95%B0%E6%8D%AE-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <id>https://shang.at/post/大数据-环境配置/</id>
    <published>2020-06-20T10:01:00.000Z</published>
    <updated>2020-06-22T08:51:19.705Z</updated>
    
    <content type="html"><![CDATA[<h5 id="linux的文件和目录的权限规则"><a href="#linux的文件和目录的权限规则" class="headerlink" title="linux的文件和目录的权限规则"></a>linux的文件和目录的权限规则</h5><p>使用<code>ls -l</code>命令可以查看当前目录的文件列表以及权限信息，显示如下</p><p>drwxr-xr-x</p><h5 id="linux安装rpm包"><a href="#linux安装rpm包" class="headerlink" title="linux安装rpm包"></a>linux安装rpm包</h5><h5 id="免密登录"><a href="#免密登录" class="headerlink" title="免密登录"></a>免密登录</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 生成密钥 公钥</span><br><span class="line">sudo ssh-keygen -t rsa -f ~/.ssh/id_rsa</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 将公钥拷贝到目标机器</span><br><span class="line">ssh-copy-id user@tartget_hostame</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 这样之后就可以在节点之间 免密登录了</span><br><span class="line">ssh user@tartget_hostame</span><br><span class="line">ssh tartget_hostame # 如果当前登录的用户和target的用户名一致，则不需要加user@</span><br></pre></td></tr></table></figure><p>注意，如果执行ssh-copy-id 输入密码后仍报错(<code>Permission denied (publickey,gssapi-keyex,gssapi-with-mic)</code>)，可以尝试按照如下方案解决：</p><p>进入target机器，进入<code>cd /etc/ssh/sshd_config</code>，然后修改为<code>PasswordAuthentication yes</code>，最后重启sshd服务<code>service sshd restart</code>即可</p><h5 id="同步时钟"><a href="#同步时钟" class="headerlink" title="同步时钟"></a>同步时钟</h5><p>ntpdate cn.pool.ntp.org | ntp[1-7].aliyun.com</p><p>clock -w</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;linux的文件和目录的权限规则&quot;&gt;&lt;a href=&quot;#linux的文件和目录的权限规则&quot; class=&quot;headerlink&quot; title=&quot;linux的文件和目录的权限规则&quot;&gt;&lt;/a&gt;linux的文件和目录的权限规则&lt;/h5&gt;&lt;p&gt;使用&lt;code&gt;ls -l&lt;
      
    
    </summary>
    
      <category term="大数据生态" scheme="https://shang.at/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/"/>
    
    
      <category term="大数据环境" scheme="https://shang.at/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%8E%AF%E5%A2%83/"/>
    
  </entry>
  
  <entry>
    <title>虚拟机-Vagrant使用</title>
    <link href="https://shang.at/post/%E8%99%9A%E6%8B%9F%E6%9C%BA-Vagrant%E4%BD%BF%E7%94%A8/"/>
    <id>https://shang.at/post/虚拟机-Vagrant使用/</id>
    <published>2020-06-20T03:48:16.000Z</published>
    <updated>2020-06-22T10:44:18.634Z</updated>
    
    <content type="html"><![CDATA[<h4 id="什么是Vagrant"><a href="#什么是Vagrant" class="headerlink" title="什么是Vagrant"></a>什么是Vagrant</h4><p>vagrant是一个基于VirtualBox, VMware, AWS等平台的一个构造和管理VM的工具，它提供了一个简单的工作流程，让VM的创建和管理全都自动化。vagrant的配置是基于ruby的</p><p>Vagrant是基于Box的，Box是针对Vagrant运行环境的封装</p><h4 id="如何使用Vagrant"><a href="#如何使用Vagrant" class="headerlink" title="如何使用Vagrant"></a>如何使用Vagrant</h4><p>Step 1：安装</p><p>官网：<a href="https://www.vagrantup.com" target="_blank" rel="noopener">https://www.vagrantup.com</a></p><p>Step 2：初始化环境</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir vm-workspace</span><br><span class="line">cd vm-workspace</span><br><span class="line">vagrant init</span><br></pre></td></tr></table></figure><p>Step 3：配置Vagrantfile</p><blockquote><p>经过vagrant init之后，会在vm-workspace下生成一个Vagrantfile，内容如下(删除了注释)</p></blockquote><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- mode: ruby -*-</span></span><br><span class="line"><span class="comment"># vi: set ft=ruby :</span></span><br><span class="line">Vagrant.configure(<span class="string">"2"</span>) <span class="keyword">do</span> <span class="params">|config|</span></span><br><span class="line">  config.vm.box = <span class="string">"centos/7"</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>配置文件简介：</p><ul><li>2 是指当前配置的Vagrant config的版本，目前Vagrant只支持两个版本 1和2，这里我不用改，用2就可以</li><li>config 就是配置对象，我们可以对他进行配置</li><li>do … end 是ruby的语法，就是一个代码块</li></ul><p>下面是创建了</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- mode: ruby -*-</span></span><br><span class="line"><span class="comment"># vi: set ft=ruby :</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 指定了配置的版本</span></span><br><span class="line">Vagrant.configure(<span class="string">"2"</span>) <span class="keyword">do</span> <span class="params">|config|</span></span><br><span class="line">  <span class="comment"># 指定 box为 centos/7</span></span><br><span class="line">  config.vm.box = <span class="string">"centos/7"</span></span><br><span class="line">  <span class="comment"># 使用define定义vm的配置节点：一个配置节点就是一个虚拟机。</span></span><br><span class="line">  <span class="comment"># 这里表示：在config中配置一个master的vm，该vm的配置对象命名为master，下面可以对该配置进行配置</span></span><br><span class="line">  config.vm.define <span class="symbol">:master</span> <span class="keyword">do</span> <span class="params">|master|</span></span><br><span class="line">    <span class="comment"># 配置master的hostname为master</span></span><br><span class="line">    master.vm.hostname = <span class="string">"master"</span></span><br><span class="line">    <span class="comment"># 定义 虚机容器提供者配置，这里使用virtualbox。打开virtualbox后，可以在里面看到对应的vm实例</span></span><br><span class="line">    master.vm.provider <span class="symbol">:virtualbox</span> <span class="keyword">do</span> <span class="params">|v|</span></span><br><span class="line">      v.name = <span class="string">"master"</span>  <span class="comment"># vm的名称</span></span><br><span class="line">      v.memory = <span class="number">1024</span>    <span class="comment"># vm的内存</span></span><br><span class="line">      v.cpus = <span class="number">1</span>         <span class="comment"># vm可以使用的CPU个数</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="comment"># 配置master vm使用host-only网络模式，ip为10.211.55.100</span></span><br><span class="line">    master.vm.network <span class="symbol">:private_network</span>, <span class="symbol">ip:</span> <span class="string">"10.211.55.100"</span></span><br><span class="line">    <span class="comment"># 配置vagrant 启动vm的时候，需要执行的命令或脚本</span></span><br><span class="line">    <span class="comment"># master.vm.provision :shell, path: "bootstrap_master.sh"</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 再次循环给vm创建3个配置节点，即再创建3个虚拟机</span></span><br><span class="line">  (<span class="number">1</span>..<span class="number">3</span>).each <span class="keyword">do</span> <span class="params">|i|</span></span><br><span class="line">    config.vm.define <span class="string">"node<span class="subst">#&#123;i&#125;</span>"</span> <span class="keyword">do</span> <span class="params">|node|</span></span><br><span class="line">      node.vm.hostname = <span class="string">"node<span class="subst">#&#123;i&#125;</span>"</span></span><br><span class="line">      node.vm.provider <span class="symbol">:virtualbox</span> <span class="keyword">do</span> <span class="params">|v|</span></span><br><span class="line">        v.name = <span class="string">"node<span class="subst">#&#123;i&#125;</span>"</span></span><br><span class="line">        v.memory = <span class="number">1024</span></span><br><span class="line">        v.cpus = <span class="number">1</span></span><br><span class="line">      <span class="keyword">end</span></span><br><span class="line">      node.vm.network <span class="symbol">:private_network</span>, <span class="symbol">ip:</span> <span class="string">"10.211.55.10<span class="subst">#&#123;i&#125;</span>"</span></span><br><span class="line">      <span class="comment"># node.vm.provision :shell, path: "bootstrap_master.sh"</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># config.vm.synced_folder "" ""  # vagrant默认会把当前工作目录挂载在vm的/vagrant目录下</span></span><br><span class="line">  config.vm.provision <span class="symbol">:shell</span>, <span class="symbol">path:</span> <span class="string">"bootstrap.sh"</span></span><br><span class="line">  config.vm.provision <span class="symbol">:shell</span>, <span class="symbol">path:</span> <span class="string">"sshd.sh"</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> bootstrap.sh:虚拟机初始化的过程，并且配置java、sshkey、hosts</span><br><span class="line">sudo yum -y update</span><br><span class="line">sudo yum -y upgrade</span><br><span class="line">sudo yum groupinstall -y development</span><br><span class="line">sudo yum install -y java-1.8.0-openjdk net-tools rsync mlocate wget vim \</span><br><span class="line">gcc zlib-dev openssl-devel sqlite-devel bzip2-devel python-devel</span><br><span class="line"><span class="meta">#</span> set Java</span><br><span class="line">echo 'export JAVA_HOME=/usr/lib/jvm/jre' &gt;&gt; /etc/profile.d/java.sh</span><br><span class="line">echo 'export PATH=/usr/lib/jvm/jre/bin:$PATH' &gt;&gt; /etc/profile.d/java.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> sshkey</span><br><span class="line">sudo ssh-keygen -t rsa -f ~/.ssh/id_rsa</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> set hosts</span><br><span class="line">echo '10.211.55.100 node0' &gt;&gt; /etc/hosts</span><br><span class="line">echo '10.211.55.101 node1' &gt;&gt; /etc/hosts</span><br><span class="line">echo '10.211.55.102 node2' &gt;&gt; /etc/hosts</span><br><span class="line">echo '10.211.55.102 node3' &gt;&gt; /etc/hosts</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> sshd.sh: centos/7下的ssh 默认没有开启PasswordAuthentication，所以单独使用这个脚本开启一下</span><br><span class="line"><span class="meta">#</span> 免去后面配置免密登录的时候，再去修改</span><br><span class="line"><span class="meta">#</span> open PasswordAuthentication</span><br><span class="line">sed -i 's/#PasswordAuthentication yes/PasswordAuthentication yes/g' /etc/ssh/sshd_config</span><br><span class="line">sed -i 's/PasswordAuthentication no/#PasswordAuthentication yes/g' /etc/ssh/sshd_config</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> restart sshd</span><br><span class="line">service sshd restart</span><br></pre></td></tr></table></figure><p>解释：</p><ol><li><p>Vagrant的网络连接方式有三种：</p><p>NAT : 缺省创建，用于让vm可以通过host转发访问局域网甚至互联网。</p><p>host-only : 只有主机可以访问vm，其他机器无法访问它。</p><p>bridge : 此模式下vm就像局域网中的一台独立的机器，可以被其他机器访问。</p></li><li><p>根据vagrantfile的层次，分为：</p><p>configure级：它定义在 Vagrant.configure(“2”) 的下一层次，形如： config.vm.provision …</p><p>vm级：它定义在 config.vm.define :master do |master| 的下一层次，master.vm.provision …</p><p>执行的顺序是先执行configure级任务，再执行vm级任务，即便configure级任务在vm定义的下面才定义</p></li></ol><p>Step 4：启动Vagrant</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant up</span><br></pre></td></tr></table></figure><p>Step 5：连接vm</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant ssh node0</span><br></pre></td></tr></table></figure><p>Step 6：切换到root用户</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">su</span><br><span class="line">password默认是vagrant</span><br></pre></td></tr></table></figure><p>至此，就可以使用vm了。</p><p>有一个非常有用的命令：<code>vagrant rsync-auto</code>。因为我们可能会经常性的修改共享文件夹，这个命令可以触发共享文件夹的同步，而不需要执行<code>vagrant reload</code>来同步共享文件夹，该命令会重启VM</p><h4 id="Vagrant常用命令"><a href="#Vagrant常用命令" class="headerlink" title="Vagrant常用命令"></a>Vagrant常用命令</h4><h6 id="vagrant-help"><a href="#vagrant-help" class="headerlink" title="vagrant help"></a>vagrant help</h6><ul><li>vagrant help</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant help</span><br></pre></td></tr></table></figure><ul><li>vagrant [command] -h</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant box -h</span><br></pre></td></tr></table></figure><h6 id="vagrant-box"><a href="#vagrant-box" class="headerlink" title="vagrant box"></a>vagrant box</h6><ul><li>添加box</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant box add --name centos-7.4-base centos-7.4-base.box</span><br></pre></td></tr></table></figure><ul><li>查看box</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant box list</span><br></pre></td></tr></table></figure><ul><li>移除box</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant box remove centos-7.4-base</span><br></pre></td></tr></table></figure><h6 id="vagrant-vm"><a href="#vagrant-vm" class="headerlink" title="vagrant vm"></a>vagrant vm</h6><ul><li>初始化</li></ul><p>如果自己编写Vagrantfile，不需要这一步</p><p>这一步会把config.vm.box写入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant init centos-7.4-base</span><br></pre></td></tr></table></figure><ul><li>启动虚拟机</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant up</span><br></pre></td></tr></table></figure><ul><li>查看状态</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant status</span><br></pre></td></tr></table></figure><ul><li>ssh</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant ssh</span><br></pre></td></tr></table></figure><ul><li>暂停虚拟机</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant suspend</span><br></pre></td></tr></table></figure><ul><li>恢复虚拟机</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant resume</span><br></pre></td></tr></table></figure><ul><li>关闭虚拟机</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant halt</span><br></pre></td></tr></table></figure><ul><li>销毁虚拟机</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant destroy</span><br></pre></td></tr></table></figure><ul><li>更新Vagrantfile，刷新容器</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant reload</span><br></pre></td></tr></table></figure><h6 id="vagrant-snapshot"><a href="#vagrant-snapshot" class="headerlink" title="vagrant snapshot"></a>vagrant snapshot</h6><p>使用虚拟机快照命令需要先启动虚拟机</p><ul><li>保存虚拟机快照</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant snapshot save snap1</span><br></pre></td></tr></table></figure><ul><li>list虚拟机快照</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant snapshot list</span><br></pre></td></tr></table></figure><ul><li>恢复虚拟机快照</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant snapshot restore snap1</span><br></pre></td></tr></table></figure><ul><li>删除虚拟机快照</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant snapshot delete snap1</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;什么是Vagrant&quot;&gt;&lt;a href=&quot;#什么是Vagrant&quot; class=&quot;headerlink&quot; title=&quot;什么是Vagrant&quot;&gt;&lt;/a&gt;什么是Vagrant&lt;/h4&gt;&lt;p&gt;vagrant是一个基于VirtualBox, VMware, AWS等平台
      
    
    </summary>
    
      <category term="虚拟机" scheme="https://shang.at/categories/%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
    
    
      <category term="Vagrant" scheme="https://shang.at/tags/Vagrant/"/>
    
  </entry>
  
  <entry>
    <title>大数据-消息队列-数据采集-Kafka</title>
    <link href="https://shang.at/post/%E5%A4%A7%E6%95%B0%E6%8D%AE-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86-Kafka/"/>
    <id>https://shang.at/post/大数据-消息队列-数据采集-Kafka/</id>
    <published>2020-06-20T03:14:01.000Z</published>
    <updated>2020-06-23T06:51:13.466Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Kafka的基本概念和架构"><a href="#Kafka的基本概念和架构" class="headerlink" title="Kafka的基本概念和架构"></a>Kafka的基本概念和架构</h4><p>Apache Kafka是Apache软件基金会的开源的流处理平台，该平台提供了消息的订阅与发布的消息队列，一般用作系统间解耦、异步通信、削峰填谷等作用</p><p>逻辑上概念：</p><ul><li><p>Producer：生产消息的客户端</p></li><li><p>Consumer：消费消息的客户端</p><ul><li><p>Consumer Group：同一个ConsumerGroup中的Consumer往往是一个服务的多个实例，用来提高消费的效率，也就是说同一个CG中的多个C不能重复消费消息；不同CG往往代表了多种服务，他们处理不同的业务，所以，不同的CG中的C对于消息的处理是相互独立的，如CG2中的C2可以重复的消费在CG1中的C1已经消费过的消息</p><blockquote><p>消费者使用Consumer Group名称标记自己，并且发布到Topic的每条记录都会传递到每个订阅Consumer Group中的一个消费者实例。</p><p>​    如果所有Consumer实例都具有相同的Consumer Group，那么Topic中的记录会在该ConsumerGroup中的Consumer实例进行均分消费；</p><p>​    如果所有Consumer实例具有不同的ConsumerGroup，则每条记录将广播到所有Consumer Group进程。</p><p>更常见的是，我们发现Topic具有少量的Consumer Group，每个Consumer Group可以理解为一个“逻辑的订阅者”。每个Consumer Group均由许多Consumer实例组成，以实现<code>可伸缩性和容错能力</code>。这无非就是发布-订阅模型，其中订阅者是<code>消费者的集群</code>而不是单个进程。这种消费方式Kafka会将Topic按照分区的方式均分给一个Consumer Group下的实例，如果ConsumerGroup下有新的成员介入，则新介入的Consumer实例会去接管ConsumerGroup内其他消费者负责的某些分区，同样如果一下ConsumerGroup下的有其他Consumer实例宕机，则由该ConsumerGroup中其他Consumer实例接管。</p></blockquote><p><img src="/images/kafka消费者组.png" height="300" width="400"></p></li></ul></li></ul><ul><li><p>Tocpic：一组Record可以作为一个Topic在集群中被管理</p><ul><li>Record：Producer生产的每一条消息就是一个Record，每一个Record只能属于一个Topic</li></ul><blockquote><p>由于Kafka的Topic的分区策略，因此Kafka仅提供分区中记录的有序性，也就意味着相同Topic的不同分区记录之间无顺序。因为针对于绝大多数的大数据应用和使用场景， 使用分区内部有序或者使用key进行分区策略已经足够满足绝大多数应用场景。但是，如果您需要记录全局有序，则可以通过只有一个分区Topic来实现，尽管这将意味着每个ConsumerGroup只有一个Consumer进程</p></blockquote></li><li><p>Partition：每个Topic会有<code>num.partitions(默认)</code>个分区，每个Topic在创建的时候，也可以被指定分区的个数。</p><blockquote><p>Kafka中对Topic实现日志分区的有以下目的：</p><ol><li>支持集群存储的横向扩容。如果单一服务器的资源不够用，那么增加集群节点即可</li><li>每个服务器充当其某些分区的Leader，也可能充当其他分区的Follwer，因此群集中的负载得到了很好的平衡。</li><li>同一个Topic 多个分区可以提高Consumer消费的并行度</li></ol></blockquote><blockquote><p>在kafka中同一个partition的record是严格有序的，但是不同partition的record并不是严格有序的。也就是说，kafka只能保证partition内部record的有序消费</p></blockquote><ul><li>Duplicate(副本)：每个分区会有<code>--replication-factor</code>个副本，是在Topic被创建的时候指定的</li></ul></li><li><p>offset (非常重要的一个概念)  <font color="red">– 待补充</font></p><blockquote><p>在kafka中对于消息的生产和消费都是通过offset控制的。同一个partition的消息record的offset是递增的，消费者消费的时候，也是消费的指定的offset之后的消息。</p><p>消费者会定期的上传自己消费的offset给kafka server</p></blockquote></li><li><p>Segments  <font color="red">– 待补充</font></p></li></ul><p>架构上的概念</p><ul><li><p>Broker：Kafka集群内的节点被称为broker</p></li><li><p>Leader：kafka采用主从的架构，每个partition都有自己的leader。每个partition的leader负责消息的读写</p></li><li><p>Follower：每个</p></li><li><p>ISR</p></li></ul><h4 id="kafka的基本使用"><a href="#kafka的基本使用" class="headerlink" title="kafka的基本使用"></a>kafka的基本使用</h4><h5 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h5><ul><li>创建topic</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh \</span><br><span class="line">--bootstrap-server node1:9092,node2:9092,node3:9092 \</span><br><span class="line">--create \</span><br><span class="line">--topic topic01 \</span><br><span class="line">--partitions 3 \</span><br><span class="line">--replication-factor 3</span><br></pre></td></tr></table></figure><ul><li>查看topic列表</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh \</span><br><span class="line">--bootstrap-server node1:9092,node2:9092,node3:9092 \</span><br><span class="line">--list</span><br></pre></td></tr></table></figure><ul><li>查看topic详情</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh \</span><br><span class="line">--bootstrap-server node1:9092,node2:9092,node3:9092 \</span><br><span class="line">--describe \</span><br><span class="line">--topic topic01</span><br></pre></td></tr></table></figure><ul><li>修改topic</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh \</span><br><span class="line">--bootstrap-server node1:9092,node2:9092,node3:9092 \</span><br><span class="line">--create \</span><br><span class="line">--topic topic03 \</span><br><span class="line">--partitions 1 \</span><br><span class="line">--replication-factor 1</span><br><span class="line"></span><br><span class="line">kafka-topics.sh \</span><br><span class="line">--bootstrap-server node1:9092,node2:9092,node3:9092 \</span><br><span class="line">--alter \</span><br><span class="line">--topic topic03 \</span><br><span class="line">--partitions 2</span><br></pre></td></tr></table></figure><ul><li>删除topic</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh \</span><br><span class="line">--bootstrap-server node1:9092,node2:9092,node3:9092 \</span><br><span class="line">--delete \</span><br><span class="line">--topic topic03</span><br></pre></td></tr></table></figure><ul><li>消费者订阅topic</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh \</span><br><span class="line">--bootstrap-server node1:9092,node2:9092,node3:9092 \</span><br><span class="line">--topic topic01 \</span><br><span class="line">--group g1 \</span><br><span class="line">--property print.key=true \</span><br><span class="line">--property print.value=true \</span><br><span class="line">--property key.separator=,</span><br></pre></td></tr></table></figure><ul><li>消费者组</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">kafka-consumer-groups.sh \</span><br><span class="line">--bootstrap-server node1:9092,node2:9092,node3:9092 \</span><br><span class="line">--list</span><br><span class="line"></span><br><span class="line">kafka-consumer-groups.sh \</span><br><span class="line">--bootstrap-server node1:9092,node2:9092,node3:9092 \</span><br><span class="line">--describe \</span><br><span class="line">--group g1</span><br></pre></td></tr></table></figure><ul><li>生产者生产消息</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer.sh \</span><br><span class="line">--broker-list node1:9092,node2:9092,node3:9092 \</span><br><span class="line">--topic topic01</span><br></pre></td></tr></table></figure><h5 id="API"><a href="#API" class="headerlink" title="API"></a>API</h5><h6 id="基本API"><a href="#基本API" class="headerlink" title="基本API"></a>基本API</h6><h6 id="高级API"><a href="#高级API" class="headerlink" title="高级API"></a>高级API</h6><h4 id="架构进阶"><a href="#架构进阶" class="headerlink" title="架构进阶"></a>架构进阶</h4><h5 id="高性能分析之零拷贝-amp-源码分析"><a href="#高性能分析之零拷贝-amp-源码分析" class="headerlink" title="高性能分析之零拷贝&amp;源码分析"></a>高性能分析之零拷贝&amp;源码分析</h5><h5 id="数据同步机制"><a href="#数据同步机制" class="headerlink" title="数据同步机制"></a>数据同步机制</h5><h4 id="kafka与其他软件的集成"><a href="#kafka与其他软件的集成" class="headerlink" title="kafka与其他软件的集成"></a>kafka与其他软件的集成</h4><h5 id="与Flume的集成"><a href="#与Flume的集成" class="headerlink" title="与Flume的集成"></a>与Flume的集成</h5><h5 id="与SpringBoot的集成"><a href="#与SpringBoot的集成" class="headerlink" title="与SpringBoot的集成"></a>与SpringBoot的集成</h5><h5 id="在大数据流计算中的应用"><a href="#在大数据流计算中的应用" class="headerlink" title="在大数据流计算中的应用"></a>在大数据流计算中的应用</h5><h4 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h4><p>Kafka中的leader监控和topic的元数据，都是存在zk中</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;Kafka的基本概念和架构&quot;&gt;&lt;a href=&quot;#Kafka的基本概念和架构&quot; class=&quot;headerlink&quot; title=&quot;Kafka的基本概念和架构&quot;&gt;&lt;/a&gt;Kafka的基本概念和架构&lt;/h4&gt;&lt;p&gt;Apache Kafka是Apache软件基金会的开
      
    
    </summary>
    
      <category term="大数据生态" scheme="https://shang.at/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/"/>
    
    
      <category term="Kafka" scheme="https://shang.at/tags/Kafka/"/>
    
  </entry>
  
</feed>
