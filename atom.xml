<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>努力，奋斗</title>
  
  <subtitle>记录学习</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://shang.at/"/>
  <updated>2020-03-25T09:15:05.594Z</updated>
  <id>https://shang.at/</id>
  
  <author>
    <name>王尚</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Spark应用之import spark.implicits._</title>
    <link href="https://shang.at/post/Spark%E5%BA%94%E7%94%A8%E4%B9%8Bimport-spark-implicits/"/>
    <id>https://shang.at/post/Spark应用之import-spark-implicits/</id>
    <published>2020-03-25T09:10:54.000Z</published>
    <updated>2020-03-25T09:15:05.594Z</updated>
    
    <content type="html"><![CDATA[<p>在初期使用spark的时候，大家都会遇见一个很奇怪的写法</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在初期使用spark的时候，大家都会遇见一个很奇怪的写法&lt;/p&gt;

      
    
    </summary>
    
      <category term="Spark" scheme="https://shang.at/categories/Spark/"/>
    
    
      <category term="Spark应用" scheme="https://shang.at/tags/Spark%E5%BA%94%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>hadoop源码学习一</title>
    <link href="https://shang.at/post/hadoop%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B8%80/"/>
    <id>https://shang.at/post/hadoop源码学习一/</id>
    <published>2019-07-10T03:03:43.000Z</published>
    <updated>2019-08-03T02:17:49.590Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="Hadoop" scheme="https://shang.at/categories/Hadoop/"/>
    
    
      <category term="源码学习" scheme="https://shang.at/tags/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Pandas-学习</title>
    <link href="https://shang.at/post/Pandas-%E5%AD%A6%E4%B9%A0/"/>
    <id>https://shang.at/post/Pandas-学习/</id>
    <published>2019-06-11T01:53:35.000Z</published>
    <updated>2019-08-03T02:17:49.584Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="Pandas" scheme="https://shang.at/categories/Pandas/"/>
    
    
  </entry>
  
  <entry>
    <title>Python学习-时间处理</title>
    <link href="https://shang.at/post/Python%E5%AD%A6%E4%B9%A0-%E6%97%B6%E9%97%B4%E5%A4%84%E7%90%86/"/>
    <id>https://shang.at/post/Python学习-时间处理/</id>
    <published>2019-06-06T08:37:46.000Z</published>
    <updated>2019-08-03T02:17:49.584Z</updated>
    
    <content type="html"><![CDATA[<p>关于时间戳的几个概念<br>时间戳，根据1970年1月1日00:00:00开始按秒计算的偏移量。<br>时间元组（struct_time），包含9个元素。 </p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">time.struct_time(tm_year=<span class="number">2017</span>, tm_mon=<span class="number">10</span>, tm_mday=<span class="number">1</span>, tm_hour=<span class="number">14</span>, tm_min=<span class="number">21</span>, tm_sec=<span class="number">57</span>, tm_wday=<span class="number">6</span>, tm_yday=<span class="number">274</span>, tm_isdst=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>时间格式字符串，字符串形式的时间。<br>time模块与时间戳和时间相关的重要函数</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">time.time() <span class="comment"># 生成当前的时间戳，格式为10位整数的浮点数。</span></span><br><span class="line">time.strftime() <span class="comment"># 根据时间元组生成时间格式化字符串。</span></span><br><span class="line">time.strptime() <span class="comment"># 根据时间格式化字符串生成时间元组。time.strptime()与time.strftime()为互操作。</span></span><br><span class="line">time.localtime() <span class="comment"># 根据时间戳生成当前时区的时间元组。</span></span><br><span class="line">time.mktime() <span class="comment"># 根据时间元组生成时间戳。</span></span><br></pre></td></tr></table></figure><p>示例</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment">##生成当前时间的时间戳，只有一个参数即时间戳的位数，默认为10位，输入位数即生成相应位数的时间戳，比如可以生成常用的13位时间戳</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">now_to_timestamp</span><span class="params">(digits = <span class="number">10</span>)</span>:</span></span><br><span class="line">    time_stamp = time.time()</span><br><span class="line">    digits = <span class="number">10</span> ** (digits <span class="number">-10</span>)</span><br><span class="line">    time_stamp = int(round(time_stamp*digits))</span><br><span class="line">    <span class="keyword">return</span> time_stamp</span><br><span class="line"></span><br><span class="line"><span class="comment">##将时间戳规范为10位时间戳</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">timestamp_to_timestamp10</span><span class="params">(time_stamp)</span>:</span></span><br><span class="line">    time_stamp = int (time_stamp* (<span class="number">10</span> ** (<span class="number">10</span>-len(str(time_stamp)))))</span><br><span class="line">    <span class="keyword">return</span> time_stamp</span><br><span class="line"></span><br><span class="line"><span class="comment">##将当前时间转换为时间字符串，默认为2017-10-01 13:37:04格式</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">now_to_date</span><span class="params">(format_string=<span class="string">"%Y-%m-%d %H:%M:%S"</span>)</span>:</span></span><br><span class="line">    time_stamp = int(time.time())</span><br><span class="line">    time_array = time.localtime(time_stamp)</span><br><span class="line">    str_date = time.strftime(format_string, time_array)</span><br><span class="line">    <span class="keyword">return</span> str_date</span><br><span class="line"></span><br><span class="line"><span class="comment">##将10位时间戳转换为时间字符串，默认为2017-10-01 13:37:04格式</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">timestamp_to_date</span><span class="params">(time_stamp, format_string=<span class="string">"%Y-%m-%d %H:%M:%S"</span>)</span>:</span></span><br><span class="line">    time_array = time.localtime(time_stamp)</span><br><span class="line">    str_date = time.strftime(format_string, time_array)</span><br><span class="line">    <span class="keyword">return</span> str_date</span><br><span class="line"></span><br><span class="line"><span class="comment">##将时间字符串转换为10位时间戳，时间字符串默认为2017-10-01 13:37:04格式</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">date_to_timestamp</span><span class="params">(date, format_string=<span class="string">"%Y-%m-%d %H:%M:%S"</span>)</span>:</span></span><br><span class="line">    time_array = time.strptime(date, format_string)</span><br><span class="line">    time_stamp = int(time.mktime(time_array))</span><br><span class="line">    <span class="keyword">return</span> time_stamp</span><br><span class="line"></span><br><span class="line"><span class="comment">##不同时间格式字符串的转换</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">date_style_transfomation</span><span class="params">(date, format_string1=<span class="string">"%Y-%m-%d %H:%M:%S"</span>,format_string2=<span class="string">"%Y-%m-%d %H-%M-%S"</span>)</span>:</span></span><br><span class="line">    time_array  = time.strptime(date, format_string1)</span><br><span class="line">    str_date = time.strftime(format_string2, time_array)</span><br><span class="line">    <span class="keyword">return</span> str_date</span><br><span class="line"></span><br><span class="line">print(now_to_date())</span><br><span class="line">print(timestamp_to_date(<span class="number">1506816572</span>))</span><br><span class="line">print(date_to_timestamp(<span class="string">'2017-10-01 08:09:32'</span>))</span><br><span class="line">print(timestamp_to_timestamp10(<span class="number">1506816572546</span>))</span><br><span class="line">print(date_style_transfomation(<span class="string">'2017-10-01 08:09:32'</span>))</span><br></pre></td></tr></table></figure><p>结果为</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1506836224000</span><br><span class="line">2017-10-01 13:37:04</span><br><span class="line">2017-10-01 08:09:32</span><br><span class="line">1506816572</span><br><span class="line">1506816572</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;关于时间戳的几个概念&lt;br&gt;时间戳，根据1970年1月1日00:00:00开始按秒计算的偏移量。&lt;br&gt;时间元组（struct_time），包含9个元素。 &lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=
      
    
    </summary>
    
      <category term="Python" scheme="https://shang.at/categories/Python/"/>
    
    
      <category term="python中的时间处理" scheme="https://shang.at/tags/python%E4%B8%AD%E7%9A%84%E6%97%B6%E9%97%B4%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>Spark学习笔记-Configuration</title>
    <link href="https://shang.at/post/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Configuration/"/>
    <id>https://shang.at/post/Spark学习笔记-Configuration/</id>
    <published>2019-06-03T09:32:33.000Z</published>
    <updated>2019-08-03T02:17:49.585Z</updated>
    
    <content type="html"><![CDATA[<p> submit 参数</p><p>运行时可配置参数：在代码中使用spark.conf.set(‘’， ‘’)的方式设置。运行时设置的参数不会在WebUI中显示</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; submit 参数&lt;/p&gt;
&lt;p&gt;运行时可配置参数：在代码中使用spark.conf.set(‘’， ‘’)的方式设置。运行时设置的参数不会在WebUI中显示&lt;/p&gt;

      
    
    </summary>
    
      <category term="Spark" scheme="https://shang.at/categories/Spark/"/>
    
    
      <category term="Configuration" scheme="https://shang.at/tags/Configuration/"/>
    
  </entry>
  
  <entry>
    <title>Python学习-队列</title>
    <link href="https://shang.at/post/Python%E5%AD%A6%E4%B9%A0-%E9%98%9F%E5%88%97/"/>
    <id>https://shang.at/post/Python学习-队列/</id>
    <published>2019-06-03T02:10:48.000Z</published>
    <updated>2019-08-03T02:17:49.585Z</updated>
    
    <content type="html"><![CDATA[<h3 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from queue import Queue #LILO队列</span><br><span class="line">q = Queue() #创建队列对象</span><br><span class="line">q.put(0)    #在队列尾部插入元素</span><br><span class="line">q.put(1)</span><br><span class="line">q.put(2)</span><br><span class="line">print(&apos;LILO队列&apos;,q.queue)  #查看队列中的所有元素</span><br><span class="line">print(q.get())  #返回并删除队列头部元素</span><br><span class="line">print(q.queue)</span><br><span class="line"></span><br><span class="line">from queue import LifoQueue #LIFO队列</span><br><span class="line">lifoQueue = LifoQueue()</span><br><span class="line">lifoQueue.put(1)</span><br><span class="line">lifoQueue.put(2)</span><br><span class="line">lifoQueue.put(3)</span><br><span class="line">print(&apos;LIFO队列&apos;,lifoQueue.queue)</span><br><span class="line">lifoQueue.get() #返回并删除队列尾部元素</span><br><span class="line">lifoQueue.get()</span><br><span class="line">print(lifoQueue.queue)</span><br><span class="line"></span><br><span class="line">from queue import PriorityQueue #优先队列</span><br><span class="line">priorityQueue = PriorityQueue() #创建优先队列对象</span><br><span class="line">priorityQueue.put(3)    #插入元素</span><br><span class="line">priorityQueue.put(78)   #插入元素</span><br><span class="line">priorityQueue.put(100)  #插入元素</span><br><span class="line">print(priorityQueue.queue)  #查看优先级队列中的所有元素</span><br><span class="line">priorityQueue.put(1)    #插入元素</span><br><span class="line">priorityQueue.put(2)    #插入元素</span><br><span class="line">print(&apos;优先级队列:&apos;,priorityQueue.queue)  #查看优先级队列中的所有元素</span><br><span class="line">priorityQueue.get() #返回并删除优先级最低的元素</span><br><span class="line">print(&apos;删除后剩余元素&apos;,priorityQueue.queue)</span><br><span class="line">priorityQueue.get() #返回并删除优先级最低的元素</span><br><span class="line">print(&apos;删除后剩余元素&apos;,priorityQueue.queue)  #删除后剩余元素</span><br><span class="line">priorityQueue.get() #返回并删除优先级最低的元素</span><br><span class="line">print(&apos;删除后剩余元素&apos;,priorityQueue.queue)  #删除后剩余元素</span><br><span class="line">priorityQueue.get() #返回并删除优先级最低的元素</span><br><span class="line">print(&apos;删除后剩余元素&apos;,priorityQueue.queue)  #删除后剩余元素</span><br><span class="line">priorityQueue.get() #返回并删除优先级最低的元素</span><br><span class="line">print(&apos;全部被删除后:&apos;,priorityQueue.queue)  #查看优先级队列中的所有元素</span><br><span class="line"></span><br><span class="line">from collections import deque   #双端队列</span><br><span class="line">dequeQueue = deque([&apos;Eric&apos;,&apos;John&apos;,&apos;Smith&apos;])</span><br><span class="line">print(dequeQueue)</span><br><span class="line">dequeQueue.append(&apos;Tom&apos;)    #在右侧插入新元素</span><br><span class="line">dequeQueue.appendleft(&apos;Terry&apos;)  #在左侧插入新元素</span><br><span class="line">print(dequeQueue)</span><br><span class="line">dequeQueue.rotate(2)    #循环右移2次</span><br><span class="line">print(&apos;循环右移2次后的队列&apos;,dequeQueue)</span><br><span class="line">dequeQueue.popleft()    #返回并删除队列最左端元素</span><br><span class="line">print(&apos;删除最左端元素后的队列：&apos;,dequeQueue)</span><br><span class="line">dequeQueue.pop()    #返回并删除队列最右端元素</span><br><span class="line">print(&apos;删除最右端元素后的队列：&apos;,dequeQueue)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;队列&quot;&gt;&lt;a href=&quot;#队列&quot; class=&quot;headerlink&quot; title=&quot;队列&quot;&gt;&lt;/a&gt;队列&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span cl
      
    
    </summary>
    
      <category term="Python" scheme="https://shang.at/categories/Python/"/>
    
    
      <category term="数据结构" scheme="https://shang.at/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>Spark学习笔记-广播变量</title>
    <link href="https://shang.at/post/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/"/>
    <id>https://shang.at/post/Spark学习笔记-广播变量/</id>
    <published>2019-05-28T08:19:03.000Z</published>
    <updated>2019-08-03T02:17:49.589Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Shared-Variables"><a href="#Shared-Variables" class="headerlink" title="Shared Variables"></a>Shared Variables</h2><p>通常，当在远程集群节点上执行传递给Spark操作（例如<code>map</code>or <code>reduce</code>）的函数时，它将在函数中使用的所有变量的单独副本上工作。这些变量将复制到每台计算机，并且远程计算机上的变量的更新不会传播回驱动程序。支持跨任务的通用，读写共享变量效率低下。但是，Spark确实为两种常见的使用模式提供了两种有限类型的<em>共享变量</em>：广播变量和累加器。</p><h2 id="Broadcast"><a href="#Broadcast" class="headerlink" title="Broadcast"></a>Broadcast</h2><p>广播变量允许程序员在每台机器上保留一个只读变量，而不是随副本一起发送它的副本。例如，它们可用于以有效的方式为每个节点提供大输入数据集的副本。Spark还尝试使用有效的广播算法来分发广播变量，以降低通信成本。</p><p>Spark动作通过一组阶段执行，由分布式“shuffle”操作分隔。Spark自动广播每个阶段中任务所需的公共数据。以这种方式广播的数据以序列化形式缓存并在运行每个任务之前反序列化。这意味着显式创建广播变量仅在跨多个阶段的任务需要相同数据或以反序列化形式缓存数据很重要时才有用。</p><p>广播变量是<code>v</code>通过调用从变量创建的<code>SparkContext.broadcast(v)</code>。广播变量是一个包装器<code>v</code>，可以通过调用该<code>value</code> 方法来访问它的值。下面的代码显示了这个：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>broadcastVar = sc.broadcast([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">&lt;pyspark.broadcast.Broadcast object at <span class="number">0x102789f10</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>broadcastVar.value</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure><p>创建广播变量后，应该使用它来代替<code>v</code>群集上运行的任何函数中的值，这样<code>v</code>就不会多次传送到节点。此外，在<code>v</code>广播之后不应修改对象 ，以确保所有节点获得相同的广播变量值（例如，如果稍后将变量发送到新节点）。</p><p><a href="https://spark.apache.org/docs/latest/sql-performance-tuning.html" target="_blank" rel="noopener">Performance Tuning</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">== Physical Plan ==</span><br><span class="line">InMemoryTableScan [bill_create_date#4955, week_last_day#5015, month_last_day#5075, total_outstanding_amount_ex_dp90#6075]</span><br><span class="line">   +- InMemoryRelation [bill_create_date#4955, week_last_day#5015, month_last_day#5075, total_outstanding_amount_ex_dp90#6075], true, 10000, StorageLevel(disk, 1 replicas)</span><br><span class="line">         +- *(34) Project [bill_create_date#4955, week_last_day#5015, month_last_day#5075, ((coalesce(nanvl(total_disburse_amount#5203, null), 0.0) - cast(coalesce(total_repay_principal_amount#5974, 0) as double)) - coalesce(nanvl(total_write_off_principal#5986, null), 0.0)) AS total_outstanding_amount_ex_dp90#6075]</span><br><span class="line">            +- SortMergeJoin [bill_create_date#4955], [write_off_date#4776], LeftOuter</span><br><span class="line">               :- *(23) Project [bill_create_date#4955, week_last_day#5015, month_last_day#5075, total_disburse_amount#5203, total_repay_principal_amount#5974]</span><br><span class="line">               :  +- SortMergeJoin [bill_create_date#4955], [repay_date#5789], LeftOuter</span><br><span class="line">               :     :- *(6) Sort [bill_create_date#4955 ASC NULLS FIRST], false, 0</span><br><span class="line">               :     :  +- Exchange hashpartitioning(bill_create_date#4955, 200)</span><br><span class="line">               :     :     +- *(5) Project [bill_create_date#4955, week_last_day#5015, month_last_day#5075, total_disburse_amount#5203]</span><br><span class="line">               :     :        +- Window [sum(disburse_amount#5197) windowspecdefinition(1, bill_create_date#4955 ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS total_disburse_amount#5203], [1], [bill_create_date#4955 ASC NULLS FIRST]</span><br><span class="line">               :     :           +- *(4) Sort [1 ASC NULLS FIRST, bill_create_date#4955 ASC NULLS FIRST], false, 0</span><br><span class="line">               :     :              +- Exchange hashpartitioning(1, 200)</span><br><span class="line">               :     :                 +- *(3) HashAggregate(keys=[bill_create_date#4955, week_last_day#5015, month_last_day#5075], functions=[sum(cast(principal#615 as double))])</span><br><span class="line">               :     :                    +- Exchange hashpartitioning(bill_create_date#4955, week_last_day#5015, month_last_day#5075, 200)</span><br><span class="line">               :     :                       +- *(2) HashAggregate(keys=[bill_create_date#4955, week_last_day#5015, month_last_day#5075], functions=[partial_sum(cast(principal#615 as double))])</span><br><span class="line">               :     :                          +- *(2) Project [principal#615, cast(from_utc_timestamp(cast(from_unixtime(cast((cast(create_time#632L as double) / 1000.0) as bigint), yyyy-MM-dd HH:mm:ss, Some(UTC)) as timestamp), Asia/Ho_Chi_Minh) as date) AS bill_create_date#4955, next_day(cast(from_utc_timestamp(cast(from_unixtime(cast((cast(create_time#632L as double) / 1000.0) as bigint), yyyy-MM-dd HH:mm:ss, Some(UTC)) as timestamp), Asia/Ho_Chi_Minh) as date), Sun) AS week_last_day#5015, last_day(cast(from_utc_timestamp(cast(from_unixtime(cast((cast(create_time#632L as double) / 1000.0) as bigint), yyyy-MM-dd HH:mm:ss, Some(UTC)) as timestamp), Asia/Ho_Chi_Minh) as date)) AS month_last_day#5075]</span><br><span class="line">               :     :                             +- *(2) BroadcastHashJoin [id#392], [loan_id#609], Inner, BuildRight</span><br><span class="line">               :     :                                :- *(2) Project [id#392]</span><br><span class="line">               :     :                                :  +- *(2) Filter (status#397 IN (COMPLETED,CURRENT,LATE) &amp;&amp; isnotnull(id#392))</span><br><span class="line">               :     :                                :     +- *(2) FileScan parquet [id#392,status#397] Batched: true, Format: Parquet, Location: InMemoryFileIndex[...], PartitionFilters: [], PushedFilters: [In(status, [COMPLETED,CURRENT,LATE]), IsNotNull(id)], ReadSchema: struct&lt;id:string,status:string&gt;</span><br><span class="line">               :     :                                +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))</span><br><span class="line">               :     :                                   +- *(1) Project [loan_id#609, principal#615, create_time#632L]</span><br><span class="line">               :     :                                      +- *(1) Filter ((cast(from_utc_timestamp(cast(from_unixtime(cast((cast(create_time#632L as double) / 1000.0) as bigint), yyyy-MM-dd HH:mm:ss, Some(UTC)) as timestamp), Asia/Ho_Chi_Minh) as date) &lt;= 18043) &amp;&amp; isnotnull(loan_id#609))</span><br><span class="line">               :     :                                         +- *(1) FileScan parquet [loan_id#609,principal#615,create_time#632L] Batched: true, Format: Parquet, Location: InMemoryFileIndex[...], PartitionFilters: [], PushedFilters: [IsNotNull(loan_id)], ReadSchema: struct&lt;loan_id:string,principal:string,create_time:bigint&gt;</span><br><span class="line">               :     +- *(22) Sort [repay_date#5789 ASC NULLS FIRST], false, 0</span><br><span class="line">               :        +- Exchange hashpartitioning(repay_date#5789, 200)</span><br><span class="line">               :           +- *(21) Project [repay_date#5789, total_repay_principal_amount#5974]</span><br><span class="line">               :              +- Window [sum(repay_principal_amount#5970) windowspecdefinition(1, repay_date#5789 ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS total_repay_principal_amount#5974], [1], [repay_date#5789 ASC NULLS FIRST]</span><br><span class="line">               :                 +- *(20) Sort [1 ASC NULLS FIRST, repay_date#5789 ASC NULLS FIRST], false, 0</span><br><span class="line">               :                    +- Exchange hashpartitioning(1, 200)</span><br><span class="line">               :                       +- *(19) HashAggregate(keys=[repay_date#5789], functions=[sum(CASE WHEN (isnull(write_off_date#4776) || (write_off_date#4776 &gt; repay_date#5789)) THEN repaid_principal#684 END)])</span><br><span class="line">               :                          +- Exchange hashpartitioning(repay_date#5789, 200)</span><br><span class="line">               :                             +- *(18) HashAggregate(keys=[repay_date#5789], functions=[partial_sum(CASE WHEN (isnull(write_off_date#4776) || (write_off_date#4776 &gt; repay_date#5789)) THEN repaid_principal#684 END)])</span><br><span class="line">               :                                +- *(18) Project [repaid_principal#684, write_off_date#4776, cast(from_utc_timestamp(repay_time#692, Asia/Ho_Chi_Minh) as date) AS repay_date#5789]</span><br><span class="line">               :                                   +- SortMergeJoin [loan_id#609], [loan_id#5672], LeftOuter</span><br><span class="line">               :                                      :- *(12) Sort [loan_id#609 ASC NULLS FIRST], false, 0</span><br><span class="line">               :                                      :  +- Exchange hashpartitioning(loan_id#609, 200)</span><br><span class="line">               :                                      :     +- *(11) Project [loan_id#609, repaid_principal#684, repay_time#692]</span><br><span class="line">               :                                      :        +- *(11) BroadcastHashJoin [id#608], [bill_id#670], Inner, BuildRight</span><br><span class="line">               :                                      :           :- *(11) Project [id#608, loan_id#609]</span><br><span class="line">               :                                      :           :  +- *(11) BroadcastHashJoin [id#392], [loan_id#609], Inner, BuildRight</span><br><span class="line">               :                                      :           :     :- *(11) Project [id#392]</span><br><span class="line">               :                                      :           :     :  +- *(11) Filter (status#397 IN (COMPLETED,CURRENT,LATE) &amp;&amp; isnotnull(id#392))</span><br><span class="line">               :                                      :           :     :     +- *(11) FileScan parquet [id#392,status#397] Batched: true, Format: Parquet, Location: InMemoryFileIndex[...], PartitionFilters: [], PushedFilters: [In(status, [COMPLETED,CURRENT,LATE]), IsNotNull(id)], ReadSchema: struct&lt;id:string,status:string&gt;</span><br><span class="line">               :                                      :           :     +- BroadcastExchange HashedRelationBroadcastMode(List(input[1, string, true]))</span><br><span class="line">               :                                      :           :        +- *(7) Project [id#608, loan_id#609]</span><br><span class="line">               :                                      :           :           +- *(7) Filter (isnotnull(loan_id#609) &amp;&amp; isnotnull(id#608))</span><br><span class="line">               :                                      :           :              +- *(7) FileScan parquet [id#608,loan_id#609] Batched: true, Format: Parquet, Location: InMemoryFileIndex[...], PartitionFilters: [], PushedFilters: [IsNotNull(loan_id), IsNotNull(id)], ReadSchema: struct&lt;id:string,loan_id:string&gt;</span><br><span class="line">               :                                      :           +- BroadcastExchange HashedRelationBroadcastMode(ArrayBuffer(input[0, string, true]))</span><br><span class="line">               :                                      :              +- *(10) Project [bill_id#670, repaid_principal#684, repay_time#692]</span><br><span class="line">               :                                      :                 +- *(10) Filter ((isnotnull(rn#5382) &amp;&amp; (rn#5382 = 1)) &amp;&amp; (cast(from_utc_timestamp(repay_time#692, Asia/Ho_Chi_Minh) as date) &lt;= 18043))</span><br><span class="line">               :                                      :                    +- Window [row_number() windowspecdefinition(bill_id#670, repay_time#692 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#5382], [bill_id#670], [repay_time#692 DESC NULLS LAST]</span><br><span class="line">               :                                      :                       +- *(9) Sort [bill_id#670 ASC NULLS FIRST, repay_time#692 DESC NULLS LAST], false, 0</span><br><span class="line">               :                                      :                          +- Exchange hashpartitioning(bill_id#670, 200)</span><br><span class="line">               :                                      :                             +- *(8) Project [bill_id#670, repaid_principal#684, repay_time#692]</span><br><span class="line">               :                                      :                                +- *(8) Filter isnotnull(bill_id#670)</span><br><span class="line">               :                                      :                                   +- *(8) FileScan parquet [bill_id#670,repaid_principal#684,repay_time#692] Batched: true, Format: Parquet, Location: InMemoryFileIndex[...], PartitionFilters: [], PushedFilters: [IsNotNull(bill_id)], ReadSchema: struct&lt;bill_id:string,repaid_principal:decimal(20,0),repay_time:timestamp&gt;</span><br><span class="line">               :                                      +- *(17) Sort [loan_id#5672 ASC NULLS FIRST], false, 0</span><br><span class="line">               :                                         +- *(17) HashAggregate(keys=[loan_id#5672], functions=[first(write_off_date#4705, true)])</span><br><span class="line">               :                                            +- *(17) HashAggregate(keys=[loan_id#5672], functions=[partial_first(write_off_date#4705, true)])</span><br><span class="line">               :                                               +- *(17) Project [loan_id#5672, write_off_date#4705]</span><br><span class="line">               :                                                  +- *(17) BroadcastHashJoin [bill_id#4714], [bill_id#670], LeftOuter, BuildRight</span><br><span class="line">               :                                                     :- *(17) Project [loan_id#5672, write_off_date#4705, bill_id#4714]</span><br><span class="line">               :                                                     :  +- *(17) BroadcastHashJoin [loan_id#5672], [loan_id#4718], LeftOuter, BuildRight</span><br><span class="line">               :                                                     :     :- *(17) Project [loan_id#5672, write_off_date#4705]</span><br><span class="line">               :                                                     :     :  +- *(17) BroadcastHashJoin [loan_id#5672], [loan_id#4708], LeftOuter, BuildRight</span><br><span class="line">               :                                                     :     :     :- *(17) HashAggregate(keys=[loan_id#5672], functions=[min(CASE WHEN is_write_off_bill#4594 THEN write_off_date#4630 END)])</span><br><span class="line">               :                                                     :     :     :  +- Exchange hashpartitioning(loan_id#5672, 200)</span><br><span class="line">               :                                                     :     :     :     +- *(13) HashAggregate(keys=[loan_id#5672], functions=[partial_min(CASE WHEN is_write_off_bill#4594 THEN write_off_date#4630 END)])</span><br><span class="line">               :                                                     :     :     :        +- *(13) Project [loan_id#5672, (CASE WHEN isnotnull(CASE WHEN (status#5676 = OVERDUE) THEN datediff(18044, cast(due_date#5686 as date)) END) THEN CASE WHEN (status#5676 = OVERDUE) THEN datediff(18044, cast(due_date#5686 as date)) END WHEN isnotnull(CASE WHEN (status#5676 IN (REBALANCED,REPAID) &amp;&amp; (cast(cast(from_utc_timestamp(cast(from_unixtime(cast((cast(repay_time#5694L as double) / 1000.0) as bigint), yyyy-MM-dd HH:mm:ss, Some(UTC)) as timestamp), Asia/Ho_Chi_Minh) as date) as string) &gt; due_date#5686)) THEN datediff(cast(from_utc_timestamp(cast(from_unixtime(cast((cast(repay_time#5694L as double) / 1000.0) as bigint), yyyy-MM-dd HH:mm:ss, Some(UTC)) as timestamp), Asia/Ho_Chi_Minh) as date), cast(due_date#5686 as date)) END) THEN CASE WHEN (status#5676 IN (REBALANCED,REPAID) &amp;&amp; (cast(cast(from_utc_timestamp(cast(from_unixtime(cast((cast(repay_time#5694L as double) / 1000.0) as bigint), yyyy-MM-dd HH:mm:ss, Some(UTC)) as timestamp), Asia/Ho_Chi_Minh) as date) as string) &gt; due_date#5686)) THEN datediff(cast(from_utc_timestamp(cast(from_unixtime(cast((cast(repay_time#5694L as double) / 1000.0) as bigint), yyyy-MM-dd HH:mm:ss, Some(UTC)) as timestamp), Asia/Ho_Chi_Minh) as date), cast(due_date#5686 as date)) END ELSE 0 END &gt;= 91) AS is_write_off_bill#4594, date_add(cast(due_date#5686 as date), 91) AS write_off_date#4630]</span><br><span class="line">               :                                                     :     :     :           +- *(13) Filter (CASE WHEN isnotnull(CASE WHEN (status#5676 = OVERDUE) THEN datediff(18044, cast(due_date#5686 as date)) END) THEN CASE WHEN (status#5676 = OVERDUE) THEN datediff(18044, cast(due_date#5686 as date)) END WHEN isnotnull(CASE WHEN (status#5676 IN (REBALANCED,REPAID) &amp;&amp; (cast(cast(from_utc_timestamp(cast(from_unixtime(cast((cast(repay_time#5694L as double) / 1000.0) as bigint), yyyy-MM-dd HH:mm:ss, Some(UTC)) as timestamp), Asia/Ho_Chi_Minh) as date) as string) &gt; due_date#5686)) THEN datediff(cast(from_utc_timestamp(cast(from_unixtime(cast((cast(repay_time#5694L as double) / 1000.0) as bigint), yyyy-MM-dd HH:mm:ss, Some(UTC)) as timestamp), Asia/Ho_Chi_Minh) as date), cast(due_date#5686 as date)) END) THEN CASE WHEN (status#5676 IN (REBALANCED,REPAID) &amp;&amp; (cast(cast(from_utc_timestamp(cast(from_unixtime(cast((cast(repay_time#5694L as double) / 1000.0) as bigint), yyyy-MM-dd HH:mm:ss, Some(UTC)) as timestamp), Asia/Ho_Chi_Minh) as date) as string) &gt; due_date#5686)) THEN datediff(cast(from_utc_timestamp(cast(from_unixtime(cast((cast(repay_time#5694L as double) / 1000.0) as bigint), yyyy-MM-dd HH:mm:ss, Some(UTC)) as timestamp), Asia/Ho_Chi_Minh) as date), cast(due_date#5686 as date)) END ELSE 0 END &gt;= 91)</span><br><span class="line">               :                                                     :     :     :              +- *(13) FileScan parquet [loan_id#5672,status#5676,due_date#5686,repay_time#5694L] Batched: true, Format: Parquet, Location: InMemoryFileIndex[...], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;loan_id:string,status:string,due_date:string,repay_time:bigint&gt;</span><br><span class="line">               :                                                     :     :     +- BroadcastExchange HashedRelationBroadcastMode(ArrayBuffer(input[0, string, true]))</span><br><span class="line">               :                                                     :     :        +- *(14) Project [id#392 AS loan_id#4708]</span><br><span class="line">               :                                                     :     :           +- *(14) FileScan parquet [id#392] Batched: true, Format: Parquet, Location: InMemoryFileIndex[...], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;id:string&gt;</span><br><span class="line">               :                                                     :     +- BroadcastExchange HashedRelationBroadcastMode(ArrayBuffer(input[1, string, true]))</span><br><span class="line">               :                                                     :        +- *(15) Project [id#4717 AS bill_id#4714, loan_id#4718]</span><br><span class="line">               :                                                     :           +- *(15) FileScan parquet [id#4717,loan_id#4718] Batched: true, Format: Parquet, Location: InMemoryFileIndex[...], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;id:string,loan_id:string&gt;</span><br><span class="line">               :                                                     +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))</span><br><span class="line">               :                                                        +- *(16) FileScan parquet [bill_id#670] Batched: true, Format: Parquet, Location: InMemoryFileIndex[...], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;bill_id:string&gt;</span><br><span class="line">               +- *(33) Sort [write_off_date#4776 ASC NULLS FIRST], false, 0</span><br><span class="line">                  +- Exchange hashpartitioning(write_off_date#4776, 200)</span><br><span class="line">                     +- *(32) Project [write_off_date#4776, total_write_off_principal#5986]</span><br><span class="line">                        +- Window [sum(write_off_principal#5982) windowspecdefinition(1, write_off_date#4776 ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS total_write_off_principal#5986], [1], [write_off_date#4776 ASC NULLS FIRST]</span><br><span class="line">                           +- *(31) Sort [1 ASC NULLS FIRST, write_off_date#4776 ASC NULLS FIRST], false, 0</span><br><span class="line">                              +- Exchange hashpartitioning(1, 200)</span><br><span class="line">                                 +- *(30) HashAggregate(keys=[write_off_date#4776], functions=[sum(write_off_principal#4779)])</span><br><span class="line">                                    +- Exchange hashpartitioning(write_off_date#4776, 200)</span><br><span class="line">                                       +- *(29) HashAggregate(keys=[write_off_date#4776], functions=[partial_sum(write_off_principal#4779)])</span><br><span class="line">                                          +- SortAggregate(key=[loan_id#609], functions=[first(write_off_date#4705, true), first(amount#398, true), sum(CASE WHEN (isnotnull(repayment_date#4760) &amp;&amp; (repayment_date#4760 &lt; write_off_date#4705)) THEN repaid_principal#684 ELSE 0 END)])</span><br><span class="line">                                             +- SortAggregate(key=[loan_id#609], functions=[partial_first(write_off_date#4705, true), partial_first(amount#398, true), partial_sum(CASE WHEN (isnotnull(repayment_date#4760) &amp;&amp; (repayment_date#4760 &lt; write_off_date#4705)) THEN repaid_principal#684 ELSE 0 END)])</span><br><span class="line">                                                +- *(28) Sort [loan_id#609 ASC NULLS FIRST], false, 0</span><br><span class="line">                                                   +- *(28) Project [loan_id#609, write_off_date#4705, amount#398, repaid_principal#684, cast(from_utc_timestamp(repay_time#692, Asia/Ho_Chi_Minh) as date) AS repayment_date#4760]</span><br><span class="line">                                                      +- *(28) BroadcastHashJoin [bill_id#4714], [bill_id#670], LeftOuter, BuildRight</span><br><span class="line">                                                         :- *(28) Project [loan_id#609, write_off_date#4705, amount#398, bill_id#4714]</span><br><span class="line">                                                         :  +- *(28) BroadcastHashJoin [loan_id#609], [loan_id#4718], LeftOuter, BuildRight</span><br><span class="line">                                                         :     :- *(28) Project [loan_id#609, write_off_date#4705, amount#398]</span><br><span class="line">                                                         :     :  +- *(28) BroadcastHashJoin [loan_id#609], [loan_id#4708], LeftOuter, BuildRight</span><br><span class="line">                                                         :     :     :- *(28) HashAggregate(keys=[loan_id#609], functions=[min(CASE WHEN is_write_off_bill#4594 THEN write_off_date#4630 END)])</span><br><span class="line">                                                         :     :     :  +- ReusedExchange [loan_id#609, min#6101], Exchange hashpartitioning(loan_id#5672, 200)</span><br><span class="line">                                                         :     :     +- BroadcastExchange HashedRelationBroadcastMode(ArrayBuffer(input[0, string, true]))</span><br><span class="line">                                                         :     :        +- *(25) Project [id#392 AS loan_id#4708, amount#398]</span><br><span class="line">                                                         :     :           +- *(25) FileScan parquet [id#392,amount#398] Batched: true, Format: Parquet, Location: InMemoryFileIndex[...], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;id:string,amount:string&gt;</span><br><span class="line">                                                         :     +- ReusedExchange [bill_id#4714, loan_id#4718], BroadcastExchange HashedRelationBroadcastMode(ArrayBuffer(input[1, string, true]))</span><br><span class="line">                                                         +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))</span><br><span class="line">                                                            +- *(27) Project [bill_id#670, repay_time#692, repaid_principal#684]</span><br><span class="line">                                                               +- *(27) FileScan parquet [bill_id#670,repaid_principal#684,repay_time#692] Batched: true, Format: Parquet, Location: InMemoryFileIndex[...], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;bill_id:string,repaid_principal:decimal(20,0),repay_time:timestamp&gt;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Shared-Variables&quot;&gt;&lt;a href=&quot;#Shared-Variables&quot; class=&quot;headerlink&quot; title=&quot;Shared Variables&quot;&gt;&lt;/a&gt;Shared Variables&lt;/h2&gt;&lt;p&gt;通常，当在远程集群节点上执行
      
    
    </summary>
    
      <category term="Spark" scheme="https://shang.at/categories/Spark/"/>
    
    
      <category term="Spark学习" scheme="https://shang.at/tags/Spark%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>数据结构学习笔记二-算法</title>
    <link href="https://shang.at/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C-%E7%AE%97%E6%B3%95/"/>
    <id>https://shang.at/post/数据结构学习笔记二-算法/</id>
    <published>2019-05-16T09:54:29.000Z</published>
    <updated>2019-05-16T14:39:58.762Z</updated>
    
    <content type="html"><![CDATA[<h2 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h2><h2 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h2><h2 id="哈希算法"><a href="#哈希算法" class="headerlink" title="哈希算法"></a>哈希算法</h2><h2 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h2><h2 id="深度和广度优先搜索"><a href="#深度和广度优先搜索" class="headerlink" title="深度和广度优先搜索"></a>深度和广度优先搜索</h2><h2 id="字符串匹配"><a href="#字符串匹配" class="headerlink" title="字符串匹配"></a>字符串匹配</h2><h2 id="贪心算法"><a href="#贪心算法" class="headerlink" title="贪心算法"></a>贪心算法</h2><p>##分治算法</p><h2 id="回溯算法"><a href="#回溯算法" class="headerlink" title="回溯算法"></a>回溯算法</h2><h2 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h2><h2 id="拓扑排序"><a href="#拓扑排序" class="headerlink" title="拓扑排序"></a>拓扑排序</h2><h2 id="最短路径"><a href="#最短路径" class="headerlink" title="最短路径"></a>最短路径</h2><h2 id="并行算法"><a href="#并行算法" class="headerlink" title="并行算法"></a>并行算法</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;递归&quot;&gt;&lt;a href=&quot;#递归&quot; class=&quot;headerlink&quot; title=&quot;递归&quot;&gt;&lt;/a&gt;递归&lt;/h2&gt;&lt;h2 id=&quot;二分查找&quot;&gt;&lt;a href=&quot;#二分查找&quot; class=&quot;headerlink&quot; title=&quot;二分查找&quot;&gt;&lt;/a&gt;二分查找&lt;/h
      
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://shang.at/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="https://shang.at/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Spark学习笔记-pivot透视图</title>
    <link href="https://shang.at/post/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-pivot%E9%80%8F%E8%A7%86%E5%9B%BE/"/>
    <id>https://shang.at/post/Spark学习笔记-pivot透视图/</id>
    <published>2019-05-09T02:52:07.000Z</published>
    <updated>2019-08-03T02:17:49.587Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = spark.createDataFrame([</span><br><span class="line">    (<span class="string">'2018-01'</span>,<span class="string">'项目1'</span>,<span class="number">100</span>, <span class="string">'xm'</span>), </span><br><span class="line">    (<span class="string">'2018-01'</span>,<span class="string">'项目1'</span>,<span class="number">100</span>, <span class="string">'xl'</span>), </span><br><span class="line">    (<span class="string">'2018-01'</span>,<span class="string">'项目1'</span>,<span class="number">100</span>, <span class="string">'xp'</span>), </span><br><span class="line">    (<span class="string">'2018-01'</span>,<span class="string">'项目2'</span>,<span class="number">200</span>, <span class="string">'ch'</span>), </span><br><span class="line">    (<span class="string">'2018-01'</span>,<span class="string">'项目3'</span>,<span class="number">300</span>, <span class="string">'xl'</span>),    </span><br><span class="line">    (<span class="string">'2018-02'</span>,<span class="string">'项目1'</span>,<span class="number">1000</span>, <span class="string">'xp'</span>), </span><br><span class="line">    (<span class="string">'2018-02'</span>,<span class="string">'项目2'</span>,<span class="number">2000</span>, <span class="string">'xl'</span>), </span><br><span class="line">    (<span class="string">'2018-03'</span>,<span class="string">'项目x'</span>,<span class="number">999</span>, <span class="string">'xm'</span>)</span><br><span class="line">], [<span class="string">'date'</span>,<span class="string">'project'</span>,<span class="string">'income'</span>, <span class="string">'saler'</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.toPandas()</span><br></pre></td></tr></table></figure><table border="1" class="dataframe"><br>  <thead><br>    <tr style="text-align: right;"><br>      <th></th><br>      <th>date</th><br>      <th>project</th><br>      <th>income</th><br>      <th>saler</th><br>    </tr><br>  </thead><br>  <tbody><br>    <tr><br>      <th>0</th><br>      <td>2018-01</td><br>      <td>项目1</td><br>      <td>100</td><br>      <td>xm</td><br>    </tr><br>    <tr><br>      <th>1</th><br>      <td>2018-01</td><br>      <td>项目1</td><br>      <td>100</td><br>      <td>xl</td><br>    </tr><br>    <tr><br>      <th>2</th><br>      <td>2018-01</td><br>      <td>项目1</td><br>      <td>100</td><br>      <td>xp</td><br>    </tr><br>    <tr><br>      <th>3</th><br>      <td>2018-01</td><br>      <td>项目2</td><br>      <td>200</td><br>      <td>ch</td><br>    </tr><br>    <tr><br>      <th>4</th><br>      <td>2018-01</td><br>      <td>项目3</td><br>      <td>300</td><br>      <td>xl</td><br>    </tr><br>    <tr><br>      <th>5</th><br>      <td>2018-02</td><br>      <td>项目1</td><br>      <td>1000</td><br>      <td>xp</td><br>    </tr><br>    <tr><br>      <th>6</th><br>      <td>2018-02</td><br>      <td>项目2</td><br>      <td>2000</td><br>      <td>xl</td><br>    </tr><br>    <tr><br>      <th>7</th><br>      <td>2018-03</td><br>      <td>项目x</td><br>      <td>999</td><br>      <td>xm</td><br>    </tr><br>  </tbody><br></table><h3 id="pivot"><a href="#pivot" class="headerlink" title="pivot"></a>pivot</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df_pivot = df.groupBy(<span class="string">'date'</span>).pivot(</span><br><span class="line">    <span class="string">'project'</span>, [<span class="string">'项目1'</span>, <span class="string">'项目2'</span>, <span class="string">'项目3'</span>, <span class="string">'项目x'</span>]</span><br><span class="line">).agg(</span><br><span class="line">    sum(<span class="string">'income'</span>)</span><br><span class="line">).na.fill(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">df_pivot.toPandas()</span><br></pre></td></tr></table></figure><table border="1" class="dataframe"><br>  <thead><br>    <tr style="text-align: right;"><br>      <th></th><br>      <th>date</th><br>      <th>项目1</th><br>      <th>项目2</th><br>      <th>项目3</th><br>      <th>项目x</th><br>    </tr><br>  </thead><br>  <tbody><br>    <tr><br>      <th>0</th><br>      <td>2018-03</td><br>      <td>0</td><br>      <td>0</td><br>      <td>0</td><br>      <td>999</td><br>    </tr><br>    <tr><br>      <th>1</th><br>      <td>2018-02</td><br>      <td>1000</td><br>      <td>2000</td><br>      <td>0</td><br>      <td>0</td><br>    </tr><br>    <tr><br>      <th>2</th><br>      <td>2018-01</td><br>      <td>300</td><br>      <td>200</td><br>      <td>300</td><br>      <td>0</td><br>    </tr><br>  </tbody><br></table><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.groupBy(<span class="string">'project'</span>).pivot(</span><br><span class="line">    <span class="string">'date'</span></span><br><span class="line">).agg(</span><br><span class="line">    sum(<span class="string">'income'</span>)</span><br><span class="line">).na.fill(<span class="number">0</span>).toPandas()</span><br></pre></td></tr></table></figure><table border="1" class="dataframe"><br>  <thead><br>    <tr style="text-align: right;"><br>      <th></th><br>      <th>project</th><br>      <th>2018-01</th><br>      <th>2018-02</th><br>      <th>2018-03</th><br>    </tr><br>  </thead><br>  <tbody><br>    <tr><br>      <th>0</th><br>      <td>项目2</td><br>      <td>200</td><br>      <td>2000</td><br>      <td>0</td><br>    </tr><br>    <tr><br>      <th>1</th><br>      <td>项目x</td><br>      <td>0</td><br>      <td>0</td><br>      <td>999</td><br>    </tr><br>    <tr><br>      <th>2</th><br>      <td>项目1</td><br>      <td>300</td><br>      <td>1000</td><br>      <td>0</td><br>    </tr><br>    <tr><br>      <th>3</th><br>      <td>项目3</td><br>      <td>300</td><br>      <td>0</td><br>      <td>0</td><br>    </tr><br>  </tbody><br></table><h3 id="unpivot"><a href="#unpivot" class="headerlink" title="unpivot"></a>unpivot</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df_pivot.selectExpr(<span class="string">"date"</span>, </span><br><span class="line">                    <span class="string">"stack(4, '项目11', `项目1`, '项目22', `项目2`, '项目33', `项目3`, '项目xx', `项目x`) as (`project`,`income`)"</span>)\</span><br><span class="line">            .filter(<span class="string">"income &gt; 0 "</span>)\</span><br><span class="line">            .orderBy([<span class="string">"date"</span>, <span class="string">"project"</span>])\</span><br><span class="line">            .toPandas()</span><br></pre></td></tr></table></figure><table border="1" class="dataframe"><br>  <thead><br>    <tr style="text-align: right;"><br>      <th></th><br>      <th>date</th><br>      <th>project</th><br>      <th>income</th><br>    </tr><br>  </thead><br>  <tbody><br>    <tr><br>      <th>0</th><br>      <td>2018-01</td><br>      <td>项目11</td><br>      <td>300</td><br>    </tr><br>    <tr><br>      <th>1</th><br>      <td>2018-01</td><br>      <td>项目22</td><br>      <td>200</td><br>    </tr><br>    <tr><br>      <th>2</th><br>      <td>2018-01</td><br>      <td>项目33</td><br>      <td>300</td><br>    </tr><br>    <tr><br>      <th>3</th><br>      <td>2018-02</td><br>      <td>项目11</td><br>      <td>1000</td><br>    </tr><br>    <tr><br>      <th>4</th><br>      <td>2018-02</td><br>      <td>项目22</td><br>      <td>2000</td><br>    </tr><br>    <tr><br>      <th>5</th><br>      <td>2018-03</td><br>      <td>项目xx</td><br>      <td>999</td><br>    </tr><br>  </tbody><br></table><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">stack(n, expr1, ..., exprk) 将k个[expr1, ..., exprk]拆解成n rows</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;df = spark.createDataFrame([&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;lin
      
    
    </summary>
    
      <category term="Spark" scheme="https://shang.at/categories/Spark/"/>
    
    
      <category term="Spark学习" scheme="https://shang.at/tags/Spark%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Spark学习笔记-tips</title>
    <link href="https://shang.at/post/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-tips/"/>
    <id>https://shang.at/post/Spark学习笔记-tips/</id>
    <published>2019-04-15T05:50:00.000Z</published>
    <updated>2019-08-03T02:17:49.589Z</updated>
    
    <content type="html"><![CDATA[<ul><li>写spark dataframe的时候，最好用哪些字段就取哪些字段，否则spark会默认把所有字段都读进内存，如果进行cache操作，就会无故占用大量内存</li><li>没有被明确select的字段依然可以作为filter的条件</li><li>获取周的第一天日期和当前日期位于周的第几天，周的第一天定义不同<ul><li>周日</li><li>周一</li></ul></li><li>Spark Shuffle spill (Memory) and (Disk) on SPARK UI? What do they mean?<ul><li><a href="https://community.hortonworks.com/questions/202809/spark-shuffle-spill-memory.html" target="_blank" rel="noopener">https://community.hortonworks.com/questions/202809/spark-shuffle-spill-memory.html</a></li></ul></li></ul><ul><li>窗口函数会引起重分区吗？分区数(200)是固定的吗？</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">test_df = kreditpintar.spark.range(0, end=100, numPartitions=5).toDF(&apos;input&apos;)</span><br><span class="line">test_df.rdd.getNumPartitions() # 5</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test_1_df = test_df.withColumn(&apos;id&apos;, row_number().over(Window.partitionBy(lit(1)).orderBy(&apos;input&apos;)))</span><br><span class="line">test_1_df.rdd.getNumPartitions() # 200</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test_2_df = test_df.withColumn(&apos;id&apos;, monotonically_increasing_id())</span><br><span class="line">test_2_df.rdd.getNumPartitions() # 5</span><br></pre></td></tr></table></figure><ul><li>通过withColumn(‘group’, lit(‘aaaabbb’))添加的新列，不能最为后续的join操作的condition expression？</li></ul><ul><li><p>groupBy 和 窗口函数的实现原理</p><ul><li><p>哪一个效率更高</p></li><li><p>groupby 、窗口函数、distinct三种方式去重 哪个效率高</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">distinct&gt;groupby&gt;窗口函数</span><br></pre></td></tr></table></figure></li></ul></li><li><p>循环的去跑脚本，然后union每次循环的结果。</p><ul><li>这样的使用 task可能会失败，需要优化</li></ul></li></ul><ul><li>转化long列类型到时间戳，保留毫秒信息</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a_df = spark.createDataFrame([[<span class="number">1556613225852</span>]], [<span class="string">'a'</span>])</span><br><span class="line">a_df.select((col(<span class="string">'a'</span>)/<span class="number">1000.0</span>).cast(<span class="string">'timestamp'</span>)).toPandas()</span><br><span class="line"></span><br><span class="line"><span class="comment">#CAST((a / 1000.0) AS TIMESTAMP)</span></span><br><span class="line"><span class="comment">#02019-04-30 08:33:45.852</span></span><br></pre></td></tr></table></figure><ul><li>spark进行计算的过程中间检查数据没有问题，但是执行collect后出现数据不一致的情况(丢失数据和union后的数据重复)</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;写spark dataframe的时候，最好用哪些字段就取哪些字段，否则spark会默认把所有字段都读进内存，如果进行cache操作，就会无故占用大量内存&lt;/li&gt;
&lt;li&gt;没有被明确select的字段依然可以作为filter的条件&lt;/li&gt;
&lt;li&gt;获取周的第
      
    
    </summary>
    
      <category term="Spark" scheme="https://shang.at/categories/Spark/"/>
    
    
      <category term="Spark学习" scheme="https://shang.at/tags/Spark%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>BI工具使用之Tableau一</title>
    <link href="https://shang.at/post/BI%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E4%B9%8BTableau%E4%B8%80/"/>
    <id>https://shang.at/post/BI工具使用之Tableau一/</id>
    <published>2019-04-11T07:08:39.000Z</published>
    <updated>2019-05-12T00:22:00.389Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="BI" scheme="https://shang.at/categories/BI/"/>
    
    
      <category term="Tableau" scheme="https://shang.at/tags/Tableau/"/>
    
  </entry>
  
  <entry>
    <title>Spark学习笔记-DSL语法</title>
    <link href="https://shang.at/post/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-DSL%E8%AF%AD%E6%B3%95/"/>
    <id>https://shang.at/post/Spark学习笔记-DSL语法/</id>
    <published>2019-03-31T02:20:06.000Z</published>
    <updated>2019-03-31T02:21:41.762Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="Spark" scheme="https://shang.at/categories/Spark/"/>
    
    
      <category term="sparkSql-DSL语法" scheme="https://shang.at/tags/sparkSql-DSL%E8%AF%AD%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>数据结构与算法学习笔记-排序算法</title>
    <link href="https://shang.at/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"/>
    <id>https://shang.at/post/数据结构与算法学习笔记-排序算法/</id>
    <published>2019-03-29T00:49:58.000Z</published>
    <updated>2019-05-12T00:22:00.390Z</updated>
    
    <content type="html"><![CDATA[<h3 id="O-n-2"><a href="#O-n-2" class="headerlink" title="O(n^2)"></a>O(n^2)</h3><h4 id="冒泡排序-Bubble-Sort"><a href="#冒泡排序-Bubble-Sort" class="headerlink" title="冒泡排序(Bubble Sort)"></a>冒泡排序(Bubble Sort)</h4><blockquote><p>算法描述</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否符合大小关系要求。如果不满足就互换位置。一次冒泡至少会让一个元素移动到它应该在的位置，重复n次，就完成了n个元素的排序工作。</span><br></pre></td></tr></table></figure><blockquote><p>算法实现</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubble_sort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    冒泡排序：从小到大</span></span><br><span class="line"><span class="string">    :param nums:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> len(nums) &lt;= <span class="number">1</span>:</span><br><span class="line">      <span class="keyword">return</span> nums</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums) - <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, len(nums)):</span><br><span class="line">            <span class="keyword">if</span> nums[i] &gt; nums[j]:</span><br><span class="line">                nums[i], nums[j] = nums[j], nums[i]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nums</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubble_sort1</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(nums) &lt;= <span class="number">1</span>:</span><br><span class="line">      <span class="keyword">return</span> nums</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums) - <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(nums) - <span class="number">1</span> - i):</span><br><span class="line">            <span class="keyword">if</span> nums[j] &gt; nums[j + i]:</span><br><span class="line">                nums[j], nums[j + <span class="number">1</span>] = nums[j + <span class="number">1</span>], nums[j]</span><br><span class="line">    <span class="keyword">return</span> nums</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    nums = [<span class="number">-23</span>, <span class="number">0</span>, <span class="number">6</span>, <span class="number">-4</span>, <span class="number">34</span>]</span><br><span class="line">    print(bubble_sort(nums))</span><br></pre></td></tr></table></figure><h4 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h4><blockquote><p>算法描述</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">将一个元素插入一个已经有序的序列，使其依然有序。首先，将原始的序列分为两个子序列，有序的和无序的，然后，从无序的序列中依次拿出一个元素，插入到有序的序列的合适位置，并保持有序的序列依然有序，直到无序的序列中没有元素了。</span><br></pre></td></tr></table></figure><blockquote><p>算法实现</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_sort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(nums) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> nums</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(nums)):</span><br><span class="line">        tmp = nums[i]</span><br><span class="line">        j = i - <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i - <span class="number">1</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">            <span class="keyword">if</span> tmp &lt; nums[j]:</span><br><span class="line">                nums[j + <span class="number">1</span>] = nums[j]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        nums[j + <span class="number">1</span>] = tmp</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nums</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    nums = [<span class="number">-23</span>, <span class="number">0</span>, <span class="number">6</span>, <span class="number">-4</span>, <span class="number">34</span>, <span class="number">2</span>]</span><br><span class="line">    print(insert_sort(nums))</span><br></pre></td></tr></table></figure><h4 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h4><blockquote><p>算法描述</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">选择排序是选择无序序列中的最小的元素放到有序序列的末尾，直到无序序列没有元素。</span><br></pre></td></tr></table></figure><blockquote><p>算法实现</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selection_sort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(nums) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> nums</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums) - <span class="number">1</span>):</span><br><span class="line">        min_val = nums[i]</span><br><span class="line">        min_j = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, len(nums)):</span><br><span class="line">            <span class="keyword">if</span> min_val &gt; nums[j]:</span><br><span class="line">                min_val = nums[j]</span><br><span class="line">                min_j = j</span><br><span class="line">        nums[i], nums[min_j] = nums[min_j], nums[i]</span><br><span class="line">    <span class="keyword">return</span> nums</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    nums = [<span class="number">-23</span>, <span class="number">0</span>, <span class="number">6</span>, <span class="number">-4</span>, <span class="number">34</span>, <span class="number">2</span>]</span><br><span class="line">    print(selection_sort(nums))</span><br></pre></td></tr></table></figure><h4 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h4><blockquote><p>算法描述</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">希尔排序是对插入排序的优化。</span><br><span class="line">希尔排序，通过将原始序列按照一定的步长划分为多个子序列</span><br><span class="line">将原始的一维数组映射成二维数组，</span><br><span class="line">然后按列进行插入排序，</span><br><span class="line">这样的话，可以让一个元素在一次比较中跨越较大的区间，随后算法在使用较小的步长，一直到步长为1</span><br><span class="line">(已知当对有序度较高数组进行排序时，插入排序的时间复杂度接近O(N)，因此可以大幅度提高插入排序的效率)。</span><br></pre></td></tr></table></figure><blockquote><p>常见的步长选择有</p></blockquote><p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1g1v89bmqd2j30oe082q9e.jpg" alt="image-20190408145100849"></p><blockquote><p>算法实现</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shell_sort</span><span class="params">(list)</span>:</span></span><br><span class="line">    n = len(list)</span><br><span class="line">    <span class="comment"># 初始步长</span></span><br><span class="line">    gap = n // <span class="number">2</span></span><br><span class="line">    <span class="keyword">while</span> gap &gt; <span class="number">0</span>:</span><br><span class="line">        print(gap)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(gap, n):</span><br><span class="line">            <span class="comment"># 每个步长进行插入排序</span></span><br><span class="line">            temp = list[i]</span><br><span class="line">            j = i</span><br><span class="line">            <span class="comment"># 插入排序</span></span><br><span class="line">            <span class="keyword">while</span> j &gt;= gap <span class="keyword">and</span> list[j - gap] &gt; temp:</span><br><span class="line">                list[j] = list[j - gap]</span><br><span class="line">                j -= gap</span><br><span class="line">                print(<span class="string">'inner='</span>, list)</span><br><span class="line">            list[j] = temp</span><br><span class="line">        print(list)</span><br><span class="line">        <span class="comment"># 得到新的步长</span></span><br><span class="line">        gap = gap // <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shell_sort1</span><span class="params">(collection)</span>:</span></span><br><span class="line">    <span class="comment"># Marcin Ciura's gap sequence</span></span><br><span class="line">    gaps = [<span class="number">701</span>, <span class="number">301</span>, <span class="number">132</span>, <span class="number">57</span>, <span class="number">23</span>, <span class="number">10</span>, <span class="number">4</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> gap <span class="keyword">in</span> gaps:</span><br><span class="line">        i = gap</span><br><span class="line">        <span class="keyword">while</span> i &lt; len(collection):</span><br><span class="line">            temp = collection[i]</span><br><span class="line">            j = i</span><br><span class="line">            <span class="keyword">while</span> j &gt;= gap <span class="keyword">and</span> collection[j - gap] &gt; temp:</span><br><span class="line">                collection[j] = collection[j - gap]</span><br><span class="line">                j -= gap</span><br><span class="line">            collection[j] = temp</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> collection</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    nums = [<span class="number">-23</span>, <span class="number">0</span>, <span class="number">6</span>, <span class="number">-4</span>, <span class="number">34</span>, <span class="number">2</span>]</span><br><span class="line">    print(<span class="string">'\n'</span>, shell_sort1(nums))</span><br></pre></td></tr></table></figure><h3 id="O-nlogn"><a href="#O-nlogn" class="headerlink" title="O(nlogn)"></a>O(nlogn)</h3><h4 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h4><blockquote><p>算法描述</p></blockquote><p>将数组分为两部分，分别排序，最后将两部分排好序的数组合并成一个有序的数组。利用递归的方式，重复上述过程。</p><blockquote><p>算法实现</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_sort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    print(<span class="string">'before='</span>, nums)</span><br><span class="line">    length = len(nums)</span><br><span class="line">    <span class="keyword">if</span> length &gt; <span class="number">1</span>:</span><br><span class="line">        midpoint = length // <span class="number">2</span></span><br><span class="line">        left_half = merge_sort(nums[:midpoint])</span><br><span class="line">        right_half = merge_sort(nums[midpoint:])</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        j = <span class="number">0</span></span><br><span class="line">        k = <span class="number">0</span></span><br><span class="line">        left_length = len(left_half)</span><br><span class="line">        right_length = len(right_half)</span><br><span class="line">        <span class="keyword">while</span> i &lt; left_length <span class="keyword">and</span> j &lt; right_length:</span><br><span class="line">            <span class="keyword">if</span> left_half[i] &lt; right_half[j]:</span><br><span class="line">                nums[k] = left_half[i]</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                nums[k] = right_half[j]</span><br><span class="line">                j += <span class="number">1</span></span><br><span class="line">            k += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> i &lt; left_length:</span><br><span class="line">            nums[k] = left_half[i]</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            k += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> j &lt; right_length:</span><br><span class="line">            nums[k] = right_half[j]</span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">            k += <span class="number">1</span></span><br><span class="line">    print(<span class="string">'after='</span>, nums)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nums</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    nums = [<span class="number">-23</span>, <span class="number">0</span>, <span class="number">6</span>, <span class="number">-4</span>, <span class="number">34</span>, <span class="number">2</span>]</span><br><span class="line">    print(<span class="string">'\n'</span>, merge_sort(nums))</span><br></pre></td></tr></table></figure><h4 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h4><blockquote><p>算法描述</p></blockquote><p>随机选择一个pivot节点，然后将少数组中的数据分成大于pivot和小于pivot的两部分，然后递归地将大于pivot和小于pivot的部分再按照相同的思路处理，直到每个pivot两端的部分都只有最多一个元素</p><blockquote><p>算法实现</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span><span class="params">(collection)</span>:</span></span><br><span class="line">    length = len(collection)</span><br><span class="line">    <span class="keyword">if</span> length &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> collection</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        pivot = collection[<span class="number">0</span>]</span><br><span class="line">        greater = [element <span class="keyword">for</span> element <span class="keyword">in</span> collection[<span class="number">1</span>:] <span class="keyword">if</span> element &gt; pivot]</span><br><span class="line">        lesser = [element <span class="keyword">for</span> element <span class="keyword">in</span> collection[<span class="number">1</span>:] <span class="keyword">if</span> element &lt;= pivot]</span><br><span class="line">        <span class="keyword">return</span> quick_sort(lesser) + [pivot] + quick_sort(greater)</span><br></pre></td></tr></table></figure><blockquote><p>O(n) 时间复杂度内求无序数组中的第 K 大元素</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 选择数组的最后一个元素，作为pivot，然后将数组的所有元素分为大于pivot和小于pivot的两部分，</span></span><br><span class="line"><span class="comment"># 如果 len(lesser) == k - 1，则返回pivot</span></span><br><span class="line"><span class="comment"># 如果 len(lesser) &gt;= k，则说明要查找的元素在小于pivot的部分，那么继续在lesser中查找</span></span><br><span class="line"><span class="comment"># 否则的话，说明要查找的元素在大于pivot的部分，那么继续在greater中查找</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_k_max</span><span class="params">(nums, k)</span>:</span></span><br><span class="line">    length = len(nums)</span><br><span class="line">    <span class="keyword">if</span> length &lt; k:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    pivot = nums[length - <span class="number">1</span>]</span><br><span class="line">    greater = [element <span class="keyword">for</span> element <span class="keyword">in</span> nums[:length - <span class="number">1</span>] <span class="keyword">if</span> element &gt; pivot]</span><br><span class="line">    lesser = [element <span class="keyword">for</span> element <span class="keyword">in</span> nums[:length - <span class="number">1</span>] <span class="keyword">if</span> element &lt;= pivot]</span><br><span class="line">    <span class="keyword">if</span> len(lesser) == k - <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> pivot</span><br><span class="line">    <span class="keyword">elif</span> len(lesser) &gt;= k:</span><br><span class="line">        <span class="keyword">return</span> find_k_max(lesser, k)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> find_k_max(greater, k - len(lesser) - <span class="number">1</span>)</span><br></pre></td></tr></table></figure><h4 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h4><blockquote><p>算法描述</p></blockquote><blockquote><p>算法实现</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="O-n"><a href="#O-n" class="headerlink" title="O(n)"></a>O(n)</h3><h4 id="计数排序"><a href="#计数排序" class="headerlink" title="计数排序"></a>计数排序</h4><blockquote><p>算法描述</p></blockquote><blockquote><p>算法实现</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="基数排序"><a href="#基数排序" class="headerlink" title="基数排序"></a>基数排序</h4><blockquote><p>算法描述</p></blockquote><blockquote><p>算法实现</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="桶排序"><a href="#桶排序" class="headerlink" title="桶排序"></a>桶排序</h4><blockquote><p>算法描述</p></blockquote><blockquote><p>算法实现</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><table><thead><tr><th>排序算法</th><th>时间复杂度</th><th>空间复杂度</th><th>稳定性</th><th>是否基于比较</th></tr></thead><tbody><tr><td>冒泡排序</td><td>O($$n^2$$)</td><td>O(1)</td><td>是</td><td>是</td></tr><tr><td>选择排序</td><td>O($$n^2$$)</td><td>O(1)</td><td>否</td><td>是</td></tr><tr><td>插入排序</td><td>O($$n^2$$)</td><td>O(1)</td><td>是</td><td>是</td></tr><tr><td>希尔排序</td><td>O($$nlog^2n$$)</td><td>O(1)</td><td>是</td><td>是</td></tr><tr><td>归并排序</td><td>O($$nlogn$$)</td><td>O(n)</td><td>是</td><td>是</td></tr><tr><td>快速排序</td><td>O($$nlogn$$)</td><td>O(1)</td><td>否</td><td>是</td></tr><tr><td>堆排序</td><td>O($$nlogn$$)</td><td></td><td></td><td>是</td></tr><tr><td>计数排序</td><td>O($$n$$)</td><td></td><td></td><td>否</td></tr><tr><td>计数排序</td><td>O($$n$$)</td><td></td><td></td><td>否</td></tr><tr><td>桶排序</td><td>O($$n$$)</td><td></td><td></td><td>否</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;O-n-2&quot;&gt;&lt;a href=&quot;#O-n-2&quot; class=&quot;headerlink&quot; title=&quot;O(n^2)&quot;&gt;&lt;/a&gt;O(n^2)&lt;/h3&gt;&lt;h4 id=&quot;冒泡排序-Bubble-Sort&quot;&gt;&lt;a href=&quot;#冒泡排序-Bubble-Sort&quot; class
      
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://shang.at/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="排序算法" scheme="https://shang.at/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>数据分析-reduce函数引发的</title>
    <link href="https://shang.at/post/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-reduce%E5%87%BD%E6%95%B0%E5%BC%95%E5%8F%91%E7%9A%84/"/>
    <id>https://shang.at/post/数据分析-reduce函数引发的/</id>
    <published>2019-03-28T05:35:25.000Z</published>
    <updated>2019-04-10T15:36:43.244Z</updated>
    
    <content type="html"><![CDATA[<h3 id="reduce-in-python"><a href="#reduce-in-python" class="headerlink" title="reduce in python"></a>reduce in python</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># _functools.reduce</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce</span><span class="params">(function, sequence, initial=None)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    reduce(function, sequence[, initial]) -&gt; value</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Apply a function of two arguments cumulatively to the items of a sequence,</span></span><br><span class="line"><span class="string">    from left to right, so as to reduce the sequence to a single value.</span></span><br><span class="line"><span class="string">    For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates</span></span><br><span class="line"><span class="string">    ((((1+2)+3)+4)+5).  If initial is present, it is placed before the items</span></span><br><span class="line"><span class="string">    of the sequence in the calculation, and serves as a default when the</span></span><br><span class="line"><span class="string">    sequence is empty.</span></span><br><span class="line"><span class="string">    :param function:给定的一个func，func具有两个参数，参数1是临时聚合值，参数2是序列中下一个待聚合的值</span></span><br><span class="line"><span class="string">    :param sequence:待处理的可迭代的序列</span></span><br><span class="line"><span class="string">    :param initial:聚合数据的初始值</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>工作原理：reduce函数对给定的序列遍历调用func函数，每次调用返回一个临时聚合值，直到整个序列遍历结束。如果设置了初始值，那么在第一次执行func函数的时候，会将func的参数1设置为初始值。</p><p>例子：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reduce(<span class="keyword">lambda</span> x, y: x+y, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"><span class="number">15</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reduce(<span class="keyword">lambda</span> x, y: x+y, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], <span class="number">100</span>)</span><br><span class="line"><span class="number">115</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reduce(<span class="keyword">lambda</span> x, y: str(x)+str(y), [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], <span class="string">''</span>)</span><br><span class="line"><span class="string">'12345'</span></span><br></pre></td></tr></table></figure><p>reduce函数不仅可以完成这种聚合的功能，还可以完成更加复杂的操作，</p><h3 id="reduce-amp-foldLeft-amp-foldRight-amp-reduce-in-scala"><a href="#reduce-amp-foldLeft-amp-foldRight-amp-reduce-in-scala" class="headerlink" title="reduce&amp;foldLeft&amp;foldRight&amp;reduce in scala"></a>reduce&amp;foldLeft&amp;foldRight&amp;reduce in scala</h3><p>### </p><h3 id="hive的UDAF"><a href="#hive的UDAF" class="headerlink" title="hive的UDAF"></a>hive的UDAF</h3><h3 id="spark的UDAF"><a href="#spark的UDAF" class="headerlink" title="spark的UDAF"></a>spark的UDAF</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;reduce-in-python&quot;&gt;&lt;a href=&quot;#reduce-in-python&quot; class=&quot;headerlink&quot; title=&quot;reduce in python&quot;&gt;&lt;/a&gt;reduce in python&lt;/h3&gt;&lt;figure class=&quot;hi
      
    
    </summary>
    
      <category term="数据分析" scheme="https://shang.at/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="reduce" scheme="https://shang.at/tags/reduce/"/>
    
      <category term="数据分析技巧" scheme="https://shang.at/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E5%B7%A7/"/>
    
      <category term="有初始值的聚合操作" scheme="https://shang.at/tags/%E6%9C%89%E5%88%9D%E5%A7%8B%E5%80%BC%E7%9A%84%E8%81%9A%E5%90%88%E6%93%8D%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>信贷数据统计的相关指标</title>
    <link href="https://shang.at/post/%E4%BF%A1%E8%B4%B7%E6%95%B0%E6%8D%AE%E7%BB%9F%E8%AE%A1%E7%9A%84%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/"/>
    <id>https://shang.at/post/信贷数据统计的相关指标/</id>
    <published>2019-03-22T11:19:47.000Z</published>
    <updated>2019-03-28T14:24:24.845Z</updated>
    
    <content type="html"><![CDATA[<h3 id="贷款类型"><a href="#贷款类型" class="headerlink" title="贷款类型"></a>贷款类型</h3><ul><li>等额本息贷款</li></ul><p>根据固定的还款时间，计算出应还的总利息，再加上本金，然后每个月平均等额的还款。</p><ul><li>等额本金贷款</li></ul><p>等额本金相对来说要简单一些，每月所还的本金是相同的，利息由每个月的剩余本金计算得出。</p><ul><li>固定点数贷款</li></ul><p>按照定义，我们在首次还款时先按固定的点数还一部分贷款，然后再按较低的利率还完剩余的贷款。</p><ul><li>双利率贷款</li></ul><p>前x个月以较低的r1利率还款，后m-x个月以较高的r2利率还款（假设还款总月数为m）</p><h3 id="相关指标"><a href="#相关指标" class="headerlink" title="相关指标"></a>相关指标</h3><ul><li>同比增长</li><li>环比增长</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;贷款类型&quot;&gt;&lt;a href=&quot;#贷款类型&quot; class=&quot;headerlink&quot; title=&quot;贷款类型&quot;&gt;&lt;/a&gt;贷款类型&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;等额本息贷款&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;根据固定的还款时间，计算出应还的总利息，再加上本金，然后每个月平均等额
      
    
    </summary>
    
      <category term="数据分析" scheme="https://shang.at/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="分析指标" scheme="https://shang.at/tags/%E5%88%86%E6%9E%90%E6%8C%87%E6%A0%87/"/>
    
  </entry>
  
  <entry>
    <title>airflow安装</title>
    <link href="https://shang.at/post/airflow%E5%AE%89%E8%A3%85/"/>
    <id>https://shang.at/post/airflow安装/</id>
    <published>2019-03-19T11:24:02.000Z</published>
    <updated>2019-03-24T01:33:47.230Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># airflow needs a home, ~/airflow is the default,</span><br><span class="line"># but you can lay foundation somewhere else if you prefer</span><br><span class="line"># (optional)</span><br><span class="line">export AIRFLOW_HOME=~/airflow</span><br><span class="line"></span><br><span class="line"># install from pypi using pip</span><br><span class="line">pip install apache-airflow</span><br><span class="line"></span><br><span class="line"># initialize the database</span><br><span class="line">airflow initdb</span><br><span class="line"></span><br><span class="line"># start the web server, default port is 8080</span><br><span class="line">airflow webserver -p 8080</span><br><span class="line"></span><br><span class="line"># start the scheduler</span><br><span class="line">airflow scheduler</span><br><span class="line"></span><br><span class="line"># visit localhost:8080 in the browser and enable the example dag in the home page</span><br></pre></td></tr></table></figure><h3 id="USE-Mysql"><a href="#USE-Mysql" class="headerlink" title="USE Mysql"></a>USE Mysql</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim $AIRFLOW_HOME/airflow.cfg</span><br><span class="line">sql_alchemy_conn = mysql+pymysql://root:123456@localhost:3306/airflow</span><br><span class="line">需要pip install pymysql</span><br></pre></td></tr></table></figure><h3 id="启动失败"><a href="#启动失败" class="headerlink" title="启动失败"></a>启动失败</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ERROR [airflow.models.DagBag] Failed to import: /anaconda3/lib/python3.7/site-packages/airflow/example_dags/example_http_operator.py</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/anaconda3/lib/python3.7/site-packages/airflow/models.py&quot;, line 374, in process_file</span><br><span class="line">    m = imp.load_source(mod_name, filepath)</span><br><span class="line">  File &quot;/anaconda3/lib/python3.7/imp.py&quot;, line 171, in load_source</span><br><span class="line">    module = _load(spec)</span><br><span class="line">  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 696, in _load</span><br><span class="line">  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 677, in _load_unlocked</span><br><span class="line">  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 728, in exec_module</span><br><span class="line">  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed</span><br><span class="line">  File &quot;/anaconda3/lib/python3.7/site-packages/airflow/example_dags/example_http_operator.py&quot;, line 27, in &lt;module&gt;</span><br><span class="line">    from airflow.operators.http_operator import SimpleHttpOperator</span><br><span class="line">  File &quot;/anaconda3/lib/python3.7/site-packages/airflow/operators/http_operator.py&quot;, line 21, in &lt;module&gt;</span><br><span class="line">    from airflow.hooks.http_hook import HttpHook</span><br><span class="line">  File &quot;/anaconda3/lib/python3.7/site-packages/airflow/hooks/http_hook.py&quot;, line 23, in &lt;module&gt;</span><br><span class="line">    import tenacity</span><br><span class="line">  File &quot;/anaconda3/lib/python3.7/site-packages/tenacity/__init__.py&quot;, line 352</span><br><span class="line">    from tenacity.async import AsyncRetrying</span><br><span class="line">                      ^</span><br><span class="line">SyntaxError: invalid syntax</span><br></pre></td></tr></table></figure><p>修复方式：修改from tenacity.async import AsyncRetrying为from tenacity.async_a import AsyncRetrying，同时tenacity包下的async文件名为async_a</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# airflow needs a home, ~/airflow is the default,&lt;/span&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Spark学习笔记-抽样方法和自增ID</title>
    <link href="https://shang.at/post/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%8A%BD%E6%A0%B7%E6%96%B9%E6%B3%95%E5%92%8C%E8%87%AA%E5%A2%9EID/"/>
    <id>https://shang.at/post/Spark学习笔记-抽样方法和自增ID/</id>
    <published>2019-03-19T08:33:24.000Z</published>
    <updated>2019-03-24T01:33:47.229Z</updated>
    
    <content type="html"><![CDATA[<h3 id="抽样方法"><a href="#抽样方法" class="headerlink" title="抽样方法"></a>抽样方法</h3><p><code>sample</code>(<em>withReplacement=None</em>, <em>fraction=None</em>, <em>seed=None</em>)</p><p>Returns a sampled subset of this <a href="http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame" target="_blank" rel="noopener"><code>DataFrame</code></a>.</p><ul><li><p><strong>withReplacement</strong> – Sample with replacement or not (default False).</p><ul><li>true时会将抽样的数据放回数据集，导致抽样数据有重复的</li><li>false时不会放回</li></ul></li><li><p><strong>fraction</strong> – Fraction of rows to generate, range [0.0, 1.0].</p><p>表示子集占数据集的占比</p></li><li><p><strong>seed</strong> – Seed for sampling (default a random seed).</p></li></ul><blockquote><p>fraction并不能保证完全按照占比抽样数据</p></blockquote><h3 id="自增ID"><a href="#自增ID" class="headerlink" title="自增ID"></a>自增ID</h3><p><code>monotonically_increasing_id()</code></p><p>每个分区分别排序生成一个64位的整数，但不是连续的。会将分区值放到高31位，然后将每条记录的序列放到低33位。限制：分区数不能大于10亿，每个分区的数据量不能大于80亿。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;抽样方法&quot;&gt;&lt;a href=&quot;#抽样方法&quot; class=&quot;headerlink&quot; title=&quot;抽样方法&quot;&gt;&lt;/a&gt;抽样方法&lt;/h3&gt;&lt;p&gt;&lt;code&gt;sample&lt;/code&gt;(&lt;em&gt;withReplacement=None&lt;/em&gt;, &lt;em&gt;fractio
      
    
    </summary>
    
      <category term="Spark" scheme="https://shang.at/categories/Spark/"/>
    
    
      <category term="Spark学习" scheme="https://shang.at/tags/Spark%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Spark学习笔记-SparkSQL内置函数</title>
    <link href="https://shang.at/post/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-SparkSQL%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/"/>
    <id>https://shang.at/post/Spark学习笔记-SparkSQL内置函数/</id>
    <published>2019-03-19T01:27:01.000Z</published>
    <updated>2019-04-10T15:36:43.243Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>学习SparkSQL中的一些内置函数</p></blockquote><h3 id="日期函数"><a href="#日期函数" class="headerlink" title="日期函数"></a>日期函数</h3><ul><li><p>获取默认时区</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">spark.conf.get(<span class="string">'spark.sql.session.timeZone'</span>)</span><br><span class="line"></span><br><span class="line">&gt;&gt; <span class="string">'Asia/Shanghai'</span></span><br></pre></td></tr></table></figure></li><li><p>获取当前时间</p><ul><li><p>获取当前日期：current_date()</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">spark.sql(<span class="string">"""</span></span><br><span class="line"><span class="string">    select current_date()</span></span><br><span class="line"><span class="string">"""</span>).toPandas()</span><br><span class="line"></span><br><span class="line">&gt;&gt; <span class="number">2019</span><span class="number">-03</span><span class="number">-19</span></span><br></pre></td></tr></table></figure></li><li><p>获取当前时间：current_timestamp()/now()</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">spark.sql(<span class="string">"""</span></span><br><span class="line"><span class="string">    select current_timestamp()</span></span><br><span class="line"><span class="string">"""</span>).toPandas()</span><br><span class="line"></span><br><span class="line">&gt;&gt; <span class="number">2019</span><span class="number">-03</span><span class="number">-19</span> <span class="number">13</span>:<span class="number">54</span>:<span class="number">22.236</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>从日期中截取字段</p><ul><li><p>截取年月日、时分秒:year,month,day/dayofmonth,hour,minute,second</p></li><li><p>dayofweek ,dayofyear</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1 = Sunday, 2 = Monday, ..., 7 = Saturday</span><br></pre></td></tr></table></figure></li><li><p>weekofyear</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Extract the week number of a given date as integer.</span><br></pre></td></tr></table></figure></li><li><p>trunc截取某部分的日期，其他部分默认为01</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Returns date truncated to the unit specified by the format.</span><br><span class="line"></span><br><span class="line">Parameters:format – ‘year’, ‘yyyy’, ‘yy’ or ‘month’, ‘mon’, ‘mm’</span><br></pre></td></tr></table></figure></li><li><p>date_trunc [“YEAR”, “YYYY”, “YY”, “MON”, “MONTH”, “MM”, “DAY”, “DD”, “HOUR”, “MINUTE”, “SECOND”, “WEEK”, “QUARTER”]</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Returns timestamp truncated to the unit specified by the format.</span><br><span class="line"></span><br><span class="line">Parameters:format – ‘year’, ‘yyyy’, ‘yy’, ‘month’, ‘mon’, ‘mm’, ‘day’, ‘dd’, ‘hour’, ‘minute’, ‘second’, ‘week’, ‘quarter’</span><br></pre></td></tr></table></figure></li><li><p>date_format将时间转化为某种格式的字符串</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Converts a date/timestamp/string to a value of string in the format specified by the date format given by the second argument.</span><br><span class="line"></span><br><span class="line">A pattern could be for instance dd.MM.yyyy and could return a string like ‘18.03.1993’. All pattern letters of the Java class java.text.SimpleDateFormat can be used.</span><br></pre></td></tr></table></figure></li></ul></li><li><p>日期时间转换</p><ul><li><p>unix_timestamp返回当前时间的unix时间戳</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Convert time string with given pattern (‘yyyy-MM-dd HH:mm:ss’, by default) to Unix time stamp (in seconds), using the default timezone and the default locale, return null if fail.</span><br><span class="line"></span><br><span class="line">if timestamp is None, then it returns current timestamp.</span><br></pre></td></tr></table></figure></li><li><p>from_unixtime将时间戳换算成当前时间，to_unix_timestamp将时间转化为时间戳</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Converts the number of seconds from unix epoch (1970-01-01 00:00:00 UTC) to a string representing the timestamp of that moment in the current system time zone in the given format.</span><br></pre></td></tr></table></figure></li><li><p>to_date/date将字符串转化为日期格式，to_timestamp（Since: 2.2.0）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Converts a Column of pyspark.sql.types.StringType or pyspark.sql.types.TimestampType into pyspark.sql.types.DateType using the optionally specified format. Specify formats according to SimpleDateFormats. By default, it follows casting rules to pyspark.sql.types.DateType if the format is omitted (equivalent to col.cast(&quot;date&quot;)).</span><br><span class="line"></span><br><span class="line">Converts a Column of pyspark.sql.types.StringType or pyspark.sql.types.TimestampType into pyspark.sql.types.DateType using the optionally specified format. Specify formats according to SimpleDateFormats. By default, it follows casting rules to pyspark.sql.types.TimestampType if the format is omitted (equivalent to col.cast(&quot;timestamp&quot;)).</span><br></pre></td></tr></table></figure></li><li><p>quarter 将1年4等分(range 1 to 4)</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Extract the quarter of a given date as integer.</span><br></pre></td></tr></table></figure></li></ul></li><li><p>日期、时间计算</p><ul><li>months_between两个日期之间的月数</li><li>add_months返回日期后n个月后的日期</li><li>last_day(date),next_day(start_date, day_of_week)</li><li>date_add,date_sub(减)</li><li>datediff（两个日期间的天数）</li></ul></li><li>utc</li></ul><blockquote><p>在集群中对于时间戳的转换，如果不指定时区，默认会采用集群配置的时区，集群默认时区可以通过如下方式获取：spark.conf.get(‘spark.sql.session.timeZone’)。一般而言，这个值应该是集群统一设置，独立提交job的时候，不需要设置。 </p></blockquote><ul><li><ul><li><p>to_utc_timestamp(timestamp, tz)</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">将timestamp按照给定的tz解释，返回utc timestamp</span><br></pre></td></tr></table></figure></li><li><p>from_utc_timestamp(timestamp, tz)</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">将timestamp按照utc解释，返回给定tz的timestamp</span><br></pre></td></tr></table></figure></li></ul></li></ul><blockquote><p>对于有时区相关的数据统计时，需要注意。比如：集群默认时区设置为UTC，一般将数据存到集群中的时候会将时间戳转为utc timestamp以便后续的操作。此时如果有一个需求是统计北京时间的当天的数据，那么第一个想到的方式是使用current_date()获取当前日期，然后将数据中的时间戳使用to_date(from_utc_timestamp(from_unixtime(ts), ‘Asia/Beijing’))，然后进行比较。但是current_date()获取的日期，是根据集群默认时区得来的，因此会有时区的不同导致的数据统计错误，因此，这种情况不能直接使用current_date()，正确的使用方式是：to_date(from_utc_timestamp(current_timestamp(), ‘Asia/Beijing’))，然后在进行比较。</p></blockquote><h3 id="表关联"><a href="#表关联" class="headerlink" title="表关联"></a>表关联</h3><ul><li><p>Join(<em>other</em>, <em>on=None</em>, <em>how=None</em>)</p><ul><li>on：a string for the join column name, a list of column names, a join expression (Column), or a list of Columns. If on is a string or a list of strings indicating the name of the join column(s), the column(s) must exist on both sides, and this performs an equi-join.</li><li>how：str, default <code>inner</code>. Must be one of: <code>inner</code>, <code>cross</code>, <code>outer</code>, <code>full</code>, <code>full_outer</code>, <code>left</code>, <code>left_outer</code>, <code>right</code>, <code>right_outer</code>, <code>left_semi</code>, and <code>left_anti</code><ul><li>inner:内连，返回joinDF1和joinDF2合并的rows，如果joinDF2中有多条记录对应于joinDF1的同一条记录，那么返回的row number会大于joinDF1的row number</li><li>outer,full,full_outer：全连</li><li>left, left_outer：左连</li><li>right，right_outer:右连</li><li>left_semi：过滤出joinDF1中和joinDF2共有的部分，只返回joinDF1中的rows</li><li>left_anti：过滤出joinDF1中joinDF2没有的部分，只返回joinDF1中的rows</li></ul></li></ul></li><li><p>crossJoin(<em>other</em>)</p></li></ul><blockquote><p>返回两个DF的笛卡尔积</p></blockquote><h3 id="Parses-the-expression"><a href="#Parses-the-expression" class="headerlink" title="Parses the expression"></a>Parses the expression</h3><ul><li>expr</li></ul><blockquote><p>将字符串表示的表达式，翻译成DSL</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">expr(<span class="string">"length(name)"</span>)</span><br><span class="line"></span><br><span class="line">expr(<span class="string">"array_contains(user_id_set, user_id)"</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;学习SparkSQL中的一些内置函数&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;日期函数&quot;&gt;&lt;a href=&quot;#日期函数&quot; class=&quot;headerlink&quot; title=&quot;日期函数&quot;&gt;&lt;/a&gt;日期函数&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;
      
    
    </summary>
    
      <category term="Spark" scheme="https://shang.at/categories/Spark/"/>
    
    
      <category term="sparkSql内置函数" scheme="https://shang.at/tags/sparkSql%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>数据分析小知识点</title>
    <link href="https://shang.at/post/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
    <id>https://shang.at/post/数据分析小知识点/</id>
    <published>2019-03-19T01:25:56.000Z</published>
    <updated>2019-08-03T02:17:49.591Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>总结一下在数据分析中需要注意的一些tips，持续更新</p></blockquote><h3 id="Tip1-时区"><a href="#Tip1-时区" class="headerlink" title="Tip1 时区"></a>Tip1 时区</h3><p>在进行跨境业务处理的时候，时区的控制是十分必要的。平时对于国内的业务，部署在国内的服务器，使用的时区一般都是北京时间(北京时间是UTC+8:00时区的时间，而UTC时间指UTC+0:00时区的时间)，在数据库中一般存储相对于unix epoch (1970-01-01 00:00:00 UTC)的毫秒时间戳，做某个地区的数据统计时，需要将时间戳转换成当地的时间(即加一个时区的属性)</p><p><a href="https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001431937554888869fb52b812243dda6103214cd61d0c2000" target="_blank" rel="noopener">https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001431937554888869fb52b812243dda6103214cd61d0c2000</a></p><h3 id="Tip-2-Excel函数"><a href="#Tip-2-Excel函数" class="headerlink" title="Tip 2 Excel函数"></a>Tip 2 Excel函数</h3><ul><li>去重计数：SUMPRODUCT(1/COUNTIF(A2:A20,A2:A20))</li><li>VLOOKUP(要查找的值,查找返回,返回查找到的第几列,是否精确查找[1])</li></ul><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p><em>落地页</em>，也称：着陆页、引导页，是指访问者在其他地方看到发出的某个具有明确主题的特定营销活动——通过Email、社交媒体或广告发布的诱人优惠信息等，点击后被链接到你网站上的第一个页面</p><p>PRD：产品需求文档，产品需求文档是将商业需求文档（BRD）和市场需求文档（MRD）用更加专业的语言进行描述</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;总结一下在数据分析中需要注意的一些tips，持续更新&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;Tip1-时区&quot;&gt;&lt;a href=&quot;#Tip1-时区&quot; class=&quot;headerlink&quot; title=&quot;Tip1 时区&quot;&gt;&lt;/a&gt;Tip1
      
    
    </summary>
    
      <category term="数据分析" scheme="https://shang.at/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="数据分析Tips" scheme="https://shang.at/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90Tips/"/>
    
  </entry>
  
  <entry>
    <title>Spark学习笔记-窗口函数</title>
    <link href="https://shang.at/post/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0/"/>
    <id>https://shang.at/post/Spark学习笔记-窗口函数/</id>
    <published>2019-03-12T02:15:03.000Z</published>
    <updated>2019-03-24T01:33:47.229Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Window</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StringType, StructField, IntegerType</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">'shop_id'</span>, StringType()),</span><br><span class="line">    StructField(<span class="string">'date'</span>, StringType()),</span><br><span class="line">    StructField(<span class="string">'amount'</span>, IntegerType())</span><br><span class="line">])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">spark = SparkSession \</span><br><span class="line">        .builder \</span><br><span class="line">        .master(<span class="string">'local[*]'</span>) \</span><br><span class="line">        .enableHiveSupport() \</span><br><span class="line">        .getOrCreate()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = [</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120030'</span>, <span class="string">'amount'</span>: <span class="number">2313</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120100'</span>, <span class="string">'amount'</span>: <span class="number">23112</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120130'</span>, <span class="string">'amount'</span>: <span class="number">23112</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120200'</span>, <span class="string">'amount'</span>: <span class="number">24234</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120230'</span>, <span class="string">'amount'</span>: <span class="number">132</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120300'</span>, <span class="string">'amount'</span>: <span class="number">31232</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120330'</span>, <span class="string">'amount'</span>: <span class="number">221313</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120400'</span>, <span class="string">'amount'</span>: <span class="number">2134</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120430'</span>, <span class="string">'amount'</span>: <span class="number">2231</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120500'</span>, <span class="string">'amount'</span>: <span class="number">2234</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120530'</span>, <span class="string">'amount'</span>: <span class="number">2234</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120600'</span>, <span class="string">'amount'</span>: <span class="number">231635</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120630'</span>, <span class="string">'amount'</span>: <span class="number">2536</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120700'</span>, <span class="string">'amount'</span>: <span class="number">425432</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120730'</span>, <span class="string">'amount'</span>: <span class="number">36362</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120800'</span>, <span class="string">'amount'</span>: <span class="number">5645622</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120830'</span>, <span class="string">'amount'</span>: <span class="number">34532</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120900'</span>, <span class="string">'amount'</span>: <span class="number">366642</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501120930'</span>, <span class="string">'amount'</span>: <span class="number">74632</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121000'</span>, <span class="string">'amount'</span>: <span class="number">63562</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121030'</span>, <span class="string">'amount'</span>: <span class="number">26353</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121100'</span>, <span class="string">'amount'</span>: <span class="number">2353</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121130'</span>, <span class="string">'amount'</span>: <span class="number">26352</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121200'</span>, <span class="string">'amount'</span>: <span class="number">254352</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121230'</span>, <span class="string">'amount'</span>: <span class="number">534236</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121300'</span>, <span class="string">'amount'</span>: <span class="number">35432</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121330'</span>, <span class="string">'amount'</span>: <span class="number">353462</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121400'</span>, <span class="string">'amount'</span>: <span class="number">64562</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121430'</span>, <span class="string">'amount'</span>: <span class="number">652562</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121500'</span>, <span class="string">'amount'</span>: <span class="number">2456</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121530'</span>, <span class="string">'amount'</span>: <span class="number">6422</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121600'</span>, <span class="string">'amount'</span>: <span class="number">422</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121630'</span>, <span class="string">'amount'</span>: <span class="number">27843</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121700'</span>, <span class="string">'amount'</span>: <span class="number">2362</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121730'</span>, <span class="string">'amount'</span>: <span class="number">24683</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121800'</span>, <span class="string">'amount'</span>: <span class="number">4532</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121830'</span>, <span class="string">'amount'</span>: <span class="number">5342</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121900'</span>, <span class="string">'amount'</span>: <span class="number">65642</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501121930'</span>, <span class="string">'amount'</span>: <span class="number">2534</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501122000'</span>, <span class="string">'amount'</span>: <span class="number">25376</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501122030'</span>, <span class="string">'amount'</span>: <span class="number">242443</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501122100'</span>, <span class="string">'amount'</span>: <span class="number">2344562</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501122130'</span>, <span class="string">'amount'</span>: <span class="number">5462</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501122200'</span>, <span class="string">'amount'</span>: <span class="number">2535</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501122230'</span>, <span class="string">'amount'</span>: <span class="number">242546</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501122300'</span>, <span class="string">'amount'</span>: <span class="number">6542</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501122330'</span>, <span class="string">'amount'</span>: <span class="number">2546</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'shop_id'</span>: <span class="string">'10006'</span>, <span class="string">'date'</span>: <span class="string">'201501130000'</span>, <span class="string">'amount'</span>: <span class="number">45245</span>&#125;,</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = spark.createDataFrame(data, schema)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- shop_id: string (nullable = true)</span><br><span class="line"> |-- date: string (nullable = true)</span><br><span class="line"> |-- amount: integer (nullable = true)</span><br></pre></td></tr></table></figure><p>关于子窗口：</p><p>子窗口需要指定一个边界，有以下两种方式：</p><ul><li>ROWS between CURRENT ROW | UNBOUNDED PRECEDING | [num] PRECEDING AND  UNBOUNDED FOLLOWING | [num] FOLLOWING| CURRENT ROW</li><li>RANGE between [num] PRECEDING  AND [num] FOLLOWING</li></ul><p>窗口的含义<br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g10643qf18j30de06h3yq.jpg" alt></p><p>ROWS是物理窗口，从行数上控制窗口的尺寸的；<br>RANGE是逻辑窗口，从列值上控制窗口的尺寸</p><p>通常会结合order by子句使用，如果在order by子句后面没有指定窗口子句，则默认为：rows between unbounded preceding and current row</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">spark中关于Window函数的学习</span><br><span class="line"></span><br><span class="line">在spark中涉及Window函数的主要有以下两个类和一个Column的方法</span><br><span class="line">pyspark.sql.column.Column#over   在窗口上应用某一种分析函数</span><br><span class="line">pyspark.sql.window.Window        创建WindowSpec的工具类</span><br><span class="line">    pyspark.sql.window.Window.unboundedPreceding</span><br><span class="line">    pyspark.sql.window.Window.unboundedFollowing</span><br><span class="line">    pyspark.sql.window.Window.currentRow</span><br><span class="line">    pyspark.sql.window.Window#partitionBy</span><br><span class="line">    pyspark.sql.window.Window#orderBy</span><br><span class="line">    pyspark.sql.window.Window#rowsBetween(start, end)</span><br><span class="line">    pyspark.sql.window.Window#rangeBetween(start, end)</span><br><span class="line">pyspark.sql.window.WindowSpec    窗口的规范</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pyspark.sql.window.Window#rowsBetween(start, end)</span><br><span class="line">定义窗口的边界，[start, end]，在边界处是闭区间</span><br><span class="line">start和end都是相对于当前row的相对位置，例如：</span><br><span class="line">- 0：当前row</span><br><span class="line">- -1：当前行的前1row</span><br><span class="line">- 5：当前行的后5row</span><br><span class="line">- (-1, 5)：窗口的范围为，当前row+当前行的前1row+当前行的后5row = 7rows</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.show(<span class="number">50</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+-------+------------+-------+</span><br><span class="line">|shop_id|        date| amount|</span><br><span class="line">+-------+------------+-------+</span><br><span class="line">|  10006|201501120030|   2313|</span><br><span class="line">|  10006|201501120100|  23112|</span><br><span class="line">|  10006|201501120130|   2342|</span><br><span class="line">|  10006|201501120200|  24234|</span><br><span class="line">|  10006|201501120230|    132|</span><br><span class="line">|  10006|201501120300|  31232|</span><br><span class="line">|  10006|201501120330| 221313|</span><br><span class="line">|  10006|201501120400|   2134|</span><br><span class="line">|  10006|201501120430|   2231|</span><br><span class="line">|  10006|201501120500|   2234|</span><br><span class="line">|  10006|201501120530|   2234|</span><br><span class="line">|  10006|201501120600| 231635|</span><br><span class="line">|  10006|201501120630|   2536|</span><br><span class="line">|  10006|201501120700| 425432|</span><br><span class="line">|  10006|201501120730|  36362|</span><br><span class="line">|  10006|201501120800|5645622|</span><br><span class="line">|  10006|201501120830|  34532|</span><br><span class="line">|  10006|201501120900| 366642|</span><br><span class="line">|  10006|201501120930|  74632|</span><br><span class="line">|  10006|201501121000|  63562|</span><br><span class="line">|  10006|201501121030|  26353|</span><br><span class="line">|  10006|201501121100|   2353|</span><br><span class="line">|  10006|201501121130|  26352|</span><br><span class="line">|  10006|201501121200| 254352|</span><br><span class="line">|  10006|201501121230| 534236|</span><br><span class="line">|  10006|201501121300|  35432|</span><br><span class="line">|  10006|201501121330| 353462|</span><br><span class="line">|  10006|201501121400|  64562|</span><br><span class="line">|  10006|201501121430| 652562|</span><br><span class="line">|  10006|201501121500|   2456|</span><br><span class="line">|  10006|201501121530|   6422|</span><br><span class="line">|  10006|201501121600|    422|</span><br><span class="line">|  10006|201501121630|  27843|</span><br><span class="line">|  10006|201501121700|   2362|</span><br><span class="line">|  10006|201501121730|  24683|</span><br><span class="line">|  10006|201501121800|   4532|</span><br><span class="line">|  10006|201501121830|   5342|</span><br><span class="line">|  10006|201501121900|  65642|</span><br><span class="line">|  10006|201501121930|   2534|</span><br><span class="line">|  10006|201501122000|  25376|</span><br><span class="line">|  10006|201501122030| 242443|</span><br><span class="line">|  10006|201501122100|2344562|</span><br><span class="line">|  10006|201501122130|   5462|</span><br><span class="line">|  10006|201501122200|   2535|</span><br><span class="line">|  10006|201501122230| 242546|</span><br><span class="line">|  10006|201501122300|   6542|</span><br><span class="line">|  10006|201501122330|   2546|</span><br><span class="line">|  10006|201501130000|  45245|</span><br><span class="line">+-------+------------+-------+</span><br></pre></td></tr></table></figure><p>1.统计截止到当前时间段的店铺累计销售金额</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.withColumn(</span><br><span class="line">    <span class="string">'t_amount'</span>,</span><br><span class="line">    sum(<span class="string">'amount'</span>).over(Window.partitionBy(<span class="string">'shop_id'</span>).orderBy(asc(<span class="string">'date'</span>)))</span><br><span class="line">).select(</span><br><span class="line">    <span class="string">'shop_id'</span>, <span class="string">'date'</span>, <span class="string">'t_amount'</span></span><br><span class="line">).show(<span class="number">50</span>, truncate=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+-------+------------+--------+</span><br><span class="line">|shop_id|date        |t_amount|</span><br><span class="line">+-------+------------+--------+</span><br><span class="line">|10006  |201501120030|2313    |</span><br><span class="line">|10006  |201501120100|25425   |</span><br><span class="line">|10006  |201501120130|27767   |</span><br><span class="line">|10006  |201501120200|52001   |</span><br><span class="line">|10006  |201501120230|52133   |</span><br><span class="line">|10006  |201501120300|83365   |</span><br><span class="line">|10006  |201501120330|304678  |</span><br><span class="line">|10006  |201501120400|306812  |</span><br><span class="line">|10006  |201501120430|309043  |</span><br><span class="line">|10006  |201501120500|311277  |</span><br><span class="line">|10006  |201501120530|313511  |</span><br><span class="line">|10006  |201501120600|545146  |</span><br><span class="line">|10006  |201501120630|547682  |</span><br><span class="line">|10006  |201501120700|973114  |</span><br><span class="line">|10006  |201501120730|1009476 |</span><br><span class="line">|10006  |201501120800|6655098 |</span><br><span class="line">|10006  |201501120830|6689630 |</span><br><span class="line">|10006  |201501120900|7056272 |</span><br><span class="line">|10006  |201501120930|7130904 |</span><br><span class="line">|10006  |201501121000|7194466 |</span><br><span class="line">|10006  |201501121030|7220819 |</span><br><span class="line">|10006  |201501121100|7223172 |</span><br><span class="line">|10006  |201501121130|7249524 |</span><br><span class="line">|10006  |201501121200|7503876 |</span><br><span class="line">|10006  |201501121230|8038112 |</span><br><span class="line">|10006  |201501121300|8073544 |</span><br><span class="line">|10006  |201501121330|8427006 |</span><br><span class="line">|10006  |201501121400|8491568 |</span><br><span class="line">|10006  |201501121430|9144130 |</span><br><span class="line">|10006  |201501121500|9146586 |</span><br><span class="line">|10006  |201501121530|9153008 |</span><br><span class="line">|10006  |201501121600|9153430 |</span><br><span class="line">|10006  |201501121630|9181273 |</span><br><span class="line">|10006  |201501121700|9183635 |</span><br><span class="line">|10006  |201501121730|9208318 |</span><br><span class="line">|10006  |201501121800|9212850 |</span><br><span class="line">|10006  |201501121830|9218192 |</span><br><span class="line">|10006  |201501121900|9283834 |</span><br><span class="line">|10006  |201501121930|9286368 |</span><br><span class="line">|10006  |201501122000|9311744 |</span><br><span class="line">|10006  |201501122030|9554187 |</span><br><span class="line">|10006  |201501122100|11898749|</span><br><span class="line">|10006  |201501122130|11904211|</span><br><span class="line">|10006  |201501122200|11906746|</span><br><span class="line">|10006  |201501122230|12149292|</span><br><span class="line">|10006  |201501122300|12155834|</span><br><span class="line">|10006  |201501122330|12158380|</span><br><span class="line">|10006  |201501130000|12203625|</span><br><span class="line">+-------+------------+--------+</span><br></pre></td></tr></table></figure><p>分析：<br>根据shop_id分组，根据date正序排列，由于orderBy后面没有追加rowsBetween()，则默认的rowsBetween为：[Window.unboundedPreceding，Window.currentRow]。即会统计根据date排序后，从第一行计算到当前行，从而达到了<code>统计截止到当前时间段的店铺累计销售金额</code>的效果</p><p>2.统计每个时间段的销售占比</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.withColumn(</span><br><span class="line">    <span class="string">'t_amount'</span>,</span><br><span class="line">    col(<span class="string">'amount'</span>)/sum(<span class="string">'amount'</span>).over(Window.partitionBy(<span class="string">'shop_id'</span>))</span><br><span class="line">).select(</span><br><span class="line">    <span class="string">'shop_id'</span>, <span class="string">'date'</span>, <span class="string">'amount'</span>,<span class="string">'t_amount'</span></span><br><span class="line">).show(<span class="number">50</span>, truncate=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+-------+------------+-------+---------------------+</span><br><span class="line">|shop_id|date        |amount |t_amount             |</span><br><span class="line">+-------+------------+-------+---------------------+</span><br><span class="line">|10006  |201501120030|2313   |1.8953384752481333E-4|</span><br><span class="line">|10006  |201501120100|23112  |0.0018938635036720647|</span><br><span class="line">|10006  |201501120130|2342   |1.919101906195905E-4 |</span><br><span class="line">|10006  |201501120200|24234  |0.0019858033985803397|</span><br><span class="line">|10006  |201501120230|132    |1.0816458224502965E-5|</span><br><span class="line">|10006  |201501120300|31232  |0.002559239570209671 |</span><br><span class="line">|10006  |201501120330|221313 |0.01813502135635928  |</span><br><span class="line">|10006  |201501120400|2134   |1.748660746294646E-4 |</span><br><span class="line">|10006  |201501120430|2231   |1.8281453256716753E-4|</span><br><span class="line">|10006  |201501120500|2234   |1.8306036116317898E-4|</span><br><span class="line">|10006  |201501120530|2234   |1.8306036116317898E-4|</span><br><span class="line">|10006  |201501120600|231635 |0.018980835612369275 |</span><br><span class="line">|10006  |201501120630|2536   |2.0780710649499637E-4|</span><br><span class="line">|10006  |201501120700|425432 |0.03486111708611171  |</span><br><span class="line">|10006  |201501120730|36362  |0.0029796064693892186|</span><br><span class="line">|10006  |201501120800|5645622|0.46261844329041574  |</span><br><span class="line">|10006  |201501120830|34532  |0.0028296510258222453|</span><br><span class="line">|10006  |201501120900|366642 |0.030043696032941034 |</span><br><span class="line">|10006  |201501120930|74632  |0.006115559925841707 |</span><br><span class="line">|10006  |201501121000|63562  |0.005208452406559526 |</span><br><span class="line">|10006  |201501121030|26353  |0.0021594403302297475|</span><br><span class="line">|10006  |201501121100|2353   |1.9281156213829908E-4|</span><br><span class="line">|10006  |201501121130|26352  |0.00215935838736441  |</span><br><span class="line">|10006  |201501121200|254352 |0.02084233168423317  |</span><br><span class="line">|10006  |201501121230|534236 |0.04377682860625429  |</span><br><span class="line">|10006  |201501121300|35432  |0.0029033996046256747|</span><br><span class="line">|10006  |201501121330|353462 |0.028963689067797477 |</span><br><span class="line">|10006  |201501121400|64562  |0.00529039527189667  |</span><br><span class="line">|10006  |201501121430|652562 |0.05347280009013715  |</span><br><span class="line">|10006  |201501121500|2456   |2.0125167726802487E-4|</span><br><span class="line">|10006  |201501121530|6422   |5.262370811951367E-4 |</span><br><span class="line">|10006  |201501121600|422    |3.457988917227463E-5 |</span><br><span class="line">|10006  |201501121630|27843  |0.002281535199582091 |</span><br><span class="line">|10006  |201501121700|2362   |1.9354904792633337E-4|</span><br><span class="line">|10006  |201501121730|24683  |0.0020225957451167173|</span><br><span class="line">|10006  |201501121800|4532   |3.7136506570793515E-4|</span><br><span class="line">|10006  |201501121830|5342   |4.377387866310215E-4 |</span><br><span class="line">|10006  |201501121900|65642  |0.0053788935664607854|</span><br><span class="line">|10006  |201501121930|2534   |2.0764322076432208E-4|</span><br><span class="line">|10006  |201501122000|25376  |0.002079382150795358 |</span><br><span class="line">|10006  |201501122030|242443 |0.019866474100933125 |</span><br><span class="line">|10006  |201501122100|2344562|0.19212012824058425  |</span><br><span class="line">|10006  |201501122130|5462   |4.4757193047147874E-4|</span><br><span class="line">|10006  |201501122200|2535   |2.0772516362965921E-4|</span><br><span class="line">|10006  |201501122230|242546 |0.01987491421606285  |</span><br><span class="line">|10006  |201501122300|6542   |5.360702250355939E-4 |</span><br><span class="line">|10006  |201501122330|2546   |2.086265351483678E-4 |</span><br><span class="line">|10006  |201501130000|45245  |0.0037075049421790656|</span><br><span class="line">+-------+------------+-------+---------------------+</span><br></pre></td></tr></table></figure><p>分析：<br>根据shop_id分组，不排序，窗口大小默认就是整个分组。</p><p>3.找出2点的销售金额及前半小时的销售金额和后1个小时的销售金额</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.withColumn(</span><br><span class="line">    <span class="string">'pre_half_hour'</span>,</span><br><span class="line">    lag(<span class="string">'date'</span>, <span class="number">1</span>).over(Window.partitionBy(<span class="string">'shop_id'</span>).orderBy(asc(<span class="string">'date'</span>)))</span><br><span class="line">).withColumn(</span><br><span class="line">    <span class="string">'pre_half_hour_amount'</span>,</span><br><span class="line">    lag(<span class="string">'amount'</span>, <span class="number">1</span>).over(Window.partitionBy(<span class="string">'shop_id'</span>).orderBy(asc(<span class="string">'date'</span>)))</span><br><span class="line">).withColumn(</span><br><span class="line">    <span class="string">'follow_one_hour'</span>,</span><br><span class="line">    lead(<span class="string">'date'</span>, <span class="number">2</span>).over(Window.partitionBy(<span class="string">'shop_id'</span>).orderBy(asc(<span class="string">'date'</span>)))</span><br><span class="line">).withColumn(</span><br><span class="line">    <span class="string">'follow_one_hour_amount'</span>,</span><br><span class="line">    lead(<span class="string">'amount'</span>, <span class="number">2</span>).over(Window.partitionBy(<span class="string">'shop_id'</span>).orderBy(asc(<span class="string">'date'</span>)))</span><br><span class="line">).filter(</span><br><span class="line">    col(<span class="string">'date'</span>) == <span class="string">'201501120200'</span></span><br><span class="line">).select(</span><br><span class="line">    <span class="string">'shop_id'</span>, <span class="string">'date'</span>, <span class="string">'amount'</span>,<span class="string">'pre_half_hour'</span>, <span class="string">'pre_half_hour_amount'</span>, <span class="string">'follow_one_hour'</span>, <span class="string">'follow_one_hour_amount'</span></span><br><span class="line">).show(truncate=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+-------+------------+------+-------------+--------------------+---------------+----------------------+</span><br><span class="line">|shop_id|date        |amount|pre_half_hour|pre_half_hour_amount|follow_one_hour|follow_one_hour_amount|</span><br><span class="line">+-------+------------+------+-------------+--------------------+---------------+----------------------+</span><br><span class="line">|10006  |201501120200|24234 |201501120130 |2342                |201501120300   |31232                 |</span><br><span class="line">+-------+------------+------+-------------+--------------------+---------------+----------------------+</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">分析：</span><br><span class="line">pyspark.sql.functions.lag(col, count=1, default=none)</span><br><span class="line">是取前N行的值</span><br><span class="line"></span><br><span class="line">pyspark.sql.functions.lead(col, count=1, default=none)</span><br><span class="line">是取后N行的值。</span><br></pre></td></tr></table></figure><p>4.按照销售金额进行排名，金额最大的排最前（limit可以取topn的数）</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.withColumn(</span><br><span class="line">    <span class="string">'rn'</span>,</span><br><span class="line">    dense_rank().over(Window.partitionBy(<span class="string">'shop_id'</span>).orderBy(desc(<span class="string">'amount'</span>)))</span><br><span class="line">).select(</span><br><span class="line">    <span class="string">'shop_id'</span>, <span class="string">'date'</span>, <span class="string">'amount'</span>, <span class="string">'rn'</span>    </span><br><span class="line">).show(<span class="number">50</span>, truncate=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+-------+------------+-------+---+</span><br><span class="line">|shop_id|date        |amount |rn |</span><br><span class="line">+-------+------------+-------+---+</span><br><span class="line">|10006  |201501120800|5645622|1  |</span><br><span class="line">|10006  |201501122100|2344562|2  |</span><br><span class="line">|10006  |201501121430|652562 |3  |</span><br><span class="line">|10006  |201501121230|534236 |4  |</span><br><span class="line">|10006  |201501120700|425432 |5  |</span><br><span class="line">|10006  |201501120900|366642 |6  |</span><br><span class="line">|10006  |201501121330|353462 |7  |</span><br><span class="line">|10006  |201501121200|254352 |8  |</span><br><span class="line">|10006  |201501122230|242546 |9  |</span><br><span class="line">|10006  |201501122030|242443 |10 |</span><br><span class="line">|10006  |201501120600|231635 |11 |</span><br><span class="line">|10006  |201501120330|221313 |12 |</span><br><span class="line">|10006  |201501120930|74632  |13 |</span><br><span class="line">|10006  |201501121900|65642  |14 |</span><br><span class="line">|10006  |201501121400|64562  |15 |</span><br><span class="line">|10006  |201501121000|63562  |16 |</span><br><span class="line">|10006  |201501130000|45245  |17 |</span><br><span class="line">|10006  |201501120730|36362  |18 |</span><br><span class="line">|10006  |201501121300|35432  |19 |</span><br><span class="line">|10006  |201501120830|34532  |20 |</span><br><span class="line">|10006  |201501120300|31232  |21 |</span><br><span class="line">|10006  |201501121630|27843  |22 |</span><br><span class="line">|10006  |201501121030|26353  |23 |</span><br><span class="line">|10006  |201501121130|26352  |24 |</span><br><span class="line">|10006  |201501122000|25376  |25 |</span><br><span class="line">|10006  |201501121730|24683  |26 |</span><br><span class="line">|10006  |201501120200|24234  |27 |</span><br><span class="line">|10006  |201501120100|23112  |28 |</span><br><span class="line">|10006  |201501120130|23112  |28 |</span><br><span class="line">|10006  |201501122300|6542   |29 |</span><br><span class="line">|10006  |201501121530|6422   |30 |</span><br><span class="line">|10006  |201501122130|5462   |31 |</span><br><span class="line">|10006  |201501121830|5342   |32 |</span><br><span class="line">|10006  |201501121800|4532   |33 |</span><br><span class="line">|10006  |201501122330|2546   |34 |</span><br><span class="line">|10006  |201501120630|2536   |35 |</span><br><span class="line">|10006  |201501122200|2535   |36 |</span><br><span class="line">|10006  |201501121930|2534   |37 |</span><br><span class="line">|10006  |201501121500|2456   |38 |</span><br><span class="line">|10006  |201501121700|2362   |39 |</span><br><span class="line">|10006  |201501121100|2353   |40 |</span><br><span class="line">|10006  |201501120030|2313   |41 |</span><br><span class="line">|10006  |201501120500|2234   |42 |</span><br><span class="line">|10006  |201501120530|2234   |42 |</span><br><span class="line">|10006  |201501120430|2231   |43 |</span><br><span class="line">|10006  |201501120400|2134   |44 |</span><br><span class="line">|10006  |201501121600|422    |45 |</span><br><span class="line">|10006  |201501120230|132    |46 |</span><br><span class="line">+-------+------------+-------+---+</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.withColumn(</span><br><span class="line">    <span class="string">'rn'</span>,</span><br><span class="line">    rank().over(Window.partitionBy(<span class="string">'shop_id'</span>).orderBy(desc(<span class="string">'amount'</span>)))</span><br><span class="line">).select(</span><br><span class="line">    <span class="string">'shop_id'</span>, <span class="string">'date'</span>, <span class="string">'amount'</span>, <span class="string">'rn'</span>    </span><br><span class="line">).show(<span class="number">50</span>, truncate=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+-------+------------+-------+---+</span><br><span class="line">|shop_id|date        |amount |rn |</span><br><span class="line">+-------+------------+-------+---+</span><br><span class="line">|10006  |201501120800|5645622|1  |</span><br><span class="line">|10006  |201501122100|2344562|2  |</span><br><span class="line">|10006  |201501121430|652562 |3  |</span><br><span class="line">|10006  |201501121230|534236 |4  |</span><br><span class="line">|10006  |201501120700|425432 |5  |</span><br><span class="line">|10006  |201501120900|366642 |6  |</span><br><span class="line">|10006  |201501121330|353462 |7  |</span><br><span class="line">|10006  |201501121200|254352 |8  |</span><br><span class="line">|10006  |201501122230|242546 |9  |</span><br><span class="line">|10006  |201501122030|242443 |10 |</span><br><span class="line">|10006  |201501120600|231635 |11 |</span><br><span class="line">|10006  |201501120330|221313 |12 |</span><br><span class="line">|10006  |201501120930|74632  |13 |</span><br><span class="line">|10006  |201501121900|65642  |14 |</span><br><span class="line">|10006  |201501121400|64562  |15 |</span><br><span class="line">|10006  |201501121000|63562  |16 |</span><br><span class="line">|10006  |201501130000|45245  |17 |</span><br><span class="line">|10006  |201501120730|36362  |18 |</span><br><span class="line">|10006  |201501121300|35432  |19 |</span><br><span class="line">|10006  |201501120830|34532  |20 |</span><br><span class="line">|10006  |201501120300|31232  |21 |</span><br><span class="line">|10006  |201501121630|27843  |22 |</span><br><span class="line">|10006  |201501121030|26353  |23 |</span><br><span class="line">|10006  |201501121130|26352  |24 |</span><br><span class="line">|10006  |201501122000|25376  |25 |</span><br><span class="line">|10006  |201501121730|24683  |26 |</span><br><span class="line">|10006  |201501120200|24234  |27 |</span><br><span class="line">|10006  |201501120100|23112  |28 |</span><br><span class="line">|10006  |201501120130|23112  |28 |</span><br><span class="line">|10006  |201501122300|6542   |30 |</span><br><span class="line">|10006  |201501121530|6422   |31 |</span><br><span class="line">|10006  |201501122130|5462   |32 |</span><br><span class="line">|10006  |201501121830|5342   |33 |</span><br><span class="line">|10006  |201501121800|4532   |34 |</span><br><span class="line">|10006  |201501122330|2546   |35 |</span><br><span class="line">|10006  |201501120630|2536   |36 |</span><br><span class="line">|10006  |201501122200|2535   |37 |</span><br><span class="line">|10006  |201501121930|2534   |38 |</span><br><span class="line">|10006  |201501121500|2456   |39 |</span><br><span class="line">|10006  |201501121700|2362   |40 |</span><br><span class="line">|10006  |201501121100|2353   |41 |</span><br><span class="line">|10006  |201501120030|2313   |42 |</span><br><span class="line">|10006  |201501120500|2234   |43 |</span><br><span class="line">|10006  |201501120530|2234   |43 |</span><br><span class="line">|10006  |201501120430|2231   |45 |</span><br><span class="line">|10006  |201501120400|2134   |46 |</span><br><span class="line">|10006  |201501121600|422    |47 |</span><br><span class="line">|10006  |201501120230|132    |48 |</span><br><span class="line">+-------+------------+-------+---+</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.withColumn(</span><br><span class="line">    <span class="string">'rn'</span>,</span><br><span class="line">    row_number().over(Window.partitionBy(<span class="string">'shop_id'</span>).orderBy(desc(<span class="string">'amount'</span>)))</span><br><span class="line">).select(</span><br><span class="line">    <span class="string">'shop_id'</span>, <span class="string">'date'</span>, <span class="string">'amount'</span>, <span class="string">'rn'</span>    </span><br><span class="line">).show(<span class="number">50</span>, truncate=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+-------+------------+-------+---+</span><br><span class="line">|shop_id|date        |amount |rn |</span><br><span class="line">+-------+------------+-------+---+</span><br><span class="line">|10006  |201501120800|5645622|1  |</span><br><span class="line">|10006  |201501122100|2344562|2  |</span><br><span class="line">|10006  |201501121430|652562 |3  |</span><br><span class="line">|10006  |201501121230|534236 |4  |</span><br><span class="line">|10006  |201501120700|425432 |5  |</span><br><span class="line">|10006  |201501120900|366642 |6  |</span><br><span class="line">|10006  |201501121330|353462 |7  |</span><br><span class="line">|10006  |201501121200|254352 |8  |</span><br><span class="line">|10006  |201501122230|242546 |9  |</span><br><span class="line">|10006  |201501122030|242443 |10 |</span><br><span class="line">|10006  |201501120600|231635 |11 |</span><br><span class="line">|10006  |201501120330|221313 |12 |</span><br><span class="line">|10006  |201501120930|74632  |13 |</span><br><span class="line">|10006  |201501121900|65642  |14 |</span><br><span class="line">|10006  |201501121400|64562  |15 |</span><br><span class="line">|10006  |201501121000|63562  |16 |</span><br><span class="line">|10006  |201501130000|45245  |17 |</span><br><span class="line">|10006  |201501120730|36362  |18 |</span><br><span class="line">|10006  |201501121300|35432  |19 |</span><br><span class="line">|10006  |201501120830|34532  |20 |</span><br><span class="line">|10006  |201501120300|31232  |21 |</span><br><span class="line">|10006  |201501121630|27843  |22 |</span><br><span class="line">|10006  |201501121030|26353  |23 |</span><br><span class="line">|10006  |201501121130|26352  |24 |</span><br><span class="line">|10006  |201501122000|25376  |25 |</span><br><span class="line">|10006  |201501121730|24683  |26 |</span><br><span class="line">|10006  |201501120200|24234  |27 |</span><br><span class="line">|10006  |201501120100|23112  |28 |</span><br><span class="line">|10006  |201501120130|23112  |29 |</span><br><span class="line">|10006  |201501122300|6542   |30 |</span><br><span class="line">|10006  |201501121530|6422   |31 |</span><br><span class="line">|10006  |201501122130|5462   |32 |</span><br><span class="line">|10006  |201501121830|5342   |33 |</span><br><span class="line">|10006  |201501121800|4532   |34 |</span><br><span class="line">|10006  |201501122330|2546   |35 |</span><br><span class="line">|10006  |201501120630|2536   |36 |</span><br><span class="line">|10006  |201501122200|2535   |37 |</span><br><span class="line">|10006  |201501121930|2534   |38 |</span><br><span class="line">|10006  |201501121500|2456   |39 |</span><br><span class="line">|10006  |201501121700|2362   |40 |</span><br><span class="line">|10006  |201501121100|2353   |41 |</span><br><span class="line">|10006  |201501120030|2313   |42 |</span><br><span class="line">|10006  |201501120500|2234   |43 |</span><br><span class="line">|10006  |201501120530|2234   |44 |</span><br><span class="line">|10006  |201501120430|2231   |45 |</span><br><span class="line">|10006  |201501120400|2134   |46 |</span><br><span class="line">|10006  |201501121600|422    |47 |</span><br><span class="line">|10006  |201501120230|132    |48 |</span><br><span class="line">+-------+------------+-------+---+</span><br></pre></td></tr></table></figure><p>分析：<br>dense_rank和rank都是排名函数，区别在于dense_rank是连续排名，rank遇到排名并列时，下一列排名跳空。<br>row_number是加行号，次序是连续的，不会存在重复的行号</p><p>5.按销售金额排序，取出前20%的时间段和相应金额</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.withColumn(</span><br><span class="line">    <span class="string">'tile'</span>,</span><br><span class="line">    ntile(<span class="number">5</span>).over(Window.partitionBy(<span class="string">'shop_id'</span>).orderBy(desc(<span class="string">'amount'</span>)))</span><br><span class="line">).select(</span><br><span class="line">    <span class="string">'shop_id'</span>, <span class="string">'date'</span>, <span class="string">'amount'</span>, <span class="string">'tile'</span>    </span><br><span class="line">).show(<span class="number">50</span>, truncate=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+-------+------------+-------+----+</span><br><span class="line">|shop_id|date        |amount |tile|</span><br><span class="line">+-------+------------+-------+----+</span><br><span class="line">|10006  |201501120800|5645622|1   |</span><br><span class="line">|10006  |201501122100|2344562|1   |</span><br><span class="line">|10006  |201501121430|652562 |1   |</span><br><span class="line">|10006  |201501121230|534236 |1   |</span><br><span class="line">|10006  |201501120700|425432 |1   |</span><br><span class="line">|10006  |201501120900|366642 |1   |</span><br><span class="line">|10006  |201501121330|353462 |1   |</span><br><span class="line">|10006  |201501121200|254352 |1   |</span><br><span class="line">|10006  |201501122230|242546 |1   |</span><br><span class="line">|10006  |201501122030|242443 |1   |</span><br><span class="line">|10006  |201501120600|231635 |2   |</span><br><span class="line">|10006  |201501120330|221313 |2   |</span><br><span class="line">|10006  |201501120930|74632  |2   |</span><br><span class="line">|10006  |201501121900|65642  |2   |</span><br><span class="line">|10006  |201501121400|64562  |2   |</span><br><span class="line">|10006  |201501121000|63562  |2   |</span><br><span class="line">|10006  |201501130000|45245  |2   |</span><br><span class="line">|10006  |201501120730|36362  |2   |</span><br><span class="line">|10006  |201501121300|35432  |2   |</span><br><span class="line">|10006  |201501120830|34532  |2   |</span><br><span class="line">|10006  |201501120300|31232  |3   |</span><br><span class="line">|10006  |201501121630|27843  |3   |</span><br><span class="line">|10006  |201501121030|26353  |3   |</span><br><span class="line">|10006  |201501121130|26352  |3   |</span><br><span class="line">|10006  |201501122000|25376  |3   |</span><br><span class="line">|10006  |201501121730|24683  |3   |</span><br><span class="line">|10006  |201501120200|24234  |3   |</span><br><span class="line">|10006  |201501120100|23112  |3   |</span><br><span class="line">|10006  |201501120130|23112  |3   |</span><br><span class="line">|10006  |201501122300|6542   |3   |</span><br><span class="line">|10006  |201501121530|6422   |4   |</span><br><span class="line">|10006  |201501122130|5462   |4   |</span><br><span class="line">|10006  |201501121830|5342   |4   |</span><br><span class="line">|10006  |201501121800|4532   |4   |</span><br><span class="line">|10006  |201501122330|2546   |4   |</span><br><span class="line">|10006  |201501120630|2536   |4   |</span><br><span class="line">|10006  |201501122200|2535   |4   |</span><br><span class="line">|10006  |201501121930|2534   |4   |</span><br><span class="line">|10006  |201501121500|2456   |4   |</span><br><span class="line">|10006  |201501121700|2362   |5   |</span><br><span class="line">|10006  |201501121100|2353   |5   |</span><br><span class="line">|10006  |201501120030|2313   |5   |</span><br><span class="line">|10006  |201501120500|2234   |5   |</span><br><span class="line">|10006  |201501120530|2234   |5   |</span><br><span class="line">|10006  |201501120430|2231   |5   |</span><br><span class="line">|10006  |201501120400|2134   |5   |</span><br><span class="line">|10006  |201501121600|422    |5   |</span><br><span class="line">|10006  |201501120230|132    |5   |</span><br><span class="line">+-------+------------+-------+----+</span><br></pre></td></tr></table></figure><p>分析：</p><p>NTILE就是把有序分区中的行分发到指定数据的组中，各个组有编号，编号从1开始，对于每一行，NTILE返回此行所属的组的编号</p><p>设置n=5，那么ntile就会把排好序的数据均分成n个组，ntile函数会返回每条数据所在组的组编号，从而可以达到取前百分比的数据</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>思考：在使用row_number函数的时候，并没有指定rowsBetween，那么默认应该是默认的rows between unbounded preceding and current row。<br>但是，结果却是把组内的所有元素都进行了标号</p><p>rowsBetween应该是针对于具有聚合性质的函数起作用</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; pyspark.sql &lt;span cla
      
    
    </summary>
    
      <category term="Spark" scheme="https://shang.at/categories/Spark/"/>
    
    
      <category term="Spark学习" scheme="https://shang.at/tags/Spark%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
