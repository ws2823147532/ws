{"title":"努力，奋斗","description":null,"language":"zh-CN","link":"https://shang.at","pubDate":"Wed, 10 Jun 2020 06:40:09 GMT","lastBuildDate":"Thu, 11 Jun 2020 03:10:19 GMT","generator":"hexo-generator-json-feed","webMaster":"王尚","items":[{"title":"数据结构与算法学习笔记-JOIN的算法实现","link":"https://shang.at/post/数据结构与算法学习笔记-JOIN的算法实现/","description":"JOIN(INNER JOIN)LEFT JOINRIGHT JOINFULL JOINleft_semileft_anti","pubDate":"Wed, 10 Jun 2020 06:40:09 GMT","guid":"https://shang.at/post/数据结构与算法学习笔记-JOIN的算法实现/","category":"数据结构与算法"},{"title":"java学习-JDK环境切换","link":"https://shang.at/post/java学习-JDK环境切换/","description":"近期，JDK版本更新十分频繁，如果要想快速切换JDK版本，可以通过linux的alias命令来简单实现： # mac环境# ~/.bash_profileexport JAVA_8_HOME=$(/usr/libexec/java_home -v 1.8)export JAVA_9_HOME=$(/usr/libexec/java_home -v 9)export JAVA_10_HOME=$(/usr/libexec/java_home -v 10)export JAVA_11_HOME=$(/usr/libexec/java_home -v 11)export JAVA_HOME=$JAVA_8_HOMEexport PATH=$JAVA_HOME/bin:$PATH# ~/.zshrc 注意要放到~/.zshrc文件的最下面# multi jdk configalias jdk8=\"export PATH=$JAVA_8_HOME/bin:$PATH\"alias jdk9=\"export PATH=$JAVA_9_HOME/bin:$PATH\"alias jdk10=\"export PATH=$JAVA_10_HOME/bin:$PATH\"alias jdk11=\"export PATH=$JAVA_11_HOME/bin:$PATH\" 默认环境为 ➜ ~ java -versionjava version \"1.8.0_144\"Java(TM) SE Runtime Environment (build 1.8.0_144-b01)Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode) 切换jdk9之后 ➜ ~ jdk9➜ ~ java -versionjava version \"9.0.4\"Java(TM) SE Runtime Environment (build 9.0.4+11)Java HotSpot(TM) 64-Bit Server VM (build 9.0.4+11, mixed mode) 这样就可以在当前的terminal session中使用jdk9的新特性了，比如jshell","pubDate":"Wed, 10 Jun 2020 05:40:50 GMT","guid":"https://shang.at/post/java学习-JDK环境切换/","category":"JAVA学习"},{"title":"java学习-JVM虚拟机栈","link":"https://shang.at/post/java学习-JVM虚拟机栈/","description":"","pubDate":"Tue, 09 Jun 2020 07:39:37 GMT","guid":"https://shang.at/post/java学习-JVM虚拟机栈/","category":"JAVA学习"},{"title":"java学习-JVM疑问","link":"https://shang.at/post/java学习-JVM疑问/","description":"在学习JVM的内存模型的时候，我有这样一些疑惑： 1、我们通常只是定义了堆大小(-Xms初始，-Xmx最大)，虚拟机栈大小(-Xss)。但是我发现这并不能计算出一个java进程占用的全部内存大小。以下是我自己理解的(JDK1.8)：java进程占用的内存​ =JVM管理的内存+非JVM管理的内存​ =线程独立的内存+线程共享的内存​ =n*(虚拟机栈内存+程序计数器内存+本地方法栈内存)+堆内存(heap)+非堆内存(non-heap)+元空间(metaspace)+堆外内存(off-heap:direct memory)其中：​ JVM管理的内存：n*(虚拟机栈内存+程序计数器内存+本地方法栈内存)+堆内存(heap)+非堆内存(non-heap)​ 非JVM管理的内存：元空间(metaspace)+堆外内存(off-heap:direct memory)​ 线程独立的内存：n*(虚拟机栈内存+程序计数器内存+本地方法栈内存)，n是线程数​ 线程共享的内存：堆内存(heap)+非堆内存(non-heap)+元空间(metaspace)+对外内存(off-heap:direct memory) 2、在JDK1.7及以前，有个永久代(PermGen)，也就是文中说的方法区。这块区域也被称为非堆内存​ 那么在JDK1.8及以后，永久代变成了元空间，到了JVM管理之外了，那么JDK1.8及以后的版本中还有非堆内存(non-heap)的说法吗？如果有的话，是指什么呢？ 3、关于线程独立的这块内存{n*(虚拟机栈内存+程序计数器内存+本地方法栈内存)，n是线程数}，它是完全独立于其他的内存的吗？​ 还是会分享堆内存，受到堆内存大小的限制​ 还是说Thread对象是建立在堆内存，然后每个Thread对应的虚拟机栈都是独立的吗？ 换句话说，随着Thread的增加(堆内存充足：还能给新的对象分配内存)，java进程占用的内存会越来越大—–我觉得这肯定不对，但是我却无法解释 4、我做了一些测试(JDK1.8)：​ 4.1、指定很小的堆内存，改变虚拟机栈大小​ 4.1.1、-Xms2m -Xmx2m -Xss16m 启动java进程，直到递归调用1,016,085深度，会报StackOverflowError​ 4.1.2、-Xms2m -Xmx2m -Xss8m 启动java进程，直到递归调用318,031深度，会报StackOverflowError​ 4.2、指定很小的堆内存，如-Xms2m -Xmx2m，最终会报OutOfMemoryError 我谈一下我的理解，首先，新创建的线程对象肯定是放在堆中的；每个线程独立的虚拟机栈，存放了很多的栈帧，每个栈帧实际上存放了局部变量表(和其他三部分)，每个栈帧对应了一个函数调用，在这个线程中执行的每个函数中的变量可能会存放在堆里面，也有可能会直接在栈上分配内存，因为这里有一个逃逸的概念(仅函数内部使用的局部变量直接在栈上分配内存，不会占用堆内存)。 所以在我的理解里面，如果虚拟机栈是一个完全独立于堆的内存，那么虚拟机栈就不会受到堆内存大小的限制(比如我上面做的实验：当堆内存远小于虚拟机栈大小，最终报的异常仍然是StackOverflowError，而不是OutOfMemoryError) 所以我才会想到，如果虚拟机栈是一个完全独立于堆的内存，无限的创建线程，每个线程的虚拟机栈如果都无限接近于-Xss分配的最大限度，那么最终会耗尽系统的所有 内存吧 我又做了一个实验，就是无限的创建线程，然后在调用start()的时候，报了OutOfMemoryError:unable to create new native thread的异常，看来操作系统在这里是对线程数是有限制的。","pubDate":"Fri, 05 Jun 2020 09:01:58 GMT","guid":"https://shang.at/post/java学习-JVM疑问/","category":"JAVA学习"},{"title":"java学习-基本类型和包装类型","link":"https://shang.at/post/java学习-基本类型和包装类型/","description":"Java 的每个基本类型都对应了一个包装类型，比如说 int 的包装类型为 Integer，double 的包装类型为 Double。基本类型和包装类型的区别主要有以下 4 点。 01、包装类型可以为 null，而基本类型不可以别小看这一点区别，它使得包装类型可以应用于 POJO 中，而基本类型则不行。 POJO 是什么呢？这里稍微说明一下。 POJO 的英文全称是 Plain Ordinary Java Object，翻译一下就是，简单无规则的 Java 对象，只有属性字段以及 setter 和 getter 方法，示例如下。 class Writer &#123;private Integer age;private String name;public Integer getAge() &#123;return age;&#125;public void setAge(Integer age) &#123;this.age = age;&#125;public String getName() &#123;return name;&#125;public void setName(String name) &#123;this.name = name;&#125;&#125; 和 POJO 类似的，还有数据传输对象 DTO（Data Transfer Object，泛指用于展示层与服务层之间的数据传输对象）、视图对象 VO（View Object，把某个页面的数据封装起来）、持久化对象 PO（Persistant Object，可以看成是与数据库中的表映射的 Java 对象）。 那为什么 POJO 的属性必须要用包装类型呢？ 《阿里巴巴 Java 开发手册》上有详细的说明，我们来大声朗读一下（预备，起）。 数据库的查询结果可能是 null，如果使用基本类型的话，因为要自动拆箱（将包装类型转为基本类型，比如说把 Integer 对象转换成 int 值），就会抛出 NullPointerException 的异常。 02、包装类型可用于泛型，而基本类型不可以泛型不能使用基本类型，因为使用基本类型时会编译出错。 List&lt;int&gt; list = new ArrayList&lt;&gt;(); // 提示 Syntax error, insert &quot;Dimensions&quot; to complete ReferenceTypeList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); 为什么呢？因为泛型在编译时会进行类型擦除，最后只保留原始类型，而原始类型只能是 Object 类及其子类——基本类型是个特例。 03、基本类型比包装类型更高效基本类型在栈中直接存储的具体数值，而包装类型则存储的是堆中的引用。 很显然，相比较于基本类型而言，包装类型需要占用更多的内存空间。假如没有基本类型的话，对于数值这类经常使用到的数据来说，每次都要通过 new 一个包装类型就显得非常笨重。 03、两个包装类型的值可以相同，但却不相等两个包装类型的值可以相同，但却不相等——这句话怎么理解呢？来看一段代码就明明白白了。 Integer chenmo = new Integer(10);Integer wanger = new Integer(10);System.out.println(chenmo == wanger); // falseSystem.out.println(chenmo.equals(wanger )); // true 两个包装类型在使用“==”进行判断的时候，判断的是其指向的地址是否相等。chenmo 和 wanger 两个变量使用了 new 关键字，导致它们在“==”的时候输出了 false。 而 chenmo.equals(wanger) 的输出结果为 true，是因为 equals 方法内部比较的是两个 int 值是否相等。源码如下。 private final int value;public int intValue() &#123;return value;&#125;public boolean equals(Object obj) &#123;if (obj instanceof Integer) &#123;return value == ((Integer)obj).intValue();&#125;return false;&#125; 瞧，虽然 chenmo 和 wanger 的值都是 10，但他们并不相等。换句话说就是：将“==”操作符应用于包装类型比较的时候，其结果很可能会和预期的不符。 04、自动装箱和自动拆箱既然有了基本类型和包装类型，肯定有些时候要在它们之间进行转换。把基本类型转换成包装类型的过程叫做装箱（boxing）。反之，把包装类型转换成基本类型的过程叫做拆箱（unboxing）。 在 Java SE5 之前，开发人员要手动进行装拆箱，比如说： Integer chenmo = new Integer(10); // 手动装箱int wanger = chenmo.intValue(); // 手动拆箱 Java SE5 为了减少开发人员的工作，提供了自动装箱与自动拆箱的功能。 Integer chenmo = 10; // 自动装箱int wanger = chenmo; // 自动拆箱 上面这段代码使用 JAD 反编译后的结果如下所示： Integer chenmo = Integer.valueOf(10);int wanger = chenmo.intValue(); 也就是说，自动装箱是通过 Integer.valueOf() 完成的；自动拆箱是通过 Integer.intValue() 完成的。理解了原理之后，我们再来看一道老马当年给我出的面试题。 // 1）基本类型和包装类型int a = 100;Integer b = 100;System.out.println(a == b);// 2）两个包装类型Integer c = 100;Integer d = 100;System.out.println(c == d);// 3）c = 200;d = 200;System.out.println(c == d); 答案是什么呢？有举手要回答的吗？答对的奖励一朵小红花哦。 第一段代码，基本类型和包装类型进行 == 比较，这时候 b 会自动拆箱，直接和 a 比较值，所以结果为 true。 第二段代码，两个包装类型都被赋值为了 100，这时候会进行自动装箱，那 == 的结果会是什么呢？ 我们之前的结论是：将“==”操作符应用于包装类型比较的时候，其结果很可能会和预期的不符。那结果是 false？但这次的结果却是 true，是不是感觉很意外？ 第三段代码，两个包装类型重新被赋值为了 200，这时候仍然会进行自动装箱，那 == 的结果会是什么呢？ 吃了第二段代码的亏后，是不是有点怀疑人生了，这次结果是 true 还是 false 呢？扔个硬币吧，哈哈。我先告诉你结果吧，false。 为什么？为什么？为什么呢？ 事情到了这一步，必须使出杀手锏了——分析源码吧。 之前我们已经知道了，自动装箱是通过 Integer.valueOf() 完成的，那我们就来看看这个方法的源码吧。 public static Integer valueOf(int i) &#123;if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)return IntegerCache.cache[i + (-IntegerCache.low)];return new Integer(i);&#125; 难不成是 IntegerCache 在作怪？你猜对了！ private static class IntegerCache &#123;static final int low = -128;static final int high;static final Integer cache[];static &#123;// high value may be configured by propertyint h = 127;int i = parseInt(integerCacheHighPropValue);i = Math.max(i, 127);h = Math.min(i, Integer.MAX_VALUE - (-low) -1);high = h;cache = new Integer[(high - low) + 1];int j = low;for(int k = 0; k &lt; cache.length; k++)cache[k] = new Integer(j++);// range [-128, 127] must be interned (JLS7 5.1.7)assert IntegerCache.high &gt;= 127;&#125;&#125; 大致瞟一下这段代码你就全明白了。-128 到 127 之间的数会从 IntegerCache 中取，然后比较，所以第二段代码（100 在这个范围之内）的结果是 true，而第三段代码（200 不在这个范围之内，所以 new 出来了两个 Integer 对象）的结果是 false。 看完上面的分析之后，我希望大家记住一点：当需要进行自动装箱时，如果数字在 -128 至 127 之间时，会直接使用缓存中的对象，而不是重新创建一个对象。 自动装拆箱是一个很好的功能，大大节省了我们开发人员的精力，但也会引发一些麻烦，比如下面这段代码，性能就很差。 long t1 = System.currentTimeMillis();Long sum = 0L;for (int i = 0; i &lt; Integer.MAX_VALUE;i++) &#123; sum += i;&#125;long t2 = System.currentTimeMillis();System.out.println(t2-t1); sum 由于被声明成了包装类型 Long 而不是基本类型 long，所以 sum += i 进行了大量的拆装箱操作（sum 先拆箱和 i 相加，然后再装箱赋值给 sum），导致这段代码运行完花费的时间足足有 2986 毫秒；如果把 sum 换成基本类型 long，时间就仅有 554 毫秒，完全不一个等量级啊。","pubDate":"Thu, 04 Jun 2020 03:37:10 GMT","guid":"https://shang.at/post/java学习-基本类型和包装类型/","category":"JAVA学习"},{"title":"java学习-JVM-heap-non-heap-off-heap","link":"https://shang.at/post/java学习-JVM-heap-non-heap-off-heap/","description":"","pubDate":"Wed, 03 Jun 2020 22:50:26 GMT","guid":"https://shang.at/post/java学习-JVM-heap-non-heap-off-heap/","category":""},{"title":"java网络编程-零拷贝","link":"https://shang.at/post/java网络编程-零拷贝/","description":"什么是零拷贝刚才讲阻塞 IO 的时候我讲到，系统内核处理 IO 操作分为两个阶段——等待数据和拷贝数据。等待数据，就是系统内核在等待网卡接收到数据后，把数据写到内核中；而拷贝数据，就是系统内核在获取到数据后，将数据拷贝到用户进程的空间中。以下是具体流程： 应用进程的每一次写操作，都会把数据写到用户空间的缓冲区中，再由 CPU 将数据拷贝到系统内核的缓冲区中，之后再由 DMA 将这份数据拷贝到网卡中，最后由网卡发送出去。这里我们可以看到，一次写操作数据要拷贝两次才能通过网卡发送出去，而用户进程的读操作则是将整个流程反过来，数据同样会拷贝两次才能让应用程序读取到数据。 应用进程的一次完整的读写操作，都需要在用户空间与内核空间中来回拷贝，并且每一次拷贝，都需要 CPU 进行一次上下文切换（由用户进程切换到系统内核，或由系统内核切换到用户进程），这样是不是很浪费 CPU 和性能呢？那有没有什么方式，可以减少进程间的数据拷贝，提高数据传输的效率呢？ 这时我们就需要零拷贝（Zero-copy）技术。 所谓的零拷贝，就是取消用户空间与内核空间之间的数据拷贝操作，应用进程每一次的读写操作，都可以通过一种方式，让应用进程向用户空间写入或者读取数据，就如同直接向内核空间写入或者读取数据一样，再通过 DMA 将内核中的数据拷贝到网卡，或将网卡中的数据 copy 到内核。 那怎么做到零拷贝？你想一下是不是用户空间与内核空间都将数据写到一个地方，就不需要拷贝了？此时你有没有想到虚拟内存？ 零拷贝有两种解决方式，分别是 mmap+write 方式和 sendfile 方式，mmap+write 方式的核心原理就是通过虚拟内存来解决的。 java中的零拷贝Netty中的零拷贝 具体去读Netty的源码再详细补充这里 了解完零拷贝，我们再看看 Netty 中的零拷贝。 我刚才讲到，RPC 框架在网络通信框架的选型上，我们最优的选择是基于 Reactor 模式实现的框架，如 Java 语言，首选的便是 Netty 框架。那么 Netty 框架是否也有零拷贝机制呢？Netty 框架中的零拷贝和我之前讲的零拷贝又有什么不同呢？ 刚才我讲的零拷贝是操作系统层面上的零拷贝，主要目标是避免用户空间与内核空间之间的数据拷贝操作，可以提升 CPU 的利用率。 而 Netty 的零拷贝则不大一样，他完全站在了用户空间上，也就是 JVM 上，它的零拷贝主要是偏向于数据操作的优化上。 那么 Netty 这么做的意义是什么呢？ 回想下[第 02 讲]，在这一讲中我讲解了 RPC 框架如何去设计协议，其中我讲到：在传输过程中，RPC 并不会把请求参数的所有二进制数据整体一下子发送到对端机器上，中间可能会拆分成好几个数据包，也可能会合并其他请求的数据包，所以消息都需要有边界。那么一端的机器收到消息之后，就需要对数据包进行处理，根据边界对数据包进行分割和合并，最终获得一条完整的消息。 那收到消息后，对数据包的分割和合并，是在用户空间完成，还是在内核空间完成的呢？ 当然是在用户空间，因为对数据包的处理工作都是由应用程序来处理的，那么这里有没有可能存在数据的拷贝操作？可能会存在，当然不是在用户空间与内核空间之间的拷贝，是用户空间内部内存中的拷贝处理操作。Netty 的零拷贝就是为了解决这个问题，在用户空间对数据操作进行优化。 那么 Netty 是怎么对数据操作进行优化的呢？ Netty 提供了 CompositeByteBuf 类，它可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf，避免了各个 ByteBuf 之间的拷贝。 ByteBuf 支持 slice 操作，因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf，避免了内存的拷贝。 通过 wrap 操作，我们可以将 byte[] 数组、ByteBuf、ByteBuffer 等包装成一个 Netty ByteBuf 对象, 进而避免拷贝操作。 Netty 框架中很多内部的 ChannelHandler 实现类，都是通过 CompositeByteBuf、slice、wrap 操作来处理 TCP 传输中的拆包与粘包问题的。 那么 Netty 有没有解决用户空间与内核空间之间的数据拷贝问题的方法呢？ Netty 的 ByteBuffer 可以采用 Direct Buffers，使用堆外直接内存进行 Socket 的读写操作，最终的效果与我刚才讲解的虚拟内存所实现的效果是一样的。(mmap方式) Netty 还提供 FileRegion 中包装 NIO 的 FileChannel.transferTo() 方法实现了零拷贝，这与 Linux 中的 sendfile 方式在原理上也是一样的。 总结零拷贝带来的好处就是避免没必要的 CPU 拷贝，让 CPU 解脱出来去做其他的事，同时也减少了 CPU 在用户空间与内核空间之间的上下文切换，从而提升了网络通信效率与应用程序的整体性能。 而 Netty 的零拷贝与操作系统的零拷贝是有些区别的，Netty 的零拷贝偏向于用户空间中对数据操作的优化，这对处理 TCP 传输中的拆包粘包问题有着重要的意义，对应用程序处理请求数据与返回数据也有重要的意义。 在 RPC 框架的开发与使用过程中，我们要深入了解网络通信相关的原理知识，尽量做到零拷贝，如使用 Netty 框架；我们要合理使用 ByteBuf 子类，做到完全零拷贝，提升 RPC 框架的整体性能。 其他关于零拷贝技术的文章： Java中的零拷贝","pubDate":"Wed, 03 Jun 2020 16:32:39 GMT","guid":"https://shang.at/post/java网络编程-零拷贝/","category":"JAVA学习"},{"title":"java学习-JVM参数","link":"https://shang.at/post/java学习-JVM参数/","description":"查看JVM参数启动应用的时候分别加以下的参数可以打印相关的参数： java -XX:+PrintFlagsInitial 打印所有的JVM初始参数，但是会立刻终止应用 java -XX:+PrintFlagsFinal 打印所有的设置后的JVM参数，不会终止应用 jinfo [options] pid ​ jinfo -flags pid 查看指定pid的jvm的所有设置参数 -XX:+PrintVMOptions 程序运行时，打印虚拟机接受到的命令行显式参数。不会终止应用 -XX:+PrintCommandLineFlags 打印传递给虚拟机的显式和隐式参数。不会终止应用 常见的JVM参数 InitialHeapSize(单位是字节)：初始堆大小，默认是物理内存的1/64，最小为2m(设置了1m，发现PrintFlagsFinal打印出来的是2m)，可以使用-Xms指定，如-Xms64m，只能指定m、g这样的单位 MaxHeapSize：最大堆大小，默认是物理内存的1/4，最小为2m，可以使用-Xmx指定，如-Xmx64m MaxNewSize： NewSize： OldSize： MetaspaceSize： MaxMetaspaceSize： ThreadStackSize(单位是kb)：虚拟机栈大小，默认是1024k，可以使用-Xss指定，如-Xss256k MaxTenuringThreshold：对象晋升到老年代的年龄阈值，默认是15，可以使用-XX:MaxTenuringThreshold指定，如-XX:MaxTenuringThreshold=20 参数调优 默认空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制；空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制。因此服务器一般设置-Xms、-Xmx相等以避免在每次GC 后调整堆的大小。","pubDate":"Wed, 03 Jun 2020 10:36:02 GMT","guid":"https://shang.at/post/java学习-JVM参数/","category":"JAVA学习"},{"title":"Java学习-常见异常","link":"https://shang.at/post/Java学习-常见异常/","description":"StackOverflowError和OutOfMemoryError的区别(JDK1.8)StackOverflowError：Thrown when a stack overflow occurs because an application recurses too deeply. OutOfMemoryError：Thrown when the Java Virtual Machine cannot allocate an object because it is out of memory, and no more memory could be made available by the garbage collector. 从对这两个Error的注释来看， 由于应用程序递归过深而在堆栈溢出时会抛出StackOverflowError；同一个函数递归调用时，内存不足 当Java虚拟机由于内存不足而无法分配对象，并且垃圾回收器无法再提供更多内存时，抛出OutOfMemoryError。创建新的对象(包括虚拟机栈：函数调用(也包括递归调用)时创建虚拟机栈)时，内存不足 在java应用启动的时候，可以通过-Xss来设置虚拟机栈大小，虚拟机栈默认大小为1024k 在java里，函数的递归调用受到以下几方面的影响： 虚拟机栈大小：设置的虚拟机栈 局部变量表大小","pubDate":"Wed, 03 Jun 2020 09:31:00 GMT","guid":"https://shang.at/post/Java学习-常见异常/","category":"JAVA学习"},{"title":"JAVA并发编程-12-并发框架(Disruptor)","link":"https://shang.at/post/JAVA并发编程-12-并发框架-Disruptor/","description":"","pubDate":"Wed, 03 Jun 2020 02:54:59 GMT","guid":"https://shang.at/post/JAVA并发编程-12-并发框架-Disruptor/","category":"JAVA并发编程"},{"title":"JAVA并发编程-11-响应式编程(RxJava)","link":"https://shang.at/post/JAVA并发编程-11-响应式编程-RxJava/","description":"https://juejin.im/post/5ed62cabf265da7709526718","pubDate":"Wed, 03 Jun 2020 02:53:44 GMT","guid":"https://shang.at/post/JAVA并发编程-11-响应式编程-RxJava/","category":"JAVA并发编程"},{"title":"JAVA并发编程-10-协程","link":"https://shang.at/post/JAVA并发编程-10-协程/","description":"https://juejin.im/post/5ed62cabf265da7709526718","pubDate":"Wed, 03 Jun 2020 02:53:19 GMT","guid":"https://shang.at/post/JAVA并发编程-10-协程/","category":"JAVA并发编程"},{"title":"JAVA并发编程-9-线程池","link":"https://shang.at/post/JAVA并发编程-9-线程池/","description":"","pubDate":"Wed, 03 Jun 2020 02:52:35 GMT","guid":"https://shang.at/post/JAVA并发编程-9-线程池/","category":"JAVA并发编程"},{"title":"JAVA并发编程-8-阻塞队列","link":"https://shang.at/post/JAVA并发编程-8-阻塞队列/","description":"","pubDate":"Wed, 03 Jun 2020 02:52:16 GMT","guid":"https://shang.at/post/JAVA并发编程-8-阻塞队列/","category":"JAVA并发编程"},{"title":"JAVA并发编程-7-Atomic","link":"https://shang.at/post/JAVA并发编程-7-Atomic/","description":"","pubDate":"Wed, 03 Jun 2020 02:51:56 GMT","guid":"https://shang.at/post/JAVA并发编程-7-Atomic/","category":"JAVA并发编程"},{"title":"JAVA并发编程-6-并发集合","link":"https://shang.at/post/JAVA并发编程-6-并发集合/","description":"","pubDate":"Wed, 03 Jun 2020 02:51:41 GMT","guid":"https://shang.at/post/JAVA并发编程-6-并发集合/","category":"JAVA并发编程"},{"title":"JAVA并发编程-5-其他","link":"https://shang.at/post/JAVA并发编程-5-其他/","description":"","pubDate":"Wed, 03 Jun 2020 02:51:25 GMT","guid":"https://shang.at/post/JAVA并发编程-5-其他/","category":"JAVA并发编程"},{"title":"JAVA并发编程-4-并发工具类","link":"https://shang.at/post/JAVA并发编程-4-并发工具类/","description":"","pubDate":"Wed, 03 Jun 2020 02:51:14 GMT","guid":"https://shang.at/post/JAVA并发编程-4-并发工具类/","category":"JAVA并发编程"},{"title":"JAVA并发编程-3-锁","link":"https://shang.at/post/JAVA并发编程-3-锁/","description":"","pubDate":"Wed, 03 Jun 2020 02:51:06 GMT","guid":"https://shang.at/post/JAVA并发编程-3-锁/","category":"JAVA并发编程"},{"title":"JAVA并发编程-2-并发基础","link":"https://shang.at/post/JAVA并发编程-2-并发基础/","description":"","pubDate":"Wed, 03 Jun 2020 02:50:55 GMT","guid":"https://shang.at/post/JAVA并发编程-2-并发基础/","category":"JAVA并发编程"},{"title":"JAVA并发编程-1-内存模型","link":"https://shang.at/post/JAVA并发编程-1-内存模型/","description":"","pubDate":"Wed, 03 Jun 2020 02:50:11 GMT","guid":"https://shang.at/post/JAVA并发编程-1-内存模型/","category":"JAVA并发编程"},{"title":"Spark应用-Scheduler","link":"https://shang.at/post/Spark应用-Scheduler/","description":"Spark任务有四种提交方式： local standalone yarn(这里着重讲) mesos 这里涉及到两层的任务调度： 第一层：schedule across applications，应用间的任务调度Spark的application提交到yarn平台，yarn平台负责Spark application的调度，这里也分为两层： 第一层：Yarn的队列，Spark application和其他运行在Yarn平台上的应用并无二致，都要统一服从yarn平台的安排yarn有三种任务调度模型： FIFO scheduler：先入先出调度器，整个Yarn集群只有一个任务队列，所有提交的任务都要等待上一个任务完全执行完才能执行 Capacity scheduler：容量调度器，以Capacity为中心，把资源划分到若干个队列中，各个队列内根据自己的逻辑分配资源。例如下图中队列A可以调度的资源可以占80%，队列B占有剩下的20%，各队列接受相应的作业请求，在自己的资源中分配 Fair scheduler：秉承公平性原则，尽可能让各个作业得到的资源平均。先提交的job1马上占满了集群资源，那么作业2提交之后，原本Job1占有的资源拨出一些给作业2，从而达到“公平”(但是要等到job1的某些task执行完毕之后才能把资源让出来) 第二层：Yarn队列内的调度当使用FIFO scheduler，自不必说，它只有一个先进先出的队列，也就是队列内部的任务调度；Capacity scheduler会把 集群分成若干个队列，每个队列内部采用FIFO的策略；Fair scheduler可以通过设置，每个Fair Queue内部使用不同的schedulingPolicy，但是会有一个文档级别的默认策略的配置defaultQueueSchedulingPolicy，如果每个Queue没有自己的设置，那么就用defaultQueueSchedulingPolicy 第二层：schedule within application，同一个SparkContext内的job调度","pubDate":"Mon, 01 Jun 2020 06:22:50 GMT","guid":"https://shang.at/post/Spark应用-Scheduler/","category":"Scheduler"},{"title":"分布式常见思想-Bloomfilter","link":"https://shang.at/post/分布式常见思想-Bloomfilter/","description":"","pubDate":"Mon, 01 Jun 2020 01:58:27 GMT","guid":"https://shang.at/post/分布式常见思想-Bloomfilter/","category":"分布式"},{"title":"数据结构与算法学习笔记-内存不足","link":"https://shang.at/post/数据结构与算法学习笔记-内存不足/","description":"中位数定义：数字排序之后，位于中间的那个数。比如将100亿个数字进行排序，排序之后，位于第50亿个位置的那个数 就是中位数。 ①内存够：内存够还慌什么啊，直接把100亿个全部排序了，你用冒泡都可以…然后找到中间那个就可以了。但是你以为面试官会给你内存？？ ②内存不够：题目说是整数，我们认为是带符号的int,所以4字节，占32位。 假设100亿个数字保存在一个大文件中，依次读一部分文件到内存(不超过内存的限制)，将每个数字用二进制表示，比较二进制的最高位(第32位，符号位，0是正，1是负)，如果数字的最高位为0，则将这个数字写入 file_0文件中；如果最高位为 1，则将该数字写入file_1文件中。 从而将100亿个数字分成了两个文件，假设 file_0文件中有 60亿 个数字，file_1文件中有 40亿 个数字。那么中位数就在 file_0 文件中，并且是 file_0 文件中所有数字排序之后的第 10亿 个数字。（file_1中的数都是负数，file_0中的数都是正数，也即这里一共只有40亿个负数，那么排序之后的第50亿个数一定位于file_0中） 现在，我们只需要处理 file_0 文件了（不需要再考虑file_1文件）。对于 file_0 文件，同样采取上面的措施处理：将file_0文件依次读一部分到内存(不超内存限制)，将每个数字用二进制表示，比较二进制的 次高位（第31位），如果数字的次高位为0，写入file_0_0文件中；如果次高位为1，写入file_0_1文件 中。 现假设 file_0_0文件中有30亿个数字，file_0_1中也有30亿个数字，则中位数就是：file_0_0文件中的数字从小到大排序之后的第10亿个数字。 抛弃file_0_1文件，继续对 file_0_0文件 根据 次次高位(第30位) 划分，假设此次划分的两个文件为：file_0_0_0中有5亿个数字，file_0_0_1中有25亿个数字，那么中位数就是 file_0_0_1文件中的所有数字排序之后的 第 5亿 个数。 按照上述思路，直到划分的文件可直接加载进内存时，就可以直接对数字进行快速排序，找出中位数了。","pubDate":"Sun, 31 May 2020 23:35:34 GMT","guid":"https://shang.at/post/数据结构与算法学习笔记-内存不足/","category":"数据结构与算法"},{"title":"Java学习-Future","link":"https://shang.at/post/Java学习-Future/","description":"","pubDate":"Sun, 31 May 2020 22:44:35 GMT","guid":"https://shang.at/post/Java学习-Future/","category":"JAVA学习"}]}