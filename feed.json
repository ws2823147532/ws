{"title":"努力，奋斗","description":null,"language":"zh-CN","link":"https://shang.at","pubDate":"Mon, 29 Jun 2020 17:54:22 GMT","lastBuildDate":"Mon, 29 Jun 2020 18:29:59 GMT","generator":"hexo-generator-json-feed","webMaster":"王尚","items":[{"title":"算法-动态规划","link":"https://shang.at/post/算法-动态规划/","description":"动态规划 其本质是动态递推 避免人肉递归。可以尝试画出递归树 找到最近最简方法，将其拆解成可重复解决的问题 如何找到最近最简方法：数学归纳法思维 如何区分DP问题：DP一般会被用来求解最值问题 DP与递归和分治的联系 DP与 递归或者分治没有根本上的却别 共性：找到重复子问题 差异性：DP有最优子结构，中途可以淘汰次优解 实战例题509. 斐波那契数 傻递归 - 自顶向下 画出递归树 时间复杂度：每计算一个节点，需要计算其余的两个节点，以此类推下去，这是一个二叉树的结构，所以它的时间复杂度是O(2^n)的 优化： 加入备忘录 在傻递归的基础上，加入一个缓存，以达到避免重复子问题的重复计算的问题 使用DP的思维解决 - 自底向上 DP三步曲 找到重复子问题 根据数学归纳法：要计算第n个斐波那契数，那么我们只需要计算第n-1和n-2个斐波那契数就可以了 状态定义 - 且找到base case 假设使用a[i]表示第i个斐波那契数，那么f[i] = f[i-1]+f[i-2] 且f[0]=0,f[1]=1 DP方程 f(n)=\\left\\{ \\begin{aligned} 0 &,& n=0 \\\\ 1 &,& n=1 \\\\ f(n-1)+f(n-2) &,& n>1 \\end{aligned} \\right. 70. 爬楼梯 考虑下变体： 不止可以上1阶或2阶：可以上1、2、3阶等 可以上1 2 3阶，且相邻的两个步伐不能相同，该如何设计 本体： f(n)=\\left\\{ \\begin{aligned} 1 &,& n=1 \\\\ 2 &,& n=2 \\\\ f(n-1)+f(n-2) &,& n>2 \\end{aligned} \\right.变体1： f(n)=\\left\\{ \\begin{aligned} 1 &,& n=1 \\\\ 2 &,& n=2 \\\\ 4 &,& n=3 \\\\ f(n-1)+f(n-2)+f(n-3) &,& n>3 \\end{aligned} \\right.变体2： 定义dp[0…2][i]， ​ dp[0][i]表示到达i最后一次走了1步； ​ dp[1][i]表示到达i最后一次走了2步； ​ dp[2][i]表示到达i最后一次走了3步 那么 ​ dp[0][i]=dp[1][i-1]+dp[2][i-1]；到当前台阶走了1步，那么前面只能再选最后一次走了2步和3步的 ​ dp[1][i]=dp[0][i-2]+dp[2][i-2]；到当前台阶走了2步，那么前面只能再选最后一次走了1步和3步 ​ dp[2][i]=dp[0][i-3]+dp[1][i-3] 到当前台阶走了3步，那么前面只能再选最后一次走了1步和2步的 结果为：dp[0][-1]+dp[1][-1]+dp[2][-1]，即到达n的所有步伐的总和 1234567891011121314151617181920212223def changeClimbStairs(self, n: int) -&gt; int: if n == 1: return 1 if n == 2: return 1 if n == 3: return 3 # dp[0][i] 最后一次走了1步到达 i # dp[1][i] 最后一次走了2步到达 i # dp[2][i] 最后一次走了3步到达 i dp = [ [1, 0, 1] + [0] * (n - 3), # 最后一次走1步 [0, 1, 1] + [0] * (n - 3), # 最后一次走2步 [0, 0, 1] + [0] * (n - 3) # 最后一次走3步 ] for i in range(3, n): # 到当前台阶走了1步，那么前面只能再选最后一次走了2步和3步的 dp[0][i] = dp[1][i - 1] + dp[2][i - 1] # 到当前台阶走了2步，那么前面只能再选最后一次走了1步和3步的 dp[1][i] = dp[0][i - 2] + dp[2][i - 2] # 到当前台阶走了3步，那么前面只能再选最后一次走了1步和2步的 dp[2][i] = dp[0][i - 3] + dp[1][i - 3] return dp[0][-1] + dp[1][-1] + dp[2][-1] 322. 零钱兑换 略过递归方案，直接上DP DP问题三步曲 找到重复子问题 根据数学归纳法：已知某金额所需的最少硬币数，可得其他金额的所需最少硬币数 状态定义 假设dp[i]表示，金额为i时需要的最少硬币数，那么因为有coins个硬币可选，所以dp[i]=min(dp[i-k] for k in coins) + 1，加1表示要选择一个面值为k的硬币 dp初始值为mount+1，因为金额为amout，所需硬币最多为amout个1元硬币，长度为amout+1 dp[0]=0，表示当金额为0时，需要的硬币数也为0 最终结果：dp[amout] DP方程 f(n) = \\left\\{ \\begin{aligned} 0 &,& n=0 \\\\ 1 &,& n=1 \\\\ min(f(n-k))+1 &,& k \\in coins \\\\ \\end{aligned} \\right.123456789101112class Solution: def coinChange(self, coins: List[int], amount: int) -&gt; int: dp = [amount + 1] * (amount + 1) dp[0] = 0 for i in range(1, amount + 1): for coin in coins: if coin &lt;= i: dp[i] = min(dp[i], dp[i - coin] + 1) return dp[amount] if dp[amount] &lt; amount + 1 else -1 62. 不同路径 直接DP三步曲 找到重复子问题 要求从位置(i,j)到END的不同路径数，由于从某个位置出发只能向右或向下走，如果我知道了从(i+1, j)和从(i,j+1)到END的路径数，那么我就能得到path_{i,j}，path_{i,j}=path_{i+1,j}+path_{i,j+1} 状态定义 定义dp[m][n]数组，表示棋盘，每个元素表示从该位置出发，到END的不同路径数 dp[][n]=1，右边界全为1，因为右边界的位置到END，路径数都是1 dp[m][]=1，下边界全为1，因为下边界的位置到END，路径数都是1 遍历方向：从END位置开始向上遍历 最终结果：dp[0][0] DP方程 f(x,y) = \\left\\{ \\begin{aligned} 1 &,& x=m\\\\ 1 &,& y=n\\\\ f(x+1, y)+f(x, y+1) &,& 0 \\leq x < m \\& 0 \\leq y < n \\end{aligned} \\right.123456789101112131415161718192021class Solution: def uniquePaths(self, m: int, n: int) -&gt; int: if n == 1: return 1 # 初始化dp数组，左边界和右边界都初始化为1 dp = [[1 if j == m - 1 or i == n - 1 else 0 for j in range(m)] for i in range(n)] for i in range(n - 2, -1, -1): for j in range(m - 2, -1, -1): dp[i][j] = dp[i + 1][j] + dp[i][j + 1] return dp[0][0] # 空间压缩：我们只需要一维的数组就可以存下路径的变化 def uniquePaths(self, m: int, n: int) -&gt; int: if n == 1: return 1 # 初始化dp数组为 1 dp = [1] * m for i in range(n - 2, -1, -1): for j in range(m - 2, -1, -1): dp[j] = dp[j] + dp[j + 1] return dp[0] 63. 不同路径 II 直接DP三步曲 找到重复子问题 要求从位置(i,j)到END的不同路径数，由于从某个位置出发只能向右或向下走，如果我知道了从(i+1, j)和从(i,j+1)到END的路径数，那么我就能得到path_{i,j}，path_{i,j}=path_{i+1,j}+$$ 状态定义 定义dp[m][n]数组，表示棋盘，每个元素表示从该位置出发，到END的不同路径数 dp[][n]=1，右边界最后一个障碍物之后全为1，最后一个障碍物及之前的位置全为0，因为右边界一旦出现了障碍物，那么在这之前的位置的路径就都被截断了 dp[m][]=1，下边界最后一个障碍物之后全为1，最后一个障碍物及之前的位置全为0，因为下边界一旦出现了障碍物，那么在这之前的位置的路径就都被截断了 需要注意的是：棋盘上为1的位置不能走，那个位置的路径数为0 遍历方向：从END位置开始遍历 最终结果：dp[0][0] DP方程 f(x,y) = \\left\\{ \\begin{aligned} 0 &,& x=m\\&x\\leq lastcol(lastrow表示下边界最后一个障碍物的位置)\\\\ 0 &,& y=n\\&y\\leq lastrow(lastrow表示右边界最后一个障碍物的位置)\\\\ 1 &,& x=m\\&x>lastcol(lastrow表示下边界最后一个障碍物的位置)\\\\ 1 &,& y=n\\&y>lastrow(lastrow表示右边界最后一个障碍物的位置)\\\\ 0 &,& obstacleGrid(x, y)=1\\\\ f(x-1, y)+f(x, y-1) &,& 0 \\leq x < m \\& 0 \\leq y < n \\end{aligned} \\right.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class Solution: def uniquePathsWithObstacles(self, obstacleGrid: List[List[int]]) -&gt; int: m, n = len(obstacleGrid[0]), len(obstacleGrid) # if obstacleGrid[-1][-1] == 1 or obstacleGrid[0][0] == 1: return 0 # 起点和终点为1，直接返回0 # if n == 1: # 只有一行 # if sum(obstacleGrid[0]) &gt;= 1: # 行出现了1 # return 0 # else: # return 1 # if m == 1: # 只有一列 # if sum(list(chain(*obstacleGrid))) &gt;= 1: # 列出现了1 # return 0 # else: # return 1 # 如果 最后一行或最后一列出现了1，那么1出现的位置及之前的位置和1没有区别 last_row, last_col = -1, -1 # 标记最后一行(列)出现障碍的位置 for i in range(n - 1, -1, -1): if obstacleGrid[i][-1] == 1: last_row = i break for i in range(m - 1, -1, -1): if obstacleGrid[-1][i] == 1: last_col = i break # 根据棋盘的最后一行和最后一列初始化 dp数组 # 包含了 起点和终点为1 的情况 # 包含了 只有一行和只有一列的情况 dp = [[1 if i &gt; last_col and j == n - 1 or j &gt; last_row and i == m - 1 else 0 for i in range(m)] for j in range(n)] for i in range(n - 2, -1, -1): for j in range(m - 2, -1, -1): if obstacleGrid[i][j] == 1: dp[i][j] = 0 else: dp[i][j] = dp[i + 1][j] + dp[i][j + 1] return dp[0][0] # dp空间压缩：实际上我们在进行递推的时候，只需要一维数组就可以 def uniquePathsWithObstacles(self, obstacleGrid: List[List[int]]) -&gt; int: m, n = len(obstacleGrid[0]), len(obstacleGrid) dp = [0] * m dp[m - 1] = 1 for i in range(n - 1, -1, -1): for j in range(m - 1, -1, -1): if obstacleGrid[i][j] == 1: # 当前位置为障碍物 dp[j] = 0 elif j &lt; m - 1: # 因为要使用下一个坐标，这里要检测坐标的合法性，防止指针越界 dp[j] += dp[j + 1] return dp[0] 1143. 最长公共子序列 思维：DP最终会归结到一个状态数组中，所以拿到一个这样的题目后，就往一维状态数组上靠拢，一维搞不定，就尝试用二维数组，再不行就三维…然后依靠数学归纳法进行推导，看是否能根据已知内容的位置 推导出当前位置的值 直接上DP三步曲 找到重复子问题 abcde和abc的问题可以由下列的二维表格描述，如果要求某个位置的值，只需要知道它之前的某些位置即可 - a b c d e a LCS(a,a)=1 LCS(a,ab)=1 LCS(a,abc)=1 LCS(a,aabcd)=1 LCS(a,abcde)=1 c LCS(ac,a)=1 LCS(ac,ab)=1 LCS(ac,abc)=2 2 2 e 1 1 2 2 LCS(ace,abcde)=3 定义状态 dp[i][j]，i表示第一个字符串的位置编号，j表示第二个字符串的位置编号，整体表示两个子串的最长公共子序列的长度 dp长度初始化为text1.length+1*text2.length+1，因为至少要包含没有字符的情况 初始值：dp[0][0]=0 遍历方向：从前往后。因为base case在前部 最终结果：dp[text1.length][text2.length] DP方程 f(x, y) = \\left\\{ \\begin{aligned} 0 &,& x=0\\&y=0 \\\\ max(f(x-1, y), f(x, y-1)) &,& text1(x)!=text2(y) \\\\ f(x-1, y-1)+1 &,& text1(x)=text2(y) \\\\ \\end{aligned} \\right.1234567891011121314151617181920212223242526272829303132333435class Solution: def longestCommonSubsequence1(self, text1: str, text2: str) -&gt; int: m, n = len(text1), len(text2) dp = [[0 for _ in range(m + 1)] for _ in range(n + 1)] for i in range(1, n + 1): for j in range(1, m + 1): if text1[j - 1] == text2[i - 1]: # 当前位置的两个字符一样，取对角的值再加1(加上自身) dp[i][j] = dp[i - 1][j - 1] + 1 else: # 当前位置的两个字符不一样，取两个字符对应的最大值 dp[i][j] = max(dp[i - 1][j], dp[i][j - 1]) return dp[n][m] # dp空间压缩：发现求当前位置的值，只需要left和last_line的值 def longestCommonSubsequence(self, text1: str, text2: str) -&gt; int: m, n = len(text1), len(text2) # 当前位置，当前位置的左一位置 curr, left = 0, 0 # 上一行的值 last_line = [0] * (m + 1) for i in range(1, n + 1): for j in range(1, m + 1): if text1[j - 1] == text2[i - 1]: # 当前位置的两个字符一样，取对角的值再加1(加上自身) curr = last_line[j - 1] + 1 else: # 当前位置的两个字符不一样，取两个字符对应的最大值 curr = max(last_line[j], left) # 根据当前计算的结果 更新上一行，遍历到下一行的时候，正好可以用 if j == m: # 换行：可以更新当前位置的up位置元素，且把left重置为0 last_line[j - 1], last_line[j], left = left, curr, 0 else: # 不换行：不能更新up位置，因为在同一行中遍历的时候，要使用原始的值 last_line[j - 1], left = left, curr return curr 120. 三角形最小路径和 直接DP三步曲 找到重复子问题 要想求得到达当前位置的最小路径和，那么我只需要知道到达当前位置的up和up_left最小路径和即可 状态定义 dp[i][j]，i和j分别表示矩阵的坐标，整体表示到达该坐标的最小路径和 dp[0][0]为矩阵的第一个元素值 最终结果：min(dp[-1]) DP方程 f(x, y) = \\left\\{ \\begin{aligned} matrix(0, 0) &, & x=0\\&y=0 \\\\ min(f(x-1, y), f(x-1. y-1)) + matrix(x,y) &,& 0\\leq x \\& 0\\leq y \\end{aligned} \\right.123456789101112131415161718192021222324252627class Solution: def minimumTotal1(self, triangle: List[List[int]]) -&gt; int: m, n = len(triangle[-1]), len(triangle) dp = [[0 for _ in row] for row in triangle] dp[0][0] = triangle[0][0] for i in range(1, n): for j, val in enumerate(triangle[i]): if j == 0: dp[i][j] = dp[i - 1][j] + val elif j == len(triangle[i]) - 1: dp[i][j] = dp[i - 1][j - 1] + val else: dp[i][j] = min(dp[i - 1][j], dp[i - 1][j - 1]) + val return min(dp[-1]) # dp空间压缩 def minimumTotal(self, triangle: List[List[int]]) -&gt; int: m, n = len(triangle[-1]), len(triangle) dp = triangle for i in range(1, n): for j, val in enumerate(triangle[i]): if j == 0: dp[i][j] = dp[i - 1][j] + val elif j == len(triangle[i]) - 1: dp[i][j] = dp[i - 1][j - 1] + val else: dp[i][j] = min(dp[i - 1][j], dp[i - 1][j - 1]) + val return min(dp[-1]) 221. 最大正方形 DP三步曲 找到重复子问题 以某个位置(i,j)为右下角的正方形的边长，可以根据当前位置的up、left、left_up三个位置确定出来 状态定义 dp[i][j]表示以(i,j)为右下角的正方形的边长，那么如果(i,j)为0，dp[i][j]=0；否则dp[i][j]=min(up,left,up_left)+1 加1的目的是，至少包含它本身 DP方程 123456789101112131415class Solution: def maximalSquare(self, matrix: List[List[str]]) -&gt; int: if not matrix or not matrix[0]: return 0 m, n = len(matrix[0]), len(matrix) dp = [[0 for _ in range(m)] for _ in range(n)] max_edge = dp[0][0] = int(matrix[0][0]) for i in range(0, n): for j in range(0, m): if i == 0 or j == 0: dp[i][j] = 0 if matrix[i][j] == '0' else 1 else: dp[i][j] = 0 if matrix[i][j] == '0' else min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1]) + 1 max_edge = max(dp[i][j], max_edge) return max_edge * max_edge 312. 戳气球 DP三步曲 找到重复子问题 当只有一个气球时，只需要戳一次即可 当有两个气球时，也只需要戳一次 当有三个气球时，那么肯定要先戳中间那一个 当有四个气球时，那么就要 状态定义 气球的个数为n 假设dp[i][j]表示序号在(i,j)之间的获得的硬币最大值，那么我们需要通过遍历(i,j)之间的所有序号，求出dp[i][k]和dp[k][j]，因为dp[i][j]=dp[i][k]+dp[k][j]+k， 最终结果：dp[0][n+1] DP方程 198. 打家劫舍 略过递归方案，直接上DP DP问题三步曲 找到重复子问题 根据数学归纳法：如果已知小偷在第i-1个房间对应的最高金额，那么小偷在第i个房间的对应的最高金额有以下两种情况 小偷偷了第i-1房间：那么小偷势必不能偷第i个房间，那么这个时候小偷偷的金额应该继承上一个值 小偷没有偷第i-1房间：那么小偷一定要偷第i个房间(因为是求的最大值)，这个时候小偷偷的金额应该是上一个值加上第i个房间的金额 状态定义 那么我们怎么表示某一个房间偷与不偷呢？此时我们可以考虑在一维的基础之上加一维附加这个状态，用dp[i][0]表示没有偷第i个房间，dp[i][1]表示偷了第i个房间，nums[i]表示第i间房的金额，那么 计算没有偷i房的时候在i的最大金额：dp[i][0]=max(dp[i-1][0], dp[i-1][1]) 计算偷i房的时候在i的最大金额：dp[i][1]=dp[i-1][0]+nums[i] dp的初始值为全为0，长度为n+1， 第0个元素表示房间数为0时，能偷到的金额为0， 第n个元素表示到达最后一个房间，能偷到的金额为多少 遍历从1开始 最终的结果：max(dp[n][0], dp[n][1]) DP方程定义 f(n,0) =\\left\\{ \\begin{aligned} 0 &,& n=0 \\\\ max(f(n-1, 0), f(n-1, 1)) &,& n>1 \\end{aligned} \\right. f(n,1) =\\left\\{ \\begin{aligned} 0 &,& n=0 \\\\ f(n-1, 0)+nums(n) &,& n>1 \\end{aligned} \\right. res = max(f(n, 0), f(n, 1))1234567891011class Solution: def rob(self, nums: List[int]) -&gt; int: n = len(nums) # 房间个数 dp = [[0 for _ in range(2)] for _ in range(n + 1)] for i in range(1, n + 1): dp[i][0] = max(dp[i - 1][0], dp[i - 1][1]) # 不偷第i间房 dp[i][1] = dp[i - 1][0] + nums[i - 1] # 偷第i间房 return max(dp[n][0], dp[n][1]) # 返回第i间房 偷与不偷的最大金额 DP问题三步曲-version2 第一个版本中，我们考虑的时候，并不知道小偷有没有偷某个房间，所以加了一个维度表示某个房间偷与不偷的 对应的最大金额 这个版本中，我们换个思路，可以肯定的是，小偷一定会偷其中一间房，也就是说，如果我们假定某间房必偷的话，那么我们最终的结果应该是所有结果的最大值 找到重复子问题 根据数学归纳法：由于小偷不能偷连续的两间房，那么我们如果要计算第i间房最大金额，该怎么计算呢？这个时候，前一间房要么偷了，要么没偷，如果前一间房没偷，那么看前两间房偷没偷，前两间房如果没偷，那就继续往前推 状态定义-DP数组含义及base case dp[i]表示当偷到第i间房时的最大金额，不管第i间房偷与不偷， dp[i]=max(dp[i-1], dp[i-2]+nums[i]) 表示：偷与不偷i-1的时候，在第i间房的最大金额 dp初始化全为0，长度为n+2 dp[0], dp[1]表示第1间房前1间、两间的金额都为0 遍历从2开始 最终结果：max(dp) DP方程 f(n) = \\left\\{ \\begin{aligned} 0 &,& n=-1 \\\\ 0 &,& n=0 \\\\ max(f(n-1), f(n-2)+nums(n)) &,& n>0 \\end{aligned} \\right.12345678910111213141516171819202122232425class Solution: def robnn(self, nums: List[int]) -&gt; int: n = len(nums) dp = [0] * (n + 2) for i in range(2, n + 2): dp[i] = max(dp[i - 1], dp[i - 2] + nums[i - 2]) return max(dp) # ====&gt; 优化，去掉最后的取最大值的函数，且降低空间复杂度 def rob(self, nums: List[int]) -&gt; int: n = len(nums) i_2, i_1, res = 0, 0, 0 # 前两间房的最大金额，前一间房的最大金额，当前房间的最大金额 for i in range(n): # dp[i] = max(dp[i - 1], dp[i - 2] + nums[i - 2]) # 更新偷到当前房间的最大金额 res = max(i_1, i_2 + nums[i]) # 上一个res变成前一间房 # 上一个i_1变成前两间房 i_1, i_2 = res, i_1 return res","pubDate":"Mon, 29 Jun 2020 17:54:22 GMT","guid":"https://shang.at/post/算法-动态规划/","category":"数据结构与算法"},{"title":"Python学习-python3.6-dict有序且效率更高","link":"https://shang.at/post/Python学习-python3-6-dict有序且效率更高/","description":"https://www.cnblogs.com/xieqiankun/p/python_dict.html","pubDate":"Sun, 28 Jun 2020 23:22:42 GMT","guid":"https://shang.at/post/Python学习-python3-6-dict有序且效率更高/","category":"Python学习"},{"title":"Hadoop学习","link":"https://shang.at/post/Hadoop学习/","description":"大数据 分布式数据存储 ​ 数据一致性 - CAP - poxes 主从 ​ 单点故障 - HA ​ 内存压力 - 分片管理 分布式计算 - 计算向数据移动 ​ mapreduce 数据以一条记录为单位及经过map方法映射成KV，相同的K为一组，这一组数据条用一次reduce方法，在方法内迭代计算一组数据。 迭代器模式，数据集一般是用迭代计算的方式 ​ 为什么要有split？split只是一个逻辑上的概念。 ​ 与数据物理存储上的block解耦(软件工程上：加一层解耦)，默认情况下，split等于block，但是也可以小于block，也可能大于block","pubDate":"Fri, 26 Jun 2020 16:34:48 GMT","guid":"https://shang.at/post/Hadoop学习/","category":"Hadoop学习"},{"title":"Hadoop学习-Yarn-Scheduler","link":"https://shang.at/post/Hadoop学习-Yarn-Scheduler/","description":"","pubDate":"Thu, 25 Jun 2020 06:24:45 GMT","guid":"https://shang.at/post/Hadoop学习-Yarn-Scheduler/","category":"Hadoop学习"},{"title":"Hadoop学习-Yarn-Container","link":"https://shang.at/post/Hadoop学习-Yarn-Container/","description":"","pubDate":"Thu, 25 Jun 2020 06:24:29 GMT","guid":"https://shang.at/post/Hadoop学习-Yarn-Container/","category":"Hadoop学习"},{"title":"Hadoop学习-如何实现一个在Yarn上的Application","link":"https://shang.at/post/Hadoop学习-如何实现一个在Yarn上的Application/","description":"","pubDate":"Thu, 25 Jun 2020 01:27:51 GMT","guid":"https://shang.at/post/Hadoop学习-如何实现一个在Yarn上的Application/","category":"Hadoop学习"},{"title":"Hadoop学习-Mapreduce编程模式","link":"https://shang.at/post/Hadoop学习-Mapreduce编程模式/","description":"","pubDate":"Thu, 25 Jun 2020 01:26:50 GMT","guid":"https://shang.at/post/Hadoop学习-Mapreduce编程模式/","category":"Hadoop学习"},{"title":"Hive学习-安装","link":"https://shang.at/post/Hive学习-安装/","description":"配置过程 mysql 安装 配置可以远程连接 jdbc driver hive使用的jdbc drive要与mysql的版本匹配 hive配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;!-- hive-site.xml --&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://hostmachine:3306/metastore?createDatabaseIfNotExist=true&lt;/value&gt; &lt;description&gt;the URL of the MySQL database&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;hive&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;hive1234&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;datanucleus.autoCreateSchema&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;datanucleus.fixedDatastore&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;datanucleus.autoStartMechanism&lt;/name&gt; &lt;value&gt;SchemaTable&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置数据存放在hdfs上的路径 --&gt; &lt;property&gt; &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; &lt;value&gt;/user/hive/warehouse&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置metastore service 的节点 --&gt; &lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;thrift://node2:9083&lt;/value&gt; &lt;description&gt;IP address (or fully-qualified domain name) and port of the metastore host&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.metastore.schema.verification&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 启动过程 首先启动hdfs：start-dfs.sh 初始化metestore：schematool --dbType mysql --initSchema 启动metastore service：hive --service metastore 启动hive：hive","pubDate":"Wed, 24 Jun 2020 07:41:54 GMT","guid":"https://shang.at/post/Hive学习-安装/","category":"Hive学习"},{"title":"数据库-mysql-环境配置","link":"https://shang.at/post/数据库-mysql-环境配置/","description":"platform：MAC 安装1234567891011121314brew istall mysqlWe've installed your MySQL database without a root password. To secure it run: mysql_secure_installationMySQL is configured to only allow connections from localhost by defaultTo connect run: mysql -urootTo have launchd start mysql now and restart at login: brew services start mysqlOr, if you don't want/need a background service you can just run: mysql.server start 新安装的mysql，需要重置密码： The initial root account may or may not have a password. Choose whichever of the following procedures applies: If the root account exists with an initial random password that has been expired, connect to the server as root using that password, then choose a new password. This is the case if the data directory was initialized using mysqld —initialize, either manually or using an installer that does not give you the option of specifying a password during the install operation. Because the password exists, you must use it to connect to the server. But because the password is expired, you cannot use the account for any purpose other than to choose a new password, until you do choose one. If you do not know the initial random password, look in the server error log. Connect to the server as root using the password: 12shell&gt; mysql -u root -p Enter password: (enter the random root password here) Choose a new password to replace the random password: mysql&gt; ALTER USER ‘root’@’localhost’ IDENTIFIED BY ‘root-password’; If the root account exists but has no password, connect to the server as root using no password, then assign a password. This is the case if you initialized the data directory using mysqld —initialize-insecure. Connect to the server as root using no password: 1shell&gt; mysql -u root --skip-password Assign a password: 1mysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'root-password'; After assigning the root account a password, you must supply that password whenever you connect to the server using the account. For example, to connect to the server using the mysql client, use this command: 12shell&gt; mysql -u root -p Enter password: (enter root password here) To shut down the server with mysqladmin, use this command: 12shell&gt; mysqladmin -u root -p shutdown Enter password: (enter root password here) 设置远程访问设置my.cnf使用brew 安装的mysql，my.cnf文件在/usr/local/etc/my.cnf，修改bind-address为0.0.0.0，然后重启brew services restart mysql 创建用户，赋予权限1234567891011121314# 登录mysqlmysql -u root -p 123456# 创建新用户create user 'hive' identified by 'hive1234';# 授权grant all privileges on *.* to 'hive'@'%' with grant option;# *.* 前边的*号指的是数据库，后面的*号指的是表，*.*的意思就是任意数据库下的任意表# 'root'@'%'，'root'用户名，'%'任意的主机名。# 这条配置信息就是说，允许任意节点以root身份登录，并且可以访问mysql里的任意库下的任意表# 刷新flush privileges; 至此，便可以在其他host上访问mysql服务了。 其他问题 jar记得更新 server 时区","pubDate":"Wed, 24 Jun 2020 06:16:33 GMT","guid":"https://shang.at/post/数据库-mysql-环境配置/","category":"数据库"},{"title":"Hadoop学习-Shell脚本学习","link":"https://shang.at/post/Hadoop学习-Shell脚本学习/","description":"","pubDate":"Wed, 24 Jun 2020 05:28:09 GMT","guid":"https://shang.at/post/Hadoop学习-Shell脚本学习/","category":"Hadoop学习"},{"title":"工具使用-iterm2","link":"https://shang.at/post/工具使用-iterm2/","description":"标签12345新建标签：command + t关闭标签：command + w切换标签：command + 数字 command + 左右方向键切换全屏：command + enter查找：command + f 分屏12345垂直分屏：command + d水平分屏：command + shift + d切换屏幕：command + option + 方向键 command + [ 或 command + ]查看历史命令：command + ;查看剪贴板历史：command + shift + h 其他1234567891011121314151617181920212223清除当前行：ctrl + u到行首：ctrl + a到行尾：ctrl + e前进后退：ctrl + f/b (相当于左右方向键)上一条命令：ctrl + p搜索命令历史：ctrl + r删除当前光标的字符：ctrl + d删除光标之前的字符：ctrl + h删除光标之前的单词：ctrl + w删除到文本末尾：ctrl + k交换光标处文本：ctrl + t清屏1：command + r清屏2：ctrl + l自带有哪些很实用的功能/快捷键⌘ + 数字在各 tab 标签直接来回切换选择即复制 + 鼠标中键粘贴，这个很实用⌘ + f 所查找的内容会被自动复制⌘ + d 横着分屏 / ⌘ + shift + d 竖着分屏⌘ + r = clear，而且只是换到新一屏，不会想 clear 一样创建一个空屏ctrl + u 清空当前行，无论光标在什么位置输入开头命令后 按 ⌘ + ; 会自动列出输入过的命令⌘ + shift + h 会列出剪切板历史可以在 Preferences &gt; keys 设置全局快捷键调出 iterm，这个也可以用过 Alfred 实现 常用的一些快捷键1234567891011121314⌘ + 1 / 2 左右 tab 之间来回切换，这个在 前面 已经介绍过了⌘← / ⌘→ 到一行命令最左边/最右边 ，这个功能同 C+a / C+e⌥← / ⌥→ 按单词前移/后移，相当与 C+f / C+b，其实这个功能在Iterm中已经预定义好了，⌥f / ⌥b，看个人习惯了好像就这几个设置方法如下当然除了这些可以自定义的也不能忘了 linux 下那些好用的组合C+a / C+e 这个几乎在哪都可以使用C+p / !! 上一条命令C+k 从光标处删至命令行尾 (本来 C+u 是删至命令行首，但iterm中是删掉整行)C+w A+d 从光标处删至字首/尾C+h C+d 删掉光标前后的自负C+y 粘贴至光标后C+r 搜索命令历史，这个较常用 选中即复制iterm2 有 2 种好用的选中即复制模式。 一种是用鼠标，在 iterm2 中，选中某个路径或者某个词汇，那么，iterm2 就自动复制了。 另一种是无鼠标模式，command+f,弹出 iterm2 的查找模式，输入要查找并复制的内容的前几个字母，确认找到的是自己的内容之后，输入 tab，查找窗口将自动变化内容，并将其复制。如果输入的是 shift+tab，则自动将查找内容的左边选中并复制。 自动完成输入打头几个字母，然后输入 command+; iterm2 将自动列出之前输入过的类似命令。 剪切历史输入 command+shift+h，iterm2 将自动列出剪切板的历史记录。如果需要将剪切板的历史记录保存到磁盘，在 Preferences &gt; General &gt; Save copy/paste history to disk 中设置。","pubDate":"Tue, 23 Jun 2020 10:30:55 GMT","guid":"https://shang.at/post/工具使用-iterm2/","category":"工具使用"},{"title":"Hadoop学习-源码编译","link":"https://shang.at/post/Hadoop学习-源码编译/","description":"","pubDate":"Tue, 23 Jun 2020 10:18:16 GMT","guid":"https://shang.at/post/Hadoop学习-源码编译/","category":"Hadoop学习"},{"title":"Hadoop学习-集群搭建","link":"https://shang.at/post/Hadoop学习-集群搭建/","description":"配置12345678# hadoop.sh -&gt; /etc/profile.d/export HADOOP_PREFIX=/root/hadoopexport HADOOP_YARN_HOME=$&#123;HADOOP_PREFIX&#125;export HADOOP_CONF_DIR=$&#123;HADOOP_PREFIX&#125;/etc/hadoopexport YARN_LOG_DIR=$&#123;HADOOP_YARN_HOME&#125;/logsexport YARN_IDENT_STRING=rootexport HADOOP_MAPRED_IDENT_STRING=rootexport PATH=$&#123;HADOOP_PREFIX&#125;/bin:$&#123;HADOOP_PREFIX&#125;/sbin:$&#123;PATH&#125; 12345678910111213&lt;!-- core-site.xml -&gt; path_to_hadoop/etc/hadoop/ --&gt;&lt;!-- https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-common/core-default.xml --&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://node4:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:///root/data/hadoop/tmp&lt;/value&gt; &lt;description&gt;A base for other temporary directories.&lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; 12345678910111213141516171819202122232425262728293031323334353637383940&lt;!-- hdfs-site.xml -&gt; path_to_hadoop/etc/hadoop/ --&gt;&lt;!-- https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml --&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:///root/data/hadoop/namenode&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:///root/data/hadoop/datanode&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;!-- config secondary namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;node3:50090&lt;/value&gt; &lt;/property&gt; &lt;!-- enable webhdfs --&gt; &lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- disable permissions; only for development, of course --&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;5&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt; &lt;value&gt;5&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 12345678910111213141516171819202122&lt;!-- yarn-site.xml -&gt; path_to_hadoop/etc/hadoop/ --&gt;&lt;!-- https://hadoop.apache.org/docs/r2.7.3/hadoop-yarn/hadoop-yarn-common/yarn-default.xml --&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- enable log aggregation, this is false by default --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;node4&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.timeline-service.hostname&lt;/name&gt; &lt;value&gt;node4&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 123456789101112&lt;!-- mapred-site.xml -&gt; path_to_hadoop/etc/hadoop/ --&gt;&lt;!-- https://hadoop.apache.org/docs/r2.7.3/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml --&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;node3:19888&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 启动流程Step1. 第一次启动HDFS，需要格式化一下hdfs 1$HADOOP_PREFIX/bin/hdfs namenode -format &lt;cluster-name&gt; Step2. 启动 1234start-dfs.shstart-yarn.shyarn-daemon.sh start proxyservermr-jobhistory-daemon.sh start historyserver 停止流程1234stop-dfs.shstop-yarn.shyarn-daemon.sh stop proxyservermr-jobhistory-daemon.sh stop historyserver 访问Once the Hadoop cluster is up and running check the web-ui of the components as described below: Daemon Web Interface Notes NameNode http://nn_host:port/ Default HTTP port is 50070. SecondaryNameNode http://nn_host:port/ Default HTTP port is 50090. ResourceManager http://rm_host:port/ Default HTTP port is 8088. YarnWebProxy http://proxy_host:port/ no Default HTTP port. 需要自定义 MapReduce JobHistory Server http://jhs_host:port/ Default HTTP port is 19888.","pubDate":"Tue, 23 Jun 2020 10:17:38 GMT","guid":"https://shang.at/post/Hadoop学习-集群搭建/","category":"Hadoop学习"},{"title":"Hadoop学习-配置详解","link":"https://shang.at/post/Hadoop学习-配置详解/","description":"版本：2.7.3 core-default.xml parameter default value notes fs.defaultFS file:/// 定义namenode的URI，改成hdfs://host:port/ hadoop.tmp.dir /tmp/hadoop-${user.name} 定义其他临时目录的根目录 io.file.buffer.size 4096 读写文件操作时的缓存字节数，必须是硬件上的内存页大小的整数倍 hdfs-default.xmlnamenode parameter default value note dfs.namenode.http(s)-address 0.0.0.0:50070(50470) 配置dfs的web ui界面，不建议修改。可以通过http://namenode_hostname:50070访问 dfs.namenode.name.dir file://${hadoop.tmp.dir}/dfs/name 配置DFS namenode的fsimage文件存放在本次文件系统的路径。如果配置了使用逗号分隔的多个路径，那么namemode会在每个目录下面都冗余的存放一份。 dfs.namenode.edits.dir dfs.namenode.name.dir 配置DFS namenode的edits文件存放在本次文件系统的路径。如果配置了使用逗号分隔的多个路径，那么namemode会在每个目录下面都冗余的存放一份。 dfs.namenode.fs-limits.min-block-size 1048576 1m 最小块大小（以字节为单位），由Namenode在创建时强制执行。这样可以防止意外创建具有很小块大小（因此有很多块）的文件，这会降低性能。减少数据块的数量， dfs.namenode.handler.count 10 namenode端服务的线程数，测试时可以配置的小一些，减少内存占用 datanode parameter default value notes dfs.datanode.data.dir file://${hadoop.tmp.dir}/dfs/data 文件块的在local filesystem中的存放路径。如果提供的是逗号分隔的目录列表，那么数据将会存储在所有的目录中，(通常目录列表是在不同的设备上)。目录应该被相应的存储类型所标记(HDFS上有四种存储设备：SSD、DISK、ARCHIVE、RAM_DISK)，如果没有指定，默认是DISK。如果目录不存在，那么会自动创建(需要获取目录权限) dfs.datanode.handler.count 10 namenode端服务的线程数，测试时可以配置的小一些，减少内存占用 secondary namenode parameter default value notes dfs.namenode.secondary.http(s)-address 0.0.0.0:50090(50091) 配置secondary namenode的http server和端口 dfs.namenode.checkpoint.dir file://${hadoop.tmp.dir}/dfs/namesecondary dfs.namenode.checkpoint.edits.dir ${dfs.namenode.checkpoint.dir} dfs.namenode.checkpoint.period 3600 dfs.namenode.checkpoint.txns 1000000 dfs.namenode.checkpoint.check.period 60 dfs.namenode.checkpoint.max-retries 3 dfs.namenode.num.checkpoints.retained 2 dfs parameter default value notes dfs.permissions.enabled true 配置是否启用权限检查，默认是启用的。测试时可以设置为false。当开启状态时，dfs不会检测文件的权限检测。HDFS PermissionHDFS默认启动namenode的user为superuser，这个 dfs.blocksize 134217728 128m 单位字节，新文件的block 大小 dfs.hosts / dfs.hosts.exclude List of permitted/excluded DataNodes.If necessary, use these files to control the list of allowable datanodes. dfs.replication 3 块副本数 dfs.webhdfs.enabled true 启动namenode和datanode上的WebHHDFS(REST API) mapred-default.xmlMapReduce Applications Parameter Value Notes mapreduce.framework.name yarn Execution framework set to Hadoop YARN. mapreduce.map.memory.mb 1536 Larger resource limit for maps. mapreduce.map.java.opts -Xmx1024M Larger heap-size for child jvms of maps. mapreduce.reduce.memory.mb 3072 Larger resource limit for reduces. mapreduce.reduce.java.opts -Xmx2560M Larger heap-size for child jvms of reduces. mapreduce.task.io.sort.mb 100 Higher memory-limit while sorting data for efficiency. mapreduce.task.io.sort.factor 10 More streams merged at once while sorting files. mapreduce.reduce.shuffle.parallelcopies 5 Higher number of parallel copies run by reduces to fetch outputs from very large number of maps. MapReduce JobHistory Server Parameter Value Notes mapreduce.jobhistory.address 0.0.0.0:10020 MapReduce JobHistory Server IPC host:port mapreduce.jobhistory.webapp.address 0.0.0.0:19888 MapReduce JobHistory Server Web UI host:port yarn.app.mapreduce.am.staging-dir /tmp/hadoop-yarn/staging The staging dir used while submitting jobs. mapreduce.jobhistory.intermediate-done-dir ${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate Directory where history files are written by MapReduce jobs. mapreduce.jobhistory.done-dir ${yarn.app.mapreduce.am.staging-dir}/history/done Directory where history files are managed by the MR JobHistory Server. yarn-default.xmlResourceManager and NodeManager Parameter default Value Notes yarn.acl.enable false 是否开启ACLs yarn.admin.acl * ACL to set admins on the cluster. ACLs are of for comma-separated-usersspacecomma-separated-groups. Defaults to special value of * which means anyone. Special value of just space means no one has access. yarn.log-aggregation-enable false 是否启动日志聚合。日志聚合会收集每个container的日志并且在应用完成后将他们移动到HDFS中。具体目录由下面两个选项配置yarn.nodemanager.remote-app-log-dir和yarn.nodemanager.remote-app-log-dir-suffix。用户可以通过Application Timeline Server访问这些日志文件 ResourceManager Parameter default Value Notes yarn.resourcemanager.address ${yarn.resourcemanager.hostname}:8032 配置RM的URIfor clients to submit jobs. yarn.resourcemanager.scheduler.address ${yarn.resourcemanager.hostname}:8030 资源调度器URIfor ApplicationMasters to talk to Scheduler to obtain resources. yarn.resourcemanager.resource-tracker.address ${yarn.resourcemanager.hostname}:8031 for NodeManagers. yarn.resourcemanager.admin.address ${yarn.resourcemanager.hostname}:8033 for administrative commands. yarn.resourcemanager.webapp.address ${yarn.resourcemanager.hostname}:8088 RM web application yarn.resourcemanager.hostname 0.0.0.0 ResourceManager host.应该改成特定的hostname yarn.web-proxy.address 默认没有配置，会作为RM的一部分运行 The address for the web proxy as HOST:PORT, if this is not given then the proxy will run as part of the RM yarn.resourcemanager.scheduler.class org.apache.hadoop.yarn.server.resourcemanager.&lt;br /&gt;scheduler.capacity.CapacityScheduler 指定RM使用的调度器：CapacityScheduler (recommended), FairScheduler (also recommended), or FifoScheduler yarn.scheduler.minimum-allocation-mb 1024 In MBs，Minimum limit of memory to allocate to each container request at the ResourceManager. yarn.scheduler.maximum-allocation-mb 8192 In MBs，Maximum limit of memory to allocate to each container request at the Resource Manager. yarn.resourcemanager.nodes.include-path / yarn.resourcemanager.nodes.exclude-path List of permitted/excluded NodeManagers.If necessary, use these files to control the list of allowable NodeManagers. NodeManager Parameter default Value Notes yarn.nodemanager.resource.memory-mb 8192 Resource i.e. available physical memory, in MB, for given NodeManager.Defines total available resources on the NodeManager to be made available to running containers yarn.nodemanager.vmem-pmem-ratio 2.1Maximum ratio by which virtual memory usage of tasks may exceed physical memory The virtual memory usage of each task may exceed its physical memory limit by this ratio. The total amount of virtual memory used by tasks on the NodeManager may exceed its physical memory usage by this ratio. yarn.nodemanager.local-dirs ${hadoop.tmp.dir}/nm-local-dirComma-separated list of paths on the local filesystem where intermediate data is written. Multiple paths help spread disk i/o. yarn.nodemanager.log-dirs ${yarn.log.dir}/userlogsComma-separated list of paths on the local filesystem where logs are written. Multiple paths help spread disk i/o. yarn.nodemanager.log.retain-seconds 10800 Default time (in seconds) to retain log files on the NodeManager. Only applicable if log-aggregation is disabled. yarn.nodemanager.remote-app-log-dir /tmp/logs HDFS directory where the application logs are moved on application completion. Need to set appropriate permissions. Only applicable if log-aggregation is enabled. yarn.nodemanager.remote-app-log-dir-suffix logs Suffix appended to the remote log dir. Logs will be aggregated to ${yarn.nodemanager.remote-app-log-dir}/${user}/${thisParam} Only applicable if log-aggregation is enabled. yarn.nodemanager.aux-services mapreduce_shuffle Shuffle service that needs to be set for Map Reduce applications. History Server (Needs to be moved elsewhere) Parameter default Value Notes yarn.log-aggregation.retain-seconds -1 How long to keep aggregation logs before deleting them. -1 disables. Be careful, set this too small and you will spam the name node. yarn.log-aggregation.retain-check-interval-seconds -1 Time between checks for aggregated log retention. If set to 0 or a negative value then the value is computed as one-tenth of the aggregated log retention time. Be careful, set this too small and you will spam the name node.","pubDate":"Tue, 23 Jun 2020 09:12:52 GMT","guid":"https://shang.at/post/Hadoop学习-配置详解/","category":"Hadoop学习"},{"title":"Shell编程-常用命令","link":"https://shang.at/post/Shell编程-常用命令/","description":"文本编辑sedawkLinux上的定时器cron命令xargsexec远程控制sshscprsync软件管理rpm","pubDate":"Tue, 23 Jun 2020 08:53:17 GMT","guid":"https://shang.at/post/Shell编程-常用命令/","category":"Shell编程"},{"title":"操作系统-centos7修改hostname","link":"https://shang.at/post/操作系统-centos7修改hostname/","description":"在CentOS7中，有三种定义的主机名:静态的（static）、瞬态的（transient）、灵活的（pretty）。“静态”主机名也称为内核主机名，是系统在启动时从/etc/hostname自动初始化的主机名。“瞬态”主机名是在系统运行时临时分配的主机名，例如，通过DHCP或mDNS服务器分配。静态主机名和瞬态主机名都遵从作为互联网域名同样的字符限制规则。而另一方面，“灵活”主机名则允许使用自由形式（包括特殊/空白字符）的主机名，以展示给终端用户。 方法一1234567891011121314151617181920212223242526[root@Geeklp201 ~]# hostnamectl #查看一下当前主机名的情况 Static hostname: Geeklp201 Icon name: computer-vm Chassis: vm Machine ID: 77efa27de81d470883b5bb0ed04f468c Boot ID: fa62bd1c0f5e4e53a0691fb97971594f Virtualization: vmware Operating System: CentOS Linux 7 (Core) CPE OS Name: cpe:/o:centos:centos:7 Kernel: Linux 3.10.0-693.el7.x86_64 Architecture: x86-64[root@Geeklp201 ~]# hostnamectl set-hostname geeklp --static[root@Geeklp201 ~]# hostnamectl status Static hostname: geeklp Pretty hostname: Geeklp201 Icon name: computer-vm Chassis: vm Machine ID: 77efa27de81d470883b5bb0ed04f468c Boot ID: fa62bd1c0f5e4e53a0691fb97971594f Virtualization: vmware Operating System: CentOS Linux 7 (Core) CPE OS Name: cpe:/o:centos:centos:7 Kernel: Linux 3.10.0-693.el7.x86_64 Architecture: x86-64重启VM 方法二通过修改文件/etc/hostname来实现主机名的修改。把该文件内容替换成自己想要的主机名重启即可。","pubDate":"Tue, 23 Jun 2020 04:31:11 GMT","guid":"https://shang.at/post/操作系统-centos7修改hostname/","category":"centos7修改hostname"},{"title":"工具使用-vim","link":"https://shang.at/post/工具使用-vim/","description":"vim快捷键 命令模式：esc 编辑模式： 在当前字符前开始编辑：命令模式下按i 在当前字符后开始编辑：命令模式下按a 另起一行：命令模式下按o 复制 单行复制 在命令模式下，将光标移动到将要复制的行处，按“yy”进行复制，将光标移动到将要粘贴的行处，按“p”进行粘贴； 多行复制 在命令模式下，将光标移动到将要复制的首行处，按“nyy”复制n行；其中n为1、2、3…… 2、粘贴 在命令模式下，将光标移动到将要粘贴的行处，按“p”进行粘贴 查询 输入： /abc 查询 abc 开头的单词 之后，所以以abc开头的单词都会标记高亮，输入 n 会查找下一个结果 ?pattern 向上搜索#继续搜索上一个 查看 暂时显示/取消行号： 使用Vim打开文件后，在Normal模式下输入 :set number（或 :set nu）显示行号 :set nonumber （或 :set nonu）取消行号 永久显示行号 查找Vim设定文件 sudo find / -name vimrc 修改Vim设定文件 /etc/vimrc ,末尾添加 set number （或 set nu） 保存即可。","pubDate":"Tue, 23 Jun 2020 04:22:22 GMT","guid":"https://shang.at/post/工具使用-vim/","category":"工具使用"},{"title":"大数据-常见端口","link":"https://shang.at/post/大数据-常见端口/","description":"mysql：3306 redis： zookeeper：2181 kafka：9092 eagle：8048 hdfs：50070 yarn：8088 spark：4041 flink：8081","pubDate":"Sun, 21 Jun 2020 01:17:50 GMT","guid":"https://shang.at/post/大数据-常见端口/","category":"大数据生态"},{"title":"大数据-环境配置","link":"https://shang.at/post/大数据-环境配置/","description":"linux的文件和目录的权限规则使用ls -l命令可以查看当前目录的文件列表以及权限信息，显示如下 drwxr-xr-x linux安装rpm包免密登录123456789# 生成密钥 公钥sudo ssh-keygen -t rsa -f ~/.ssh/id_rsa# 将公钥拷贝到目标机器ssh-copy-id user@tartget_hostame# 这样之后就可以在节点之间 免密登录了ssh user@tartget_hostamessh tartget_hostame # 如果当前登录的用户和target的用户名一致，则不需要加user@ 注意，如果执行ssh-copy-id 输入密码后仍报错(Permission denied (publickey,gssapi-keyex,gssapi-with-mic))，可以尝试按照如下方案解决： 进入target机器，进入cd /etc/ssh/sshd_config，然后修改为PasswordAuthentication yes，最后重启sshd服务service sshd restart即可 同步时钟ntpdate cn.pool.ntp.org | ntp[1-7].aliyun.com clock -w","pubDate":"Sat, 20 Jun 2020 10:01:00 GMT","guid":"https://shang.at/post/大数据-环境配置/","category":"大数据生态"},{"title":"虚拟机-Vagrant使用","link":"https://shang.at/post/虚拟机-Vagrant使用/","description":"什么是Vagrantvagrant是一个基于VirtualBox, VMware, AWS等平台的一个构造和管理VM的工具，它提供了一个简单的工作流程，让VM的创建和管理全都自动化。vagrant的配置是基于ruby的 Vagrant是基于Box的，Box是针对Vagrant运行环境的封装 如何使用VagrantStep 1：安装 官网：https://www.vagrantup.com Step 2：初始化环境 123mkdir vm-workspacecd vm-workspacevagrant init Step 3：配置Vagrantfile 经过vagrant init之后，会在vm-workspace下生成一个Vagrantfile，内容如下(删除了注释) 12345# -*- mode: ruby -*-# vi: set ft=ruby :Vagrant.configure(\"2\") do |config| config.vm.box = \"centos/7\"end 配置文件简介： 2 是指当前配置的Vagrant config的版本，目前Vagrant只支持两个版本 1和2，这里我不用改，用2就可以 config 就是配置对象，我们可以对他进行配置 do … end 是ruby的语法，就是一个代码块 下面是创建了 123456789101112131415161718192021222324252627282930313233343536373839404142# -*- mode: ruby -*-# vi: set ft=ruby :# 2 指定了配置的版本Vagrant.configure(\"2\") do |config| # 指定 box为 centos/7 config.vm.box = \"centos/7\" # 使用define定义vm的配置节点：一个配置节点就是一个虚拟机。 # 这里表示：在config中配置一个master的vm，该vm的配置对象命名为master，下面可以对该配置进行配置 config.vm.define :master do |master| # 配置master的hostname为master master.vm.hostname = \"master\" # 定义 虚机容器提供者配置，这里使用virtualbox。打开virtualbox后，可以在里面看到对应的vm实例 master.vm.provider :virtualbox do |v| v.name = \"master\" # vm的名称 v.memory = 1024 # vm的内存 v.cpus = 1 # vm可以使用的CPU个数 end # 配置master vm使用host-only网络模式，ip为10.211.55.100 master.vm.network :private_network, ip: \"10.211.55.100\" # 配置vagrant 启动vm的时候，需要执行的命令或脚本 # master.vm.provision :shell, path: \"bootstrap_master.sh\" end # 再次循环给vm创建3个配置节点，即再创建3个虚拟机 (1..3).each do |i| config.vm.define \"node#&#123;i&#125;\" do |node| node.vm.hostname = \"node#&#123;i&#125;\" node.vm.provider :virtualbox do |v| v.name = \"node#&#123;i&#125;\" v.memory = 1024 v.cpus = 1 end node.vm.network :private_network, ip: \"10.211.55.10#&#123;i&#125;\" # node.vm.provision :shell, path: \"bootstrap_master.sh\" end end # config.vm.synced_folder \"\" \"\" # vagrant默认会把当前工作目录挂载在vm的/vagrant目录下 config.vm.provision :shell, path: \"bootstrap.sh\" config.vm.provision :shell, path: \"sshd.sh\"end 123456789101112131415161718# bootstrap.sh:虚拟机初始化的过程，并且配置java、sshkey、hostssudo yum -y updatesudo yum -y upgradesudo yum groupinstall -y developmentsudo yum install -y java-1.8.0-openjdk net-tools rsync mlocate wget vim \\ gcc zlib-dev openssl-devel sqlite-devel bzip2-devel python-devel# set Javaecho 'export JAVA_HOME=/usr/lib/jvm/jre' &gt;&gt; /etc/profile.d/java.shecho 'export PATH=/usr/lib/jvm/jre/bin:$PATH' &gt;&gt; /etc/profile.d/java.sh# sshkeysudo ssh-keygen -t rsa -f ~/.ssh/id_rsa# set hostsecho '10.211.55.100 node0' &gt;&gt; /etc/hostsecho '10.211.55.101 node1' &gt;&gt; /etc/hostsecho '10.211.55.102 node2' &gt;&gt; /etc/hostsecho '10.211.55.102 node3' &gt;&gt; /etc/hosts 12345678# sshd.sh: centos/7下的ssh 默认没有开启PasswordAuthentication，所以单独使用这个脚本开启一下# 免去后面配置免密登录的时候，再去修改# open PasswordAuthenticationsed -i 's/#PasswordAuthentication yes/PasswordAuthentication yes/g' /etc/ssh/sshd_configsed -i 's/PasswordAuthentication no/#PasswordAuthentication yes/g' /etc/ssh/sshd_config# restart sshdservice sshd restart 解释： Vagrant的网络连接方式有三种： NAT : 缺省创建，用于让vm可以通过host转发访问局域网甚至互联网。 host-only : 只有主机可以访问vm，其他机器无法访问它。 bridge : 此模式下vm就像局域网中的一台独立的机器，可以被其他机器访问。 根据vagrantfile的层次，分为： configure级：它定义在 Vagrant.configure(“2”) 的下一层次，形如： config.vm.provision … vm级：它定义在 config.vm.define :master do |master| 的下一层次，master.vm.provision … 执行的顺序是先执行configure级任务，再执行vm级任务，即便configure级任务在vm定义的下面才定义 Step 4：启动Vagrant 1vagrant up Step 5：连接vm 1vagrant ssh node0 Step 6：切换到root用户 12supassword默认是vagrant 至此，就可以使用vm了。 有一个非常有用的命令：vagrant rsync-auto。因为我们可能会经常性的修改共享文件夹，这个命令可以触发共享文件夹的同步，而不需要执行vagrant reload来同步共享文件夹，该命令会重启VM Vagrant常用命令vagrant help vagrant help 1vagrant help vagrant [command] -h 1vagrant box -h vagrant box 添加box 1vagrant box add --name centos-7.4-base centos-7.4-base.box 查看box 1vagrant box list 移除box 1vagrant box remove centos-7.4-base vagrant vm 初始化 如果自己编写Vagrantfile，不需要这一步 这一步会把config.vm.box写入 1vagrant init centos-7.4-base 启动虚拟机 1vagrant up 查看状态 1vagrant status ssh 1vagrant ssh 暂停虚拟机 1vagrant suspend 恢复虚拟机 1vagrant resume 关闭虚拟机 1vagrant halt 销毁虚拟机 1vagrant destroy 更新Vagrantfile，刷新容器 1vagrant reload vagrant snapshot使用虚拟机快照命令需要先启动虚拟机 保存虚拟机快照 1vagrant snapshot save snap1 list虚拟机快照 1vagrant snapshot list 恢复虚拟机快照 1vagrant snapshot restore snap1 删除虚拟机快照 1vagrant snapshot delete snap1","pubDate":"Sat, 20 Jun 2020 03:48:16 GMT","guid":"https://shang.at/post/虚拟机-Vagrant使用/","category":"虚拟机"},{"title":"大数据-消息队列-数据采集-Kafka","link":"https://shang.at/post/大数据-消息队列-数据采集-Kafka/","description":"Kafka的基本概念和架构Apache Kafka是Apache软件基金会的开源的流处理平台，该平台提供了消息的订阅与发布的消息队列，一般用作系统间解耦、异步通信、削峰填谷等作用 逻辑上概念： Producer：生产消息的客户端 Consumer：消费消息的客户端 Consumer Group：同一个ConsumerGroup中的Consumer往往是一个服务的多个实例，用来提高消费的效率，也就是说同一个CG中的多个C不能重复消费消息；不同CG往往代表了多种服务，他们处理不同的业务，所以，不同的CG中的C对于消息的处理是相互独立的，如CG2中的C2可以重复的消费在CG1中的C1已经消费过的消息 消费者使用Consumer Group名称标记自己，并且发布到Topic的每条记录都会传递到每个订阅Consumer Group中的一个消费者实例。 ​ 如果所有Consumer实例都具有相同的Consumer Group，那么Topic中的记录会在该ConsumerGroup中的Consumer实例进行均分消费； ​ 如果所有Consumer实例具有不同的ConsumerGroup，则每条记录将广播到所有Consumer Group进程。 更常见的是，我们发现Topic具有少量的Consumer Group，每个Consumer Group可以理解为一个“逻辑的订阅者”。每个Consumer Group均由许多Consumer实例组成，以实现可伸缩性和容错能力。这无非就是发布-订阅模型，其中订阅者是消费者的集群而不是单个进程。这种消费方式Kafka会将Topic按照分区的方式均分给一个Consumer Group下的实例，如果ConsumerGroup下有新的成员介入，则新介入的Consumer实例会去接管ConsumerGroup内其他消费者负责的某些分区，同样如果一下ConsumerGroup下的有其他Consumer实例宕机，则由该ConsumerGroup中其他Consumer实例接管。 Tocpic：一组Record可以作为一个Topic在集群中被管理 Record：Producer生产的每一条消息就是一个Record，每一个Record只能属于一个Topic 由于Kafka的Topic的分区策略，因此Kafka仅提供分区中记录的有序性，也就意味着相同Topic的不同分区记录之间无顺序。因为针对于绝大多数的大数据应用和使用场景， 使用分区内部有序或者使用key进行分区策略已经足够满足绝大多数应用场景。但是，如果您需要记录全局有序，则可以通过只有一个分区Topic来实现，尽管这将意味着每个ConsumerGroup只有一个Consumer进程 Partition：每个Topic会有num.partitions(默认)个分区，每个Topic在创建的时候，也可以被指定分区的个数。 Kafka中对Topic实现日志分区的有以下目的： 支持集群存储的横向扩容。如果单一服务器的资源不够用，那么增加集群节点即可 每个服务器充当其某些分区的Leader，也可能充当其他分区的Follwer，因此群集中的负载得到了很好的平衡。 同一个Topic 多个分区可以提高Consumer消费的并行度 在kafka中同一个partition的record是严格有序的，但是不同partition的record并不是严格有序的。也就是说，kafka只能保证partition内部record的有序消费 Duplicate(副本)：每个分区会有--replication-factor个副本，是在Topic被创建的时候指定的 offset (非常重要的一个概念) — 待补充 在kafka中对于消息的生产和消费都是通过offset控制的。同一个partition的消息record的offset是递增的，消费者消费的时候，也是消费的指定的offset之后的消息。 消费者会定期的上传自己消费的offset给kafka server Segments — 待补充 架构上的概念 Broker：Kafka集群内的节点被称为broker Leader：kafka采用主从的架构，每个partition都有自己的leader。每个partition的leader负责消息的读写 Follower：每个 ISR kafka的基本使用命令 创建topic 123456kafka-topics.sh \\--bootstrap-server node1:9092,node2:9092,node3:9092 \\--create \\--topic topic01 \\--partitions 3 \\--replication-factor 3 查看topic列表 123kafka-topics.sh \\--bootstrap-server node1:9092,node2:9092,node3:9092 \\--list 查看topic详情 1234kafka-topics.sh \\--bootstrap-server node1:9092,node2:9092,node3:9092 \\--describe \\--topic topic01 修改topic 123456789101112kafka-topics.sh \\--bootstrap-server node1:9092,node2:9092,node3:9092 \\--create \\--topic topic03 \\--partitions 1 \\--replication-factor 1kafka-topics.sh \\--bootstrap-server node1:9092,node2:9092,node3:9092 \\--alter \\--topic topic03 \\--partitions 2 删除topic 1234kafka-topics.sh \\--bootstrap-server node1:9092,node2:9092,node3:9092 \\--delete \\--topic topic03 消费者订阅topic 1234567kafka-console-consumer.sh \\--bootstrap-server node1:9092,node2:9092,node3:9092 \\--topic topic01 \\--group g1 \\--property print.key=true \\--property print.value=true \\--property key.separator=, 消费者组 12345678kafka-consumer-groups.sh \\--bootstrap-server node1:9092,node2:9092,node3:9092 \\--listkafka-consumer-groups.sh \\--bootstrap-server node1:9092,node2:9092,node3:9092 \\--describe \\--group g1 生产者生产消息 123kafka-console-producer.sh \\--broker-list node1:9092,node2:9092,node3:9092 \\--topic topic01 API基本API高级API架构进阶高性能分析之零拷贝&amp;源码分析数据同步机制kafka与其他软件的集成与Flume的集成与SpringBoot的集成在大数据流计算中的应用ZookeeperKafka中的leader监控和topic的元数据，都是存在zk中","pubDate":"Sat, 20 Jun 2020 03:14:01 GMT","guid":"https://shang.at/post/大数据-消息队列-数据采集-Kafka/","category":"大数据生态"},{"title":"大数据-知识点","link":"https://shang.at/post/大数据-知识点/","description":"生态管理员-Zookeeper 节点通信-RPC Hadoop 数据存储-HDFS 资源管理-YARN 任务调度-AppMaster：所有第三方的应用可以实现AppMaster，即可将任务跑在YARN上 数据采集-Flume 消息队列-数据采集-Kafka 数仓-Hive 数据存储-HBase 流批一体-Spark 流批一体-Flink 机器学习-Spark mlib 机器学习-FlinkML","pubDate":"Sat, 20 Jun 2020 02:46:39 GMT","guid":"https://shang.at/post/大数据-知识点/","category":"大数据生态"},{"title":"java学习-底层知识总结","link":"https://shang.at/post/java学习-底层知识总结/","description":"JVMJVM：Java Virtual Machine JMM：Java Memory Model 1：JVM基础知识 什么是JVM 常见的JVM 2：ClassFileFormat3：类编译-加载-初始化hashcode锁的信息（2位 四种组合）GC信息（年龄）如果是数组，数组的长度 4：JMMnew Cat()pointer -&gt; Cat.class寻找方法的信息 5：对象1：句柄池 （指针池）间接指针，节省内存2：直接指针，访问速度快 6：GC基础知识栈上分配TLAB（Thread Local Allocation Buffer）OldEden老不死 - &gt; Old 7：GC常用垃圾回收器new Object()markword 8个字节类型指针 8个字节实例变量 0补齐 016字节（压缩 非压缩）Object o8个字节JVM参数指定压缩或非压缩","pubDate":"Sat, 13 Jun 2020 00:20:45 GMT","guid":"https://shang.at/post/java学习-底层知识总结/","category":"JAVA学习"},{"title":"java学习-class文件格式","link":"https://shang.at/post/java学习-class文件格式/","description":"","pubDate":"Sat, 13 Jun 2020 00:12:38 GMT","guid":"https://shang.at/post/java学习-class文件格式/","category":"JAVA学习"},{"title":"Python学习-metaclass实现单例","link":"https://shang.at/post/Python学习-metaclass实现单例/","description":"","pubDate":"Fri, 12 Jun 2020 01:35:16 GMT","guid":"https://shang.at/post/Python学习-metaclass实现单例/","category":""}]}